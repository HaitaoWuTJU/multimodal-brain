{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "# 加载预训练的LDM模型\n",
    "model_name = \"CompVis/ldm-text2im-large-256\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_name).to(\"cuda\")\n",
    "\n",
    "# 定义512维隐变量\n",
    "latent_dim = 512\n",
    "z = torch.randn(1, latent_dim).to(\"cuda\")\n",
    "\n",
    "# 为隐变量创建一个虚拟的文本输入 (此步骤可能因模型实现而异)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "input_ids = tokenizer(\"A latent vector\", return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "\n",
    "# 生成图像\n",
    "with torch.no_grad():\n",
    "    image = pipe(input_ids=input_ids, latents=z).images[0]\n",
    "\n",
    "# 保存生成的图像\n",
    "image.save(\"generated_image.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': 1, 'decoder': {'unets': [{'dim': 416, 'cond_dim': 512, 'image_embed_dim': 768, 'text_embed_dim': 768, 'cond_on_text_encodings': True, 'channels': 3, 'dim_mults': [1, 2, 3, 4], 'num_resnet_blocks': 4, 'attn_heads': 8, 'attn_dim_head': 64, 'sparse_attn': True, 'memory_efficient': True}], 'clip': {'make': 'openai', 'model': 'ViT-L/14'}, 'image_sizes': [64], 'channels': 3, 'timesteps': 1000, 'loss_type': 'l2', 'beta_schedule': ['cosine'], 'learned_variance': True}, 'data': {'webdataset_base_url': 'pipe:aws s3 cp --quiet s3://s-datasets/laion-aesthetic/data/laion2B-en-aesthetic/{}.tar -', 'embeddings_url': 's3://s-datasets/laion-aesthetic/ordered_embeddings/', 'num_workers': 12, 'batch_size': 21, 'start_shard': 0, 'end_shard': 5247, 'shard_width': 5, 'index_width': 4, 'splits': {'train': 0.75, 'val': 0.15, 'test': 0.1}, 'shuffle_train': False, 'resample_train': True, 'preprocessing': {'RandomResizedCrop': {'size': [64, 64], 'scale': [0.75, 1.0], 'ratio': [1.0, 1.0]}, 'ToTensor': True}}, 'train': {'epochs': 1000, 'lr': 0.0001, 'wd': 0.01, 'max_grad_norm': 0.5, 'save_every_n_samples': 200000, 'n_sample_images': 10, 'device': 'cuda:0', 'epoch_samples': 2000000, 'validation_samples': 100000, 'use_ema': True, 'ema_beta': 0.99, 'save_all': False, 'save_latest': True, 'save_best': True, 'unet_training_mask': [True]}, 'evaluate': {'n_evaluation_samples': 30, 'FID': {'feature': 64}, 'LPIPS': {'net_type': 'vgg', 'reduction': 'mean'}}, 'tracker': {'data_path': '.tracker-data-2', 'overwrite_data_path': True, 'log': {'log_type': 'wandb', 'wandb_entity': 'nousr_laion', 'wandb_project': 'dalle2_train_decoder', 'wandb_run_id': '5ojoz4bw', 'wandb_resume': True, 'verbose': True}, 'load': {'load_from': 'url', 'url': 'https://huggingface.co/Veldrovive/test_model/resolve/main/eu_latest_checkpoint2.pth'}, 'save': [{'save_to': 'wandb'}, {'save_to': 'huggingface', 'huggingface_repo': 'laion/DALLE2-PyTorch', 'save_latest_to': 'latest_{epoch}.pth', 'save_type': 'model'}]}}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.transforms import ToPILImage\n",
    "from dalle2_pytorch import DiffusionPrior, DiffusionPriorNetwork, OpenAIClipAdapter, Decoder, DALLE2\n",
    "from dalle2_pytorch.train_configs import TrainDiffusionPriorConfig, TrainDecoderConfig\n",
    "\n",
    "decoder_config = TrainDecoderConfig.from_json_path(\"/root/workspace/wht/pretrained/dalle2/decoder_config.json\").decoder\n",
    "decoder = decoder_config.create().cuda()\n",
    "\n",
    "decoder_model_state = torch.load(\"/root/workspace/wht/pretrained/dalle2/decoder.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['unets.0.null_image_embed', 'unets.0.null_image_hiddens', 'unets.0.null_text_embed', 'unets.0.init_conv.convs.0.weight', 'unets.0.init_conv.convs.0.bias', 'unets.0.init_conv.convs.1.weight', 'unets.0.init_conv.convs.1.bias', 'unets.0.init_conv.convs.2.weight', 'unets.0.init_conv.convs.2.bias', 'unets.0.to_time_hiddens.1.weight', 'unets.0.to_time_hiddens.1.bias', 'unets.0.to_time_tokens.0.weight', 'unets.0.to_time_tokens.0.bias', 'unets.0.to_time_cond.0.weight', 'unets.0.to_time_cond.0.bias', 'unets.0.image_to_tokens.0.weight', 'unets.0.image_to_tokens.0.bias', 'unets.0.to_image_hiddens.0.weight', 'unets.0.to_image_hiddens.0.bias', 'unets.0.norm_cond.weight', 'unets.0.norm_cond.bias', 'unets.0.norm_mid_cond.weight', 'unets.0.norm_mid_cond.bias', 'unets.0.downs.0.1.time_mlp.1.weight', 'unets.0.downs.0.1.time_mlp.1.bias', 'unets.0.downs.0.1.block1.project.weight', 'unets.0.downs.0.1.block1.project.bias', 'unets.0.downs.0.1.block1.norm.weight', 'unets.0.downs.0.1.block1.norm.bias', 'unets.0.downs.0.1.block2.project.weight', 'unets.0.downs.0.1.block2.project.bias', 'unets.0.downs.0.1.block2.norm.weight', 'unets.0.downs.0.1.block2.norm.bias', 'unets.0.downs.0.2.fn.norm.g', 'unets.0.downs.0.2.fn.to_qkv.weight', 'unets.0.downs.0.2.fn.to_out.0.weight', 'unets.0.downs.0.2.fn.to_out.1.g', 'unets.0.downs.0.3.0.time_mlp.1.weight', 'unets.0.downs.0.3.0.time_mlp.1.bias', 'unets.0.downs.0.3.0.block1.project.weight', 'unets.0.downs.0.3.0.block1.project.bias', 'unets.0.downs.0.3.0.block1.norm.weight', 'unets.0.downs.0.3.0.block1.norm.bias', 'unets.0.downs.0.3.0.block2.project.weight', 'unets.0.downs.0.3.0.block2.project.bias', 'unets.0.downs.0.3.0.block2.norm.weight', 'unets.0.downs.0.3.0.block2.norm.bias', 'unets.0.downs.0.3.1.time_mlp.1.weight', 'unets.0.downs.0.3.1.time_mlp.1.bias', 'unets.0.downs.0.3.1.block1.project.weight', 'unets.0.downs.0.3.1.block1.project.bias', 'unets.0.downs.0.3.1.block1.norm.weight', 'unets.0.downs.0.3.1.block1.norm.bias', 'unets.0.downs.0.3.1.block2.project.weight', 'unets.0.downs.0.3.1.block2.project.bias', 'unets.0.downs.0.3.1.block2.norm.weight', 'unets.0.downs.0.3.1.block2.norm.bias', 'unets.0.downs.0.3.2.time_mlp.1.weight', 'unets.0.downs.0.3.2.time_mlp.1.bias', 'unets.0.downs.0.3.2.block1.project.weight', 'unets.0.downs.0.3.2.block1.project.bias', 'unets.0.downs.0.3.2.block1.norm.weight', 'unets.0.downs.0.3.2.block1.norm.bias', 'unets.0.downs.0.3.2.block2.project.weight', 'unets.0.downs.0.3.2.block2.project.bias', 'unets.0.downs.0.3.2.block2.norm.weight', 'unets.0.downs.0.3.2.block2.norm.bias', 'unets.0.downs.0.3.3.time_mlp.1.weight', 'unets.0.downs.0.3.3.time_mlp.1.bias', 'unets.0.downs.0.3.3.block1.project.weight', 'unets.0.downs.0.3.3.block1.project.bias', 'unets.0.downs.0.3.3.block1.norm.weight', 'unets.0.downs.0.3.3.block1.norm.bias', 'unets.0.downs.0.3.3.block2.project.weight', 'unets.0.downs.0.3.3.block2.project.bias', 'unets.0.downs.0.3.3.block2.norm.weight', 'unets.0.downs.0.3.3.block2.norm.bias', 'unets.0.downs.0.4.weight', 'unets.0.downs.0.4.bias', 'unets.0.downs.1.1.time_mlp.1.weight', 'unets.0.downs.1.1.time_mlp.1.bias', 'unets.0.downs.1.1.block1.project.weight', 'unets.0.downs.1.1.block1.project.bias', 'unets.0.downs.1.1.block1.norm.weight', 'unets.0.downs.1.1.block1.norm.bias', 'unets.0.downs.1.1.block2.project.weight', 'unets.0.downs.1.1.block2.project.bias', 'unets.0.downs.1.1.block2.norm.weight', 'unets.0.downs.1.1.block2.norm.bias', 'unets.0.downs.1.1.res_conv.weight', 'unets.0.downs.1.1.res_conv.bias', 'unets.0.downs.1.2.fn.norm.g', 'unets.0.downs.1.2.fn.to_qkv.weight', 'unets.0.downs.1.2.fn.to_out.0.weight', 'unets.0.downs.1.2.fn.to_out.1.g', 'unets.0.downs.1.3.0.time_mlp.1.weight', 'unets.0.downs.1.3.0.time_mlp.1.bias', 'unets.0.downs.1.3.0.cross_attn.fn.null_kv', 'unets.0.downs.1.3.0.cross_attn.fn.norm.gamma', 'unets.0.downs.1.3.0.cross_attn.fn.norm.beta', 'unets.0.downs.1.3.0.cross_attn.fn.to_q.weight', 'unets.0.downs.1.3.0.cross_attn.fn.to_kv.weight', 'unets.0.downs.1.3.0.cross_attn.fn.to_out.0.weight', 'unets.0.downs.1.3.0.cross_attn.fn.to_out.1.gamma', 'unets.0.downs.1.3.0.cross_attn.fn.to_out.1.beta', 'unets.0.downs.1.3.0.block1.project.weight', 'unets.0.downs.1.3.0.block1.project.bias', 'unets.0.downs.1.3.0.block1.norm.weight', 'unets.0.downs.1.3.0.block1.norm.bias', 'unets.0.downs.1.3.0.block2.project.weight', 'unets.0.downs.1.3.0.block2.project.bias', 'unets.0.downs.1.3.0.block2.norm.weight', 'unets.0.downs.1.3.0.block2.norm.bias', 'unets.0.downs.1.3.1.time_mlp.1.weight', 'unets.0.downs.1.3.1.time_mlp.1.bias', 'unets.0.downs.1.3.1.cross_attn.fn.null_kv', 'unets.0.downs.1.3.1.cross_attn.fn.norm.gamma', 'unets.0.downs.1.3.1.cross_attn.fn.norm.beta', 'unets.0.downs.1.3.1.cross_attn.fn.to_q.weight', 'unets.0.downs.1.3.1.cross_attn.fn.to_kv.weight', 'unets.0.downs.1.3.1.cross_attn.fn.to_out.0.weight', 'unets.0.downs.1.3.1.cross_attn.fn.to_out.1.gamma', 'unets.0.downs.1.3.1.cross_attn.fn.to_out.1.beta', 'unets.0.downs.1.3.1.block1.project.weight', 'unets.0.downs.1.3.1.block1.project.bias', 'unets.0.downs.1.3.1.block1.norm.weight', 'unets.0.downs.1.3.1.block1.norm.bias', 'unets.0.downs.1.3.1.block2.project.weight', 'unets.0.downs.1.3.1.block2.project.bias', 'unets.0.downs.1.3.1.block2.norm.weight', 'unets.0.downs.1.3.1.block2.norm.bias', 'unets.0.downs.1.3.2.time_mlp.1.weight', 'unets.0.downs.1.3.2.time_mlp.1.bias', 'unets.0.downs.1.3.2.cross_attn.fn.null_kv', 'unets.0.downs.1.3.2.cross_attn.fn.norm.gamma', 'unets.0.downs.1.3.2.cross_attn.fn.norm.beta', 'unets.0.downs.1.3.2.cross_attn.fn.to_q.weight', 'unets.0.downs.1.3.2.cross_attn.fn.to_kv.weight', 'unets.0.downs.1.3.2.cross_attn.fn.to_out.0.weight', 'unets.0.downs.1.3.2.cross_attn.fn.to_out.1.gamma', 'unets.0.downs.1.3.2.cross_attn.fn.to_out.1.beta', 'unets.0.downs.1.3.2.block1.project.weight', 'unets.0.downs.1.3.2.block1.project.bias', 'unets.0.downs.1.3.2.block1.norm.weight', 'unets.0.downs.1.3.2.block1.norm.bias', 'unets.0.downs.1.3.2.block2.project.weight', 'unets.0.downs.1.3.2.block2.project.bias', 'unets.0.downs.1.3.2.block2.norm.weight', 'unets.0.downs.1.3.2.block2.norm.bias', 'unets.0.downs.1.3.3.time_mlp.1.weight', 'unets.0.downs.1.3.3.time_mlp.1.bias', 'unets.0.downs.1.3.3.cross_attn.fn.null_kv', 'unets.0.downs.1.3.3.cross_attn.fn.norm.gamma', 'unets.0.downs.1.3.3.cross_attn.fn.norm.beta', 'unets.0.downs.1.3.3.cross_attn.fn.to_q.weight', 'unets.0.downs.1.3.3.cross_attn.fn.to_kv.weight', 'unets.0.downs.1.3.3.cross_attn.fn.to_out.0.weight', 'unets.0.downs.1.3.3.cross_attn.fn.to_out.1.gamma', 'unets.0.downs.1.3.3.cross_attn.fn.to_out.1.beta', 'unets.0.downs.1.3.3.block1.project.weight', 'unets.0.downs.1.3.3.block1.project.bias', 'unets.0.downs.1.3.3.block1.norm.weight', 'unets.0.downs.1.3.3.block1.norm.bias', 'unets.0.downs.1.3.3.block2.project.weight', 'unets.0.downs.1.3.3.block2.project.bias', 'unets.0.downs.1.3.3.block2.norm.weight', 'unets.0.downs.1.3.3.block2.norm.bias', 'unets.0.downs.1.4.weight', 'unets.0.downs.1.4.bias', 'unets.0.downs.2.1.time_mlp.1.weight', 'unets.0.downs.2.1.time_mlp.1.bias', 'unets.0.downs.2.1.block1.project.weight', 'unets.0.downs.2.1.block1.project.bias', 'unets.0.downs.2.1.block1.norm.weight', 'unets.0.downs.2.1.block1.norm.bias', 'unets.0.downs.2.1.block2.project.weight', 'unets.0.downs.2.1.block2.project.bias', 'unets.0.downs.2.1.block2.norm.weight', 'unets.0.downs.2.1.block2.norm.bias', 'unets.0.downs.2.1.res_conv.weight', 'unets.0.downs.2.1.res_conv.bias', 'unets.0.downs.2.2.fn.norm.g', 'unets.0.downs.2.2.fn.to_qkv.weight', 'unets.0.downs.2.2.fn.to_out.0.weight', 'unets.0.downs.2.2.fn.to_out.1.g', 'unets.0.downs.2.3.0.time_mlp.1.weight', 'unets.0.downs.2.3.0.time_mlp.1.bias', 'unets.0.downs.2.3.0.cross_attn.fn.null_kv', 'unets.0.downs.2.3.0.cross_attn.fn.norm.gamma', 'unets.0.downs.2.3.0.cross_attn.fn.norm.beta', 'unets.0.downs.2.3.0.cross_attn.fn.to_q.weight', 'unets.0.downs.2.3.0.cross_attn.fn.to_kv.weight', 'unets.0.downs.2.3.0.cross_attn.fn.to_out.0.weight', 'unets.0.downs.2.3.0.cross_attn.fn.to_out.1.gamma', 'unets.0.downs.2.3.0.cross_attn.fn.to_out.1.beta', 'unets.0.downs.2.3.0.block1.project.weight', 'unets.0.downs.2.3.0.block1.project.bias', 'unets.0.downs.2.3.0.block1.norm.weight', 'unets.0.downs.2.3.0.block1.norm.bias', 'unets.0.downs.2.3.0.block2.project.weight', 'unets.0.downs.2.3.0.block2.project.bias', 'unets.0.downs.2.3.0.block2.norm.weight', 'unets.0.downs.2.3.0.block2.norm.bias', 'unets.0.downs.2.3.1.time_mlp.1.weight', 'unets.0.downs.2.3.1.time_mlp.1.bias', 'unets.0.downs.2.3.1.cross_attn.fn.null_kv', 'unets.0.downs.2.3.1.cross_attn.fn.norm.gamma', 'unets.0.downs.2.3.1.cross_attn.fn.norm.beta', 'unets.0.downs.2.3.1.cross_attn.fn.to_q.weight', 'unets.0.downs.2.3.1.cross_attn.fn.to_kv.weight', 'unets.0.downs.2.3.1.cross_attn.fn.to_out.0.weight', 'unets.0.downs.2.3.1.cross_attn.fn.to_out.1.gamma', 'unets.0.downs.2.3.1.cross_attn.fn.to_out.1.beta', 'unets.0.downs.2.3.1.block1.project.weight', 'unets.0.downs.2.3.1.block1.project.bias', 'unets.0.downs.2.3.1.block1.norm.weight', 'unets.0.downs.2.3.1.block1.norm.bias', 'unets.0.downs.2.3.1.block2.project.weight', 'unets.0.downs.2.3.1.block2.project.bias', 'unets.0.downs.2.3.1.block2.norm.weight', 'unets.0.downs.2.3.1.block2.norm.bias', 'unets.0.downs.2.3.2.time_mlp.1.weight', 'unets.0.downs.2.3.2.time_mlp.1.bias', 'unets.0.downs.2.3.2.cross_attn.fn.null_kv', 'unets.0.downs.2.3.2.cross_attn.fn.norm.gamma', 'unets.0.downs.2.3.2.cross_attn.fn.norm.beta', 'unets.0.downs.2.3.2.cross_attn.fn.to_q.weight', 'unets.0.downs.2.3.2.cross_attn.fn.to_kv.weight', 'unets.0.downs.2.3.2.cross_attn.fn.to_out.0.weight', 'unets.0.downs.2.3.2.cross_attn.fn.to_out.1.gamma', 'unets.0.downs.2.3.2.cross_attn.fn.to_out.1.beta', 'unets.0.downs.2.3.2.block1.project.weight', 'unets.0.downs.2.3.2.block1.project.bias', 'unets.0.downs.2.3.2.block1.norm.weight', 'unets.0.downs.2.3.2.block1.norm.bias', 'unets.0.downs.2.3.2.block2.project.weight', 'unets.0.downs.2.3.2.block2.project.bias', 'unets.0.downs.2.3.2.block2.norm.weight', 'unets.0.downs.2.3.2.block2.norm.bias', 'unets.0.downs.2.3.3.time_mlp.1.weight', 'unets.0.downs.2.3.3.time_mlp.1.bias', 'unets.0.downs.2.3.3.cross_attn.fn.null_kv', 'unets.0.downs.2.3.3.cross_attn.fn.norm.gamma', 'unets.0.downs.2.3.3.cross_attn.fn.norm.beta', 'unets.0.downs.2.3.3.cross_attn.fn.to_q.weight', 'unets.0.downs.2.3.3.cross_attn.fn.to_kv.weight', 'unets.0.downs.2.3.3.cross_attn.fn.to_out.0.weight', 'unets.0.downs.2.3.3.cross_attn.fn.to_out.1.gamma', 'unets.0.downs.2.3.3.cross_attn.fn.to_out.1.beta', 'unets.0.downs.2.3.3.block1.project.weight', 'unets.0.downs.2.3.3.block1.project.bias', 'unets.0.downs.2.3.3.block1.norm.weight', 'unets.0.downs.2.3.3.block1.norm.bias', 'unets.0.downs.2.3.3.block2.project.weight', 'unets.0.downs.2.3.3.block2.project.bias', 'unets.0.downs.2.3.3.block2.norm.weight', 'unets.0.downs.2.3.3.block2.norm.bias', 'unets.0.downs.2.4.weight', 'unets.0.downs.2.4.bias', 'unets.0.downs.3.1.time_mlp.1.weight', 'unets.0.downs.3.1.time_mlp.1.bias', 'unets.0.downs.3.1.block1.project.weight', 'unets.0.downs.3.1.block1.project.bias', 'unets.0.downs.3.1.block1.norm.weight', 'unets.0.downs.3.1.block1.norm.bias', 'unets.0.downs.3.1.block2.project.weight', 'unets.0.downs.3.1.block2.project.bias', 'unets.0.downs.3.1.block2.norm.weight', 'unets.0.downs.3.1.block2.norm.bias', 'unets.0.downs.3.1.res_conv.weight', 'unets.0.downs.3.1.res_conv.bias', 'unets.0.downs.3.2.fn.norm.g', 'unets.0.downs.3.2.fn.to_qkv.weight', 'unets.0.downs.3.2.fn.to_out.0.weight', 'unets.0.downs.3.2.fn.to_out.1.g', 'unets.0.downs.3.3.0.time_mlp.1.weight', 'unets.0.downs.3.3.0.time_mlp.1.bias', 'unets.0.downs.3.3.0.cross_attn.fn.null_kv', 'unets.0.downs.3.3.0.cross_attn.fn.norm.gamma', 'unets.0.downs.3.3.0.cross_attn.fn.norm.beta', 'unets.0.downs.3.3.0.cross_attn.fn.to_q.weight', 'unets.0.downs.3.3.0.cross_attn.fn.to_kv.weight', 'unets.0.downs.3.3.0.cross_attn.fn.to_out.0.weight', 'unets.0.downs.3.3.0.cross_attn.fn.to_out.1.gamma', 'unets.0.downs.3.3.0.cross_attn.fn.to_out.1.beta', 'unets.0.downs.3.3.0.block1.project.weight', 'unets.0.downs.3.3.0.block1.project.bias', 'unets.0.downs.3.3.0.block1.norm.weight', 'unets.0.downs.3.3.0.block1.norm.bias', 'unets.0.downs.3.3.0.block2.project.weight', 'unets.0.downs.3.3.0.block2.project.bias', 'unets.0.downs.3.3.0.block2.norm.weight', 'unets.0.downs.3.3.0.block2.norm.bias', 'unets.0.downs.3.3.1.time_mlp.1.weight', 'unets.0.downs.3.3.1.time_mlp.1.bias', 'unets.0.downs.3.3.1.cross_attn.fn.null_kv', 'unets.0.downs.3.3.1.cross_attn.fn.norm.gamma', 'unets.0.downs.3.3.1.cross_attn.fn.norm.beta', 'unets.0.downs.3.3.1.cross_attn.fn.to_q.weight', 'unets.0.downs.3.3.1.cross_attn.fn.to_kv.weight', 'unets.0.downs.3.3.1.cross_attn.fn.to_out.0.weight', 'unets.0.downs.3.3.1.cross_attn.fn.to_out.1.gamma', 'unets.0.downs.3.3.1.cross_attn.fn.to_out.1.beta', 'unets.0.downs.3.3.1.block1.project.weight', 'unets.0.downs.3.3.1.block1.project.bias', 'unets.0.downs.3.3.1.block1.norm.weight', 'unets.0.downs.3.3.1.block1.norm.bias', 'unets.0.downs.3.3.1.block2.project.weight', 'unets.0.downs.3.3.1.block2.project.bias', 'unets.0.downs.3.3.1.block2.norm.weight', 'unets.0.downs.3.3.1.block2.norm.bias', 'unets.0.downs.3.3.2.time_mlp.1.weight', 'unets.0.downs.3.3.2.time_mlp.1.bias', 'unets.0.downs.3.3.2.cross_attn.fn.null_kv', 'unets.0.downs.3.3.2.cross_attn.fn.norm.gamma', 'unets.0.downs.3.3.2.cross_attn.fn.norm.beta', 'unets.0.downs.3.3.2.cross_attn.fn.to_q.weight', 'unets.0.downs.3.3.2.cross_attn.fn.to_kv.weight', 'unets.0.downs.3.3.2.cross_attn.fn.to_out.0.weight', 'unets.0.downs.3.3.2.cross_attn.fn.to_out.1.gamma', 'unets.0.downs.3.3.2.cross_attn.fn.to_out.1.beta', 'unets.0.downs.3.3.2.block1.project.weight', 'unets.0.downs.3.3.2.block1.project.bias', 'unets.0.downs.3.3.2.block1.norm.weight', 'unets.0.downs.3.3.2.block1.norm.bias', 'unets.0.downs.3.3.2.block2.project.weight', 'unets.0.downs.3.3.2.block2.project.bias', 'unets.0.downs.3.3.2.block2.norm.weight', 'unets.0.downs.3.3.2.block2.norm.bias', 'unets.0.downs.3.3.3.time_mlp.1.weight', 'unets.0.downs.3.3.3.time_mlp.1.bias', 'unets.0.downs.3.3.3.cross_attn.fn.null_kv', 'unets.0.downs.3.3.3.cross_attn.fn.norm.gamma', 'unets.0.downs.3.3.3.cross_attn.fn.norm.beta', 'unets.0.downs.3.3.3.cross_attn.fn.to_q.weight', 'unets.0.downs.3.3.3.cross_attn.fn.to_kv.weight', 'unets.0.downs.3.3.3.cross_attn.fn.to_out.0.weight', 'unets.0.downs.3.3.3.cross_attn.fn.to_out.1.gamma', 'unets.0.downs.3.3.3.cross_attn.fn.to_out.1.beta', 'unets.0.downs.3.3.3.block1.project.weight', 'unets.0.downs.3.3.3.block1.project.bias', 'unets.0.downs.3.3.3.block1.norm.weight', 'unets.0.downs.3.3.3.block1.norm.bias', 'unets.0.downs.3.3.3.block2.project.weight', 'unets.0.downs.3.3.3.block2.project.bias', 'unets.0.downs.3.3.3.block2.norm.weight', 'unets.0.downs.3.3.3.block2.norm.bias', 'unets.0.ups.0.0.time_mlp.1.weight', 'unets.0.ups.0.0.time_mlp.1.bias', 'unets.0.ups.0.0.cross_attn.fn.null_kv', 'unets.0.ups.0.0.cross_attn.fn.norm.gamma', 'unets.0.ups.0.0.cross_attn.fn.norm.beta', 'unets.0.ups.0.0.cross_attn.fn.to_q.weight', 'unets.0.ups.0.0.cross_attn.fn.to_kv.weight', 'unets.0.ups.0.0.cross_attn.fn.to_out.0.weight', 'unets.0.ups.0.0.cross_attn.fn.to_out.1.gamma', 'unets.0.ups.0.0.cross_attn.fn.to_out.1.beta', 'unets.0.ups.0.0.block1.project.weight', 'unets.0.ups.0.0.block1.project.bias', 'unets.0.ups.0.0.block1.norm.weight', 'unets.0.ups.0.0.block1.norm.bias', 'unets.0.ups.0.0.block2.project.weight', 'unets.0.ups.0.0.block2.project.bias', 'unets.0.ups.0.0.block2.norm.weight', 'unets.0.ups.0.0.block2.norm.bias', 'unets.0.ups.0.0.res_conv.weight', 'unets.0.ups.0.0.res_conv.bias', 'unets.0.ups.0.1.fn.norm.g', 'unets.0.ups.0.1.fn.to_qkv.weight', 'unets.0.ups.0.1.fn.to_out.0.weight', 'unets.0.ups.0.1.fn.to_out.1.g', 'unets.0.ups.0.2.0.time_mlp.1.weight', 'unets.0.ups.0.2.0.time_mlp.1.bias', 'unets.0.ups.0.2.0.cross_attn.fn.null_kv', 'unets.0.ups.0.2.0.cross_attn.fn.norm.gamma', 'unets.0.ups.0.2.0.cross_attn.fn.norm.beta', 'unets.0.ups.0.2.0.cross_attn.fn.to_q.weight', 'unets.0.ups.0.2.0.cross_attn.fn.to_kv.weight', 'unets.0.ups.0.2.0.cross_attn.fn.to_out.0.weight', 'unets.0.ups.0.2.0.cross_attn.fn.to_out.1.gamma', 'unets.0.ups.0.2.0.cross_attn.fn.to_out.1.beta', 'unets.0.ups.0.2.0.block1.project.weight', 'unets.0.ups.0.2.0.block1.project.bias', 'unets.0.ups.0.2.0.block1.norm.weight', 'unets.0.ups.0.2.0.block1.norm.bias', 'unets.0.ups.0.2.0.block2.project.weight', 'unets.0.ups.0.2.0.block2.project.bias', 'unets.0.ups.0.2.0.block2.norm.weight', 'unets.0.ups.0.2.0.block2.norm.bias', 'unets.0.ups.0.2.1.time_mlp.1.weight', 'unets.0.ups.0.2.1.time_mlp.1.bias', 'unets.0.ups.0.2.1.cross_attn.fn.null_kv', 'unets.0.ups.0.2.1.cross_attn.fn.norm.gamma', 'unets.0.ups.0.2.1.cross_attn.fn.norm.beta', 'unets.0.ups.0.2.1.cross_attn.fn.to_q.weight', 'unets.0.ups.0.2.1.cross_attn.fn.to_kv.weight', 'unets.0.ups.0.2.1.cross_attn.fn.to_out.0.weight', 'unets.0.ups.0.2.1.cross_attn.fn.to_out.1.gamma', 'unets.0.ups.0.2.1.cross_attn.fn.to_out.1.beta', 'unets.0.ups.0.2.1.block1.project.weight', 'unets.0.ups.0.2.1.block1.project.bias', 'unets.0.ups.0.2.1.block1.norm.weight', 'unets.0.ups.0.2.1.block1.norm.bias', 'unets.0.ups.0.2.1.block2.project.weight', 'unets.0.ups.0.2.1.block2.project.bias', 'unets.0.ups.0.2.1.block2.norm.weight', 'unets.0.ups.0.2.1.block2.norm.bias', 'unets.0.ups.0.2.2.time_mlp.1.weight', 'unets.0.ups.0.2.2.time_mlp.1.bias', 'unets.0.ups.0.2.2.cross_attn.fn.null_kv', 'unets.0.ups.0.2.2.cross_attn.fn.norm.gamma', 'unets.0.ups.0.2.2.cross_attn.fn.norm.beta', 'unets.0.ups.0.2.2.cross_attn.fn.to_q.weight', 'unets.0.ups.0.2.2.cross_attn.fn.to_kv.weight', 'unets.0.ups.0.2.2.cross_attn.fn.to_out.0.weight', 'unets.0.ups.0.2.2.cross_attn.fn.to_out.1.gamma', 'unets.0.ups.0.2.2.cross_attn.fn.to_out.1.beta', 'unets.0.ups.0.2.2.block1.project.weight', 'unets.0.ups.0.2.2.block1.project.bias', 'unets.0.ups.0.2.2.block1.norm.weight', 'unets.0.ups.0.2.2.block1.norm.bias', 'unets.0.ups.0.2.2.block2.project.weight', 'unets.0.ups.0.2.2.block2.project.bias', 'unets.0.ups.0.2.2.block2.norm.weight', 'unets.0.ups.0.2.2.block2.norm.bias', 'unets.0.ups.0.2.3.time_mlp.1.weight', 'unets.0.ups.0.2.3.time_mlp.1.bias', 'unets.0.ups.0.2.3.cross_attn.fn.null_kv', 'unets.0.ups.0.2.3.cross_attn.fn.norm.gamma', 'unets.0.ups.0.2.3.cross_attn.fn.norm.beta', 'unets.0.ups.0.2.3.cross_attn.fn.to_q.weight', 'unets.0.ups.0.2.3.cross_attn.fn.to_kv.weight', 'unets.0.ups.0.2.3.cross_attn.fn.to_out.0.weight', 'unets.0.ups.0.2.3.cross_attn.fn.to_out.1.gamma', 'unets.0.ups.0.2.3.cross_attn.fn.to_out.1.beta', 'unets.0.ups.0.2.3.block1.project.weight', 'unets.0.ups.0.2.3.block1.project.bias', 'unets.0.ups.0.2.3.block1.norm.weight', 'unets.0.ups.0.2.3.block1.norm.bias', 'unets.0.ups.0.2.3.block2.project.weight', 'unets.0.ups.0.2.3.block2.project.bias', 'unets.0.ups.0.2.3.block2.norm.weight', 'unets.0.ups.0.2.3.block2.norm.bias', 'unets.0.ups.0.3.weight', 'unets.0.ups.0.3.bias', 'unets.0.ups.1.0.time_mlp.1.weight', 'unets.0.ups.1.0.time_mlp.1.bias', 'unets.0.ups.1.0.cross_attn.fn.null_kv', 'unets.0.ups.1.0.cross_attn.fn.norm.gamma', 'unets.0.ups.1.0.cross_attn.fn.norm.beta', 'unets.0.ups.1.0.cross_attn.fn.to_q.weight', 'unets.0.ups.1.0.cross_attn.fn.to_kv.weight', 'unets.0.ups.1.0.cross_attn.fn.to_out.0.weight', 'unets.0.ups.1.0.cross_attn.fn.to_out.1.gamma', 'unets.0.ups.1.0.cross_attn.fn.to_out.1.beta', 'unets.0.ups.1.0.block1.project.weight', 'unets.0.ups.1.0.block1.project.bias', 'unets.0.ups.1.0.block1.norm.weight', 'unets.0.ups.1.0.block1.norm.bias', 'unets.0.ups.1.0.block2.project.weight', 'unets.0.ups.1.0.block2.project.bias', 'unets.0.ups.1.0.block2.norm.weight', 'unets.0.ups.1.0.block2.norm.bias', 'unets.0.ups.1.0.res_conv.weight', 'unets.0.ups.1.0.res_conv.bias', 'unets.0.ups.1.1.fn.norm.g', 'unets.0.ups.1.1.fn.to_qkv.weight', 'unets.0.ups.1.1.fn.to_out.0.weight', 'unets.0.ups.1.1.fn.to_out.1.g', 'unets.0.ups.1.2.0.time_mlp.1.weight', 'unets.0.ups.1.2.0.time_mlp.1.bias', 'unets.0.ups.1.2.0.cross_attn.fn.null_kv', 'unets.0.ups.1.2.0.cross_attn.fn.norm.gamma', 'unets.0.ups.1.2.0.cross_attn.fn.norm.beta', 'unets.0.ups.1.2.0.cross_attn.fn.to_q.weight', 'unets.0.ups.1.2.0.cross_attn.fn.to_kv.weight', 'unets.0.ups.1.2.0.cross_attn.fn.to_out.0.weight', 'unets.0.ups.1.2.0.cross_attn.fn.to_out.1.gamma', 'unets.0.ups.1.2.0.cross_attn.fn.to_out.1.beta', 'unets.0.ups.1.2.0.block1.project.weight', 'unets.0.ups.1.2.0.block1.project.bias', 'unets.0.ups.1.2.0.block1.norm.weight', 'unets.0.ups.1.2.0.block1.norm.bias', 'unets.0.ups.1.2.0.block2.project.weight', 'unets.0.ups.1.2.0.block2.project.bias', 'unets.0.ups.1.2.0.block2.norm.weight', 'unets.0.ups.1.2.0.block2.norm.bias', 'unets.0.ups.1.2.1.time_mlp.1.weight', 'unets.0.ups.1.2.1.time_mlp.1.bias', 'unets.0.ups.1.2.1.cross_attn.fn.null_kv', 'unets.0.ups.1.2.1.cross_attn.fn.norm.gamma', 'unets.0.ups.1.2.1.cross_attn.fn.norm.beta', 'unets.0.ups.1.2.1.cross_attn.fn.to_q.weight', 'unets.0.ups.1.2.1.cross_attn.fn.to_kv.weight', 'unets.0.ups.1.2.1.cross_attn.fn.to_out.0.weight', 'unets.0.ups.1.2.1.cross_attn.fn.to_out.1.gamma', 'unets.0.ups.1.2.1.cross_attn.fn.to_out.1.beta', 'unets.0.ups.1.2.1.block1.project.weight', 'unets.0.ups.1.2.1.block1.project.bias', 'unets.0.ups.1.2.1.block1.norm.weight', 'unets.0.ups.1.2.1.block1.norm.bias', 'unets.0.ups.1.2.1.block2.project.weight', 'unets.0.ups.1.2.1.block2.project.bias', 'unets.0.ups.1.2.1.block2.norm.weight', 'unets.0.ups.1.2.1.block2.norm.bias', 'unets.0.ups.1.2.2.time_mlp.1.weight', 'unets.0.ups.1.2.2.time_mlp.1.bias', 'unets.0.ups.1.2.2.cross_attn.fn.null_kv', 'unets.0.ups.1.2.2.cross_attn.fn.norm.gamma', 'unets.0.ups.1.2.2.cross_attn.fn.norm.beta', 'unets.0.ups.1.2.2.cross_attn.fn.to_q.weight', 'unets.0.ups.1.2.2.cross_attn.fn.to_kv.weight', 'unets.0.ups.1.2.2.cross_attn.fn.to_out.0.weight', 'unets.0.ups.1.2.2.cross_attn.fn.to_out.1.gamma', 'unets.0.ups.1.2.2.cross_attn.fn.to_out.1.beta', 'unets.0.ups.1.2.2.block1.project.weight', 'unets.0.ups.1.2.2.block1.project.bias', 'unets.0.ups.1.2.2.block1.norm.weight', 'unets.0.ups.1.2.2.block1.norm.bias', 'unets.0.ups.1.2.2.block2.project.weight', 'unets.0.ups.1.2.2.block2.project.bias', 'unets.0.ups.1.2.2.block2.norm.weight', 'unets.0.ups.1.2.2.block2.norm.bias', 'unets.0.ups.1.2.3.time_mlp.1.weight', 'unets.0.ups.1.2.3.time_mlp.1.bias', 'unets.0.ups.1.2.3.cross_attn.fn.null_kv', 'unets.0.ups.1.2.3.cross_attn.fn.norm.gamma', 'unets.0.ups.1.2.3.cross_attn.fn.norm.beta', 'unets.0.ups.1.2.3.cross_attn.fn.to_q.weight', 'unets.0.ups.1.2.3.cross_attn.fn.to_kv.weight', 'unets.0.ups.1.2.3.cross_attn.fn.to_out.0.weight', 'unets.0.ups.1.2.3.cross_attn.fn.to_out.1.gamma', 'unets.0.ups.1.2.3.cross_attn.fn.to_out.1.beta', 'unets.0.ups.1.2.3.block1.project.weight', 'unets.0.ups.1.2.3.block1.project.bias', 'unets.0.ups.1.2.3.block1.norm.weight', 'unets.0.ups.1.2.3.block1.norm.bias', 'unets.0.ups.1.2.3.block2.project.weight', 'unets.0.ups.1.2.3.block2.project.bias', 'unets.0.ups.1.2.3.block2.norm.weight', 'unets.0.ups.1.2.3.block2.norm.bias', 'unets.0.ups.1.3.weight', 'unets.0.ups.1.3.bias', 'unets.0.ups.2.0.time_mlp.1.weight', 'unets.0.ups.2.0.time_mlp.1.bias', 'unets.0.ups.2.0.cross_attn.fn.null_kv', 'unets.0.ups.2.0.cross_attn.fn.norm.gamma', 'unets.0.ups.2.0.cross_attn.fn.norm.beta', 'unets.0.ups.2.0.cross_attn.fn.to_q.weight', 'unets.0.ups.2.0.cross_attn.fn.to_kv.weight', 'unets.0.ups.2.0.cross_attn.fn.to_out.0.weight', 'unets.0.ups.2.0.cross_attn.fn.to_out.1.gamma', 'unets.0.ups.2.0.cross_attn.fn.to_out.1.beta', 'unets.0.ups.2.0.block1.project.weight', 'unets.0.ups.2.0.block1.project.bias', 'unets.0.ups.2.0.block1.norm.weight', 'unets.0.ups.2.0.block1.norm.bias', 'unets.0.ups.2.0.block2.project.weight', 'unets.0.ups.2.0.block2.project.bias', 'unets.0.ups.2.0.block2.norm.weight', 'unets.0.ups.2.0.block2.norm.bias', 'unets.0.ups.2.0.res_conv.weight', 'unets.0.ups.2.0.res_conv.bias', 'unets.0.ups.2.1.fn.norm.g', 'unets.0.ups.2.1.fn.to_qkv.weight', 'unets.0.ups.2.1.fn.to_out.0.weight', 'unets.0.ups.2.1.fn.to_out.1.g', 'unets.0.ups.2.2.0.time_mlp.1.weight', 'unets.0.ups.2.2.0.time_mlp.1.bias', 'unets.0.ups.2.2.0.cross_attn.fn.null_kv', 'unets.0.ups.2.2.0.cross_attn.fn.norm.gamma', 'unets.0.ups.2.2.0.cross_attn.fn.norm.beta', 'unets.0.ups.2.2.0.cross_attn.fn.to_q.weight', 'unets.0.ups.2.2.0.cross_attn.fn.to_kv.weight', 'unets.0.ups.2.2.0.cross_attn.fn.to_out.0.weight', 'unets.0.ups.2.2.0.cross_attn.fn.to_out.1.gamma', 'unets.0.ups.2.2.0.cross_attn.fn.to_out.1.beta', 'unets.0.ups.2.2.0.block1.project.weight', 'unets.0.ups.2.2.0.block1.project.bias', 'unets.0.ups.2.2.0.block1.norm.weight', 'unets.0.ups.2.2.0.block1.norm.bias', 'unets.0.ups.2.2.0.block2.project.weight', 'unets.0.ups.2.2.0.block2.project.bias', 'unets.0.ups.2.2.0.block2.norm.weight', 'unets.0.ups.2.2.0.block2.norm.bias', 'unets.0.ups.2.2.1.time_mlp.1.weight', 'unets.0.ups.2.2.1.time_mlp.1.bias', 'unets.0.ups.2.2.1.cross_attn.fn.null_kv', 'unets.0.ups.2.2.1.cross_attn.fn.norm.gamma', 'unets.0.ups.2.2.1.cross_attn.fn.norm.beta', 'unets.0.ups.2.2.1.cross_attn.fn.to_q.weight', 'unets.0.ups.2.2.1.cross_attn.fn.to_kv.weight', 'unets.0.ups.2.2.1.cross_attn.fn.to_out.0.weight', 'unets.0.ups.2.2.1.cross_attn.fn.to_out.1.gamma', 'unets.0.ups.2.2.1.cross_attn.fn.to_out.1.beta', 'unets.0.ups.2.2.1.block1.project.weight', 'unets.0.ups.2.2.1.block1.project.bias', 'unets.0.ups.2.2.1.block1.norm.weight', 'unets.0.ups.2.2.1.block1.norm.bias', 'unets.0.ups.2.2.1.block2.project.weight', 'unets.0.ups.2.2.1.block2.project.bias', 'unets.0.ups.2.2.1.block2.norm.weight', 'unets.0.ups.2.2.1.block2.norm.bias', 'unets.0.ups.2.2.2.time_mlp.1.weight', 'unets.0.ups.2.2.2.time_mlp.1.bias', 'unets.0.ups.2.2.2.cross_attn.fn.null_kv', 'unets.0.ups.2.2.2.cross_attn.fn.norm.gamma', 'unets.0.ups.2.2.2.cross_attn.fn.norm.beta', 'unets.0.ups.2.2.2.cross_attn.fn.to_q.weight', 'unets.0.ups.2.2.2.cross_attn.fn.to_kv.weight', 'unets.0.ups.2.2.2.cross_attn.fn.to_out.0.weight', 'unets.0.ups.2.2.2.cross_attn.fn.to_out.1.gamma', 'unets.0.ups.2.2.2.cross_attn.fn.to_out.1.beta', 'unets.0.ups.2.2.2.block1.project.weight', 'unets.0.ups.2.2.2.block1.project.bias', 'unets.0.ups.2.2.2.block1.norm.weight', 'unets.0.ups.2.2.2.block1.norm.bias', 'unets.0.ups.2.2.2.block2.project.weight', 'unets.0.ups.2.2.2.block2.project.bias', 'unets.0.ups.2.2.2.block2.norm.weight', 'unets.0.ups.2.2.2.block2.norm.bias', 'unets.0.ups.2.2.3.time_mlp.1.weight', 'unets.0.ups.2.2.3.time_mlp.1.bias', 'unets.0.ups.2.2.3.cross_attn.fn.null_kv', 'unets.0.ups.2.2.3.cross_attn.fn.norm.gamma', 'unets.0.ups.2.2.3.cross_attn.fn.norm.beta', 'unets.0.ups.2.2.3.cross_attn.fn.to_q.weight', 'unets.0.ups.2.2.3.cross_attn.fn.to_kv.weight', 'unets.0.ups.2.2.3.cross_attn.fn.to_out.0.weight', 'unets.0.ups.2.2.3.cross_attn.fn.to_out.1.gamma', 'unets.0.ups.2.2.3.cross_attn.fn.to_out.1.beta', 'unets.0.ups.2.2.3.block1.project.weight', 'unets.0.ups.2.2.3.block1.project.bias', 'unets.0.ups.2.2.3.block1.norm.weight', 'unets.0.ups.2.2.3.block1.norm.bias', 'unets.0.ups.2.2.3.block2.project.weight', 'unets.0.ups.2.2.3.block2.project.bias', 'unets.0.ups.2.2.3.block2.norm.weight', 'unets.0.ups.2.2.3.block2.norm.bias', 'unets.0.ups.2.3.weight', 'unets.0.ups.2.3.bias', 'unets.0.ups.3.0.time_mlp.1.weight', 'unets.0.ups.3.0.time_mlp.1.bias', 'unets.0.ups.3.0.block1.project.weight', 'unets.0.ups.3.0.block1.project.bias', 'unets.0.ups.3.0.block1.norm.weight', 'unets.0.ups.3.0.block1.norm.bias', 'unets.0.ups.3.0.block2.project.weight', 'unets.0.ups.3.0.block2.project.bias', 'unets.0.ups.3.0.block2.norm.weight', 'unets.0.ups.3.0.block2.norm.bias', 'unets.0.ups.3.0.res_conv.weight', 'unets.0.ups.3.0.res_conv.bias', 'unets.0.ups.3.1.fn.norm.g', 'unets.0.ups.3.1.fn.to_qkv.weight', 'unets.0.ups.3.1.fn.to_out.0.weight', 'unets.0.ups.3.1.fn.to_out.1.g', 'unets.0.ups.3.2.0.time_mlp.1.weight', 'unets.0.ups.3.2.0.time_mlp.1.bias', 'unets.0.ups.3.2.0.block1.project.weight', 'unets.0.ups.3.2.0.block1.project.bias', 'unets.0.ups.3.2.0.block1.norm.weight', 'unets.0.ups.3.2.0.block1.norm.bias', 'unets.0.ups.3.2.0.block2.project.weight', 'unets.0.ups.3.2.0.block2.project.bias', 'unets.0.ups.3.2.0.block2.norm.weight', 'unets.0.ups.3.2.0.block2.norm.bias', 'unets.0.ups.3.2.1.time_mlp.1.weight', 'unets.0.ups.3.2.1.time_mlp.1.bias', 'unets.0.ups.3.2.1.block1.project.weight', 'unets.0.ups.3.2.1.block1.project.bias', 'unets.0.ups.3.2.1.block1.norm.weight', 'unets.0.ups.3.2.1.block1.norm.bias', 'unets.0.ups.3.2.1.block2.project.weight', 'unets.0.ups.3.2.1.block2.project.bias', 'unets.0.ups.3.2.1.block2.norm.weight', 'unets.0.ups.3.2.1.block2.norm.bias', 'unets.0.ups.3.2.2.time_mlp.1.weight', 'unets.0.ups.3.2.2.time_mlp.1.bias', 'unets.0.ups.3.2.2.block1.project.weight', 'unets.0.ups.3.2.2.block1.project.bias', 'unets.0.ups.3.2.2.block1.norm.weight', 'unets.0.ups.3.2.2.block1.norm.bias', 'unets.0.ups.3.2.2.block2.project.weight', 'unets.0.ups.3.2.2.block2.project.bias', 'unets.0.ups.3.2.2.block2.norm.weight', 'unets.0.ups.3.2.2.block2.norm.bias', 'unets.0.ups.3.2.3.time_mlp.1.weight', 'unets.0.ups.3.2.3.time_mlp.1.bias', 'unets.0.ups.3.2.3.block1.project.weight', 'unets.0.ups.3.2.3.block1.project.bias', 'unets.0.ups.3.2.3.block1.norm.weight', 'unets.0.ups.3.2.3.block1.norm.bias', 'unets.0.ups.3.2.3.block2.project.weight', 'unets.0.ups.3.2.3.block2.project.bias', 'unets.0.ups.3.2.3.block2.norm.weight', 'unets.0.ups.3.2.3.block2.norm.bias', 'unets.0.mid_block1.time_mlp.1.weight', 'unets.0.mid_block1.time_mlp.1.bias', 'unets.0.mid_block1.cross_attn.fn.null_kv', 'unets.0.mid_block1.cross_attn.fn.norm.gamma', 'unets.0.mid_block1.cross_attn.fn.norm.beta', 'unets.0.mid_block1.cross_attn.fn.to_q.weight', 'unets.0.mid_block1.cross_attn.fn.to_kv.weight', 'unets.0.mid_block1.cross_attn.fn.to_out.0.weight', 'unets.0.mid_block1.cross_attn.fn.to_out.1.gamma', 'unets.0.mid_block1.cross_attn.fn.to_out.1.beta', 'unets.0.mid_block1.block1.project.weight', 'unets.0.mid_block1.block1.project.bias', 'unets.0.mid_block1.block1.norm.weight', 'unets.0.mid_block1.block1.norm.bias', 'unets.0.mid_block1.block2.project.weight', 'unets.0.mid_block1.block2.project.bias', 'unets.0.mid_block1.block2.norm.weight', 'unets.0.mid_block1.block2.norm.bias', 'unets.0.mid_attn.fn.fn.null_kv', 'unets.0.mid_attn.fn.fn.norm.gamma', 'unets.0.mid_attn.fn.fn.norm.beta', 'unets.0.mid_attn.fn.fn.to_q.weight', 'unets.0.mid_attn.fn.fn.to_kv.weight', 'unets.0.mid_attn.fn.fn.to_out.0.weight', 'unets.0.mid_attn.fn.fn.to_out.1.gamma', 'unets.0.mid_attn.fn.fn.to_out.1.beta', 'unets.0.mid_block2.time_mlp.1.weight', 'unets.0.mid_block2.time_mlp.1.bias', 'unets.0.mid_block2.cross_attn.fn.null_kv', 'unets.0.mid_block2.cross_attn.fn.norm.gamma', 'unets.0.mid_block2.cross_attn.fn.norm.beta', 'unets.0.mid_block2.cross_attn.fn.to_q.weight', 'unets.0.mid_block2.cross_attn.fn.to_kv.weight', 'unets.0.mid_block2.cross_attn.fn.to_out.0.weight', 'unets.0.mid_block2.cross_attn.fn.to_out.1.gamma', 'unets.0.mid_block2.cross_attn.fn.to_out.1.beta', 'unets.0.mid_block2.block1.project.weight', 'unets.0.mid_block2.block1.project.bias', 'unets.0.mid_block2.block1.norm.weight', 'unets.0.mid_block2.block1.norm.bias', 'unets.0.mid_block2.block2.project.weight', 'unets.0.mid_block2.block2.project.bias', 'unets.0.mid_block2.block2.norm.weight', 'unets.0.mid_block2.block2.norm.bias', 'unets.0.final_conv.0.block1.project.weight', 'unets.0.final_conv.0.block1.project.bias', 'unets.0.final_conv.0.block1.norm.weight', 'unets.0.final_conv.0.block1.norm.bias', 'unets.0.final_conv.0.block2.project.weight', 'unets.0.final_conv.0.block2.project.bias', 'unets.0.final_conv.0.block2.norm.weight', 'unets.0.final_conv.0.block2.norm.bias', 'unets.0.final_conv.0.res_conv.weight', 'unets.0.final_conv.0.res_conv.bias', 'unets.0.final_conv.1.weight', 'unets.0.final_conv.1.bias', 'noise_schedulers.0.betas', 'noise_schedulers.0.alphas_cumprod', 'noise_schedulers.0.alphas_cumprod_prev', 'noise_schedulers.0.sqrt_alphas_cumprod', 'noise_schedulers.0.sqrt_one_minus_alphas_cumprod', 'noise_schedulers.0.log_one_minus_alphas_cumprod', 'noise_schedulers.0.sqrt_recip_alphas_cumprod', 'noise_schedulers.0.sqrt_recipm1_alphas_cumprod', 'noise_schedulers.0.posterior_variance', 'noise_schedulers.0.posterior_log_variance_clipped', 'noise_schedulers.0.posterior_mean_coef1', 'noise_schedulers.0.posterior_mean_coef2', 'noise_schedulers.0.p2_loss_weight'])\n",
      "Decoder(\n",
      "  (clip): OpenAIClipAdapter(\n",
      "    (clip): CLIP(\n",
      "      (visual): VisionTransformer(\n",
      "        (conv1): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
      "        (ln_pre): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (transformer): Transformer(\n",
      "          (resblocks): Sequential(\n",
      "            (0): ResidualAttentionBlock(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Sequential(\n",
      "                (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (gelu): QuickGELU()\n",
      "                (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (1): ResidualAttentionBlock(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Sequential(\n",
      "                (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (gelu): QuickGELU()\n",
      "                (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (2): ResidualAttentionBlock(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Sequential(\n",
      "                (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (gelu): QuickGELU()\n",
      "                (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (3): ResidualAttentionBlock(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Sequential(\n",
      "                (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (gelu): QuickGELU()\n",
      "                (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (4): ResidualAttentionBlock(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Sequential(\n",
      "                (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (gelu): QuickGELU()\n",
      "                (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (5): ResidualAttentionBlock(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Sequential(\n",
      "                (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (gelu): QuickGELU()\n",
      "                (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (6): ResidualAttentionBlock(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Sequential(\n",
      "                (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (gelu): QuickGELU()\n",
      "                (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (7): ResidualAttentionBlock(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Sequential(\n",
      "                (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (gelu): QuickGELU()\n",
      "                (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (8): ResidualAttentionBlock(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Sequential(\n",
      "                (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (gelu): QuickGELU()\n",
      "                (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (9): ResidualAttentionBlock(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Sequential(\n",
      "                (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (gelu): QuickGELU()\n",
      "                (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (10): ResidualAttentionBlock(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Sequential(\n",
      "                (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (gelu): QuickGELU()\n",
      "                (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (11): ResidualAttentionBlock(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Sequential(\n",
      "                (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (gelu): QuickGELU()\n",
      "                (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (12): ResidualAttentionBlock(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Sequential(\n",
      "                (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (gelu): QuickGELU()\n",
      "                (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (13): ResidualAttentionBlock(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Sequential(\n",
      "                (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (gelu): QuickGELU()\n",
      "                (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (14): ResidualAttentionBlock(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Sequential(\n",
      "                (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (gelu): QuickGELU()\n",
      "                (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (15): ResidualAttentionBlock(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Sequential(\n",
      "                (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (gelu): QuickGELU()\n",
      "                (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (16): ResidualAttentionBlock(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Sequential(\n",
      "                (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (gelu): QuickGELU()\n",
      "                (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (17): ResidualAttentionBlock(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Sequential(\n",
      "                (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (gelu): QuickGELU()\n",
      "                (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (18): ResidualAttentionBlock(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Sequential(\n",
      "                (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (gelu): QuickGELU()\n",
      "                (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (19): ResidualAttentionBlock(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Sequential(\n",
      "                (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (gelu): QuickGELU()\n",
      "                (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (20): ResidualAttentionBlock(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Sequential(\n",
      "                (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (gelu): QuickGELU()\n",
      "                (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (21): ResidualAttentionBlock(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Sequential(\n",
      "                (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (gelu): QuickGELU()\n",
      "                (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (22): ResidualAttentionBlock(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Sequential(\n",
      "                (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (gelu): QuickGELU()\n",
      "                (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (23): ResidualAttentionBlock(\n",
      "              (attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Sequential(\n",
      "                (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (gelu): QuickGELU()\n",
      "                (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              )\n",
      "              (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (ln_post): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (transformer): Transformer(\n",
      "        (resblocks): Sequential(\n",
      "          (0): ResidualAttentionBlock(\n",
      "            (attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Sequential(\n",
      "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (gelu): QuickGELU()\n",
      "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            )\n",
      "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (1): ResidualAttentionBlock(\n",
      "            (attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Sequential(\n",
      "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (gelu): QuickGELU()\n",
      "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            )\n",
      "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (2): ResidualAttentionBlock(\n",
      "            (attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Sequential(\n",
      "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (gelu): QuickGELU()\n",
      "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            )\n",
      "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (3): ResidualAttentionBlock(\n",
      "            (attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Sequential(\n",
      "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (gelu): QuickGELU()\n",
      "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            )\n",
      "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (4): ResidualAttentionBlock(\n",
      "            (attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Sequential(\n",
      "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (gelu): QuickGELU()\n",
      "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            )\n",
      "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (5): ResidualAttentionBlock(\n",
      "            (attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Sequential(\n",
      "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (gelu): QuickGELU()\n",
      "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            )\n",
      "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (6): ResidualAttentionBlock(\n",
      "            (attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Sequential(\n",
      "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (gelu): QuickGELU()\n",
      "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            )\n",
      "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (7): ResidualAttentionBlock(\n",
      "            (attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Sequential(\n",
      "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (gelu): QuickGELU()\n",
      "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            )\n",
      "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (8): ResidualAttentionBlock(\n",
      "            (attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Sequential(\n",
      "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (gelu): QuickGELU()\n",
      "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            )\n",
      "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (9): ResidualAttentionBlock(\n",
      "            (attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Sequential(\n",
      "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (gelu): QuickGELU()\n",
      "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            )\n",
      "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (10): ResidualAttentionBlock(\n",
      "            (attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Sequential(\n",
      "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (gelu): QuickGELU()\n",
      "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            )\n",
      "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (11): ResidualAttentionBlock(\n",
      "            (attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Sequential(\n",
      "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (gelu): QuickGELU()\n",
      "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            )\n",
      "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (token_embedding): Embedding(49408, 768)\n",
      "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (clip_normalize): Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))\n",
      "  )\n",
      "  (unets): ModuleList(\n",
      "    (0): Unet(\n",
      "      (init_conv): CrossEmbedLayer(\n",
      "        (convs): ModuleList(\n",
      "          (0): Conv2d(3, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): Conv2d(3, 104, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "          (2): Conv2d(3, 104, kernel_size=(15, 15), stride=(1, 1), padding=(7, 7))\n",
      "        )\n",
      "      )\n",
      "      (to_time_hiddens): Sequential(\n",
      "        (0): SinusoidalPosEmb()\n",
      "        (1): Linear(in_features=416, out_features=1664, bias=True)\n",
      "        (2): GELU(approximate='none')\n",
      "      )\n",
      "      (to_time_tokens): Sequential(\n",
      "        (0): Linear(in_features=1664, out_features=1024, bias=True)\n",
      "        (1): Rearrange('b (r d) -> b r d', r=2)\n",
      "      )\n",
      "      (to_time_cond): Sequential(\n",
      "        (0): Linear(in_features=1664, out_features=1664, bias=True)\n",
      "      )\n",
      "      (image_to_tokens): Sequential(\n",
      "        (0): Linear(in_features=768, out_features=2048, bias=True)\n",
      "        (1): Rearrange('b (n d) -> b n d', n=4)\n",
      "      )\n",
      "      (to_image_hiddens): Sequential(\n",
      "        (0): Linear(in_features=768, out_features=1664, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "      )\n",
      "      (norm_cond): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm_mid_cond): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (text_to_cond): Linear(in_features=768, out_features=512, bias=True)\n",
      "      (init_resnet_block): ResnetBlock(\n",
      "        (time_mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=1664, out_features=832, bias=True)\n",
      "        )\n",
      "        (block1): Block(\n",
      "          (project): Conv2d(416, 416, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 416, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): Block(\n",
      "          (project): Conv2d(416, 416, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 416, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Identity()\n",
      "      )\n",
      "      (downs): ModuleList(\n",
      "        (0): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Rearrange('b c (h s1) (w s2) -> b (c s1 s2) h w', s1=2, s2=2)\n",
      "            (1): Conv2d(1664, 416, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1): ResnetBlock(\n",
      "            (time_mlp): Sequential(\n",
      "              (0): SiLU()\n",
      "              (1): Linear(in_features=1664, out_features=832, bias=True)\n",
      "            )\n",
      "            (block1): Block(\n",
      "              (project): Conv2d(416, 416, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (norm): GroupNorm(8, 416, eps=1e-05, affine=True)\n",
      "              (act): SiLU()\n",
      "            )\n",
      "            (block2): Block(\n",
      "              (project): Conv2d(416, 416, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (norm): GroupNorm(8, 416, eps=1e-05, affine=True)\n",
      "              (act): SiLU()\n",
      "            )\n",
      "            (res_conv): Identity()\n",
      "          )\n",
      "          (2): ModuleList(\n",
      "            (0-3): 4 x ResnetBlock(\n",
      "              (time_mlp): Sequential(\n",
      "                (0): SiLU()\n",
      "                (1): Linear(in_features=1664, out_features=832, bias=True)\n",
      "              )\n",
      "              (block1): Block(\n",
      "                (project): Conv2d(416, 416, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (norm): GroupNorm(8, 416, eps=1e-05, affine=True)\n",
      "                (act): SiLU()\n",
      "              )\n",
      "              (block2): Block(\n",
      "                (project): Conv2d(416, 416, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (norm): GroupNorm(8, 416, eps=1e-05, affine=True)\n",
      "                (act): SiLU()\n",
      "              )\n",
      "              (res_conv): Identity()\n",
      "            )\n",
      "          )\n",
      "          (3): Residual(\n",
      "            (fn): LinearAttention(\n",
      "              (norm): ChanLayerNorm()\n",
      "              (nonlin): GELU(approximate='none')\n",
      "              (to_qkv): Conv2d(416, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Conv2d(512, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (1): ChanLayerNorm()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (4): Conv2d(416, 416, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Rearrange('b c (h s1) (w s2) -> b (c s1 s2) h w', s1=2, s2=2)\n",
      "            (1): Conv2d(1664, 832, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1): ResnetBlock(\n",
      "            (time_mlp): Sequential(\n",
      "              (0): SiLU()\n",
      "              (1): Linear(in_features=1664, out_features=1664, bias=True)\n",
      "            )\n",
      "            (block1): Block(\n",
      "              (project): Conv2d(832, 832, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (norm): GroupNorm(8, 832, eps=1e-05, affine=True)\n",
      "              (act): SiLU()\n",
      "            )\n",
      "            (block2): Block(\n",
      "              (project): Conv2d(832, 832, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (norm): GroupNorm(8, 832, eps=1e-05, affine=True)\n",
      "              (act): SiLU()\n",
      "            )\n",
      "            (res_conv): Identity()\n",
      "          )\n",
      "          (2): ModuleList(\n",
      "            (0-3): 4 x ResnetBlock(\n",
      "              (time_mlp): Sequential(\n",
      "                (0): SiLU()\n",
      "                (1): Linear(in_features=1664, out_features=1664, bias=True)\n",
      "              )\n",
      "              (cross_attn): CrossAttention(\n",
      "                (norm): LayerNorm()\n",
      "                (norm_context): Identity()\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "                (to_q): Linear(in_features=832, out_features=512, bias=False)\n",
      "                (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
      "                (to_out): Sequential(\n",
      "                  (0): Linear(in_features=512, out_features=832, bias=False)\n",
      "                  (1): LayerNorm()\n",
      "                )\n",
      "              )\n",
      "              (block1): Block(\n",
      "                (project): Conv2d(832, 832, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (norm): GroupNorm(8, 832, eps=1e-05, affine=True)\n",
      "                (act): SiLU()\n",
      "              )\n",
      "              (block2): Block(\n",
      "                (project): Conv2d(832, 832, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (norm): GroupNorm(8, 832, eps=1e-05, affine=True)\n",
      "                (act): SiLU()\n",
      "              )\n",
      "              (res_conv): Identity()\n",
      "            )\n",
      "          )\n",
      "          (3): Residual(\n",
      "            (fn): LinearAttention(\n",
      "              (norm): ChanLayerNorm()\n",
      "              (nonlin): GELU(approximate='none')\n",
      "              (to_qkv): Conv2d(832, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Conv2d(512, 832, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (1): ChanLayerNorm()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (4): Conv2d(832, 832, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Rearrange('b c (h s1) (w s2) -> b (c s1 s2) h w', s1=2, s2=2)\n",
      "            (1): Conv2d(3328, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1): ResnetBlock(\n",
      "            (time_mlp): Sequential(\n",
      "              (0): SiLU()\n",
      "              (1): Linear(in_features=1664, out_features=2496, bias=True)\n",
      "            )\n",
      "            (block1): Block(\n",
      "              (project): Conv2d(1248, 1248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (norm): GroupNorm(8, 1248, eps=1e-05, affine=True)\n",
      "              (act): SiLU()\n",
      "            )\n",
      "            (block2): Block(\n",
      "              (project): Conv2d(1248, 1248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (norm): GroupNorm(8, 1248, eps=1e-05, affine=True)\n",
      "              (act): SiLU()\n",
      "            )\n",
      "            (res_conv): Identity()\n",
      "          )\n",
      "          (2): ModuleList(\n",
      "            (0-3): 4 x ResnetBlock(\n",
      "              (time_mlp): Sequential(\n",
      "                (0): SiLU()\n",
      "                (1): Linear(in_features=1664, out_features=2496, bias=True)\n",
      "              )\n",
      "              (cross_attn): CrossAttention(\n",
      "                (norm): LayerNorm()\n",
      "                (norm_context): Identity()\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "                (to_q): Linear(in_features=1248, out_features=512, bias=False)\n",
      "                (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
      "                (to_out): Sequential(\n",
      "                  (0): Linear(in_features=512, out_features=1248, bias=False)\n",
      "                  (1): LayerNorm()\n",
      "                )\n",
      "              )\n",
      "              (block1): Block(\n",
      "                (project): Conv2d(1248, 1248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (norm): GroupNorm(8, 1248, eps=1e-05, affine=True)\n",
      "                (act): SiLU()\n",
      "              )\n",
      "              (block2): Block(\n",
      "                (project): Conv2d(1248, 1248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (norm): GroupNorm(8, 1248, eps=1e-05, affine=True)\n",
      "                (act): SiLU()\n",
      "              )\n",
      "              (res_conv): Identity()\n",
      "            )\n",
      "          )\n",
      "          (3): Residual(\n",
      "            (fn): LinearAttention(\n",
      "              (norm): ChanLayerNorm()\n",
      "              (nonlin): GELU(approximate='none')\n",
      "              (to_qkv): Conv2d(1248, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Conv2d(512, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (1): ChanLayerNorm()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (4): Conv2d(1248, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (3): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Rearrange('b c (h s1) (w s2) -> b (c s1 s2) h w', s1=2, s2=2)\n",
      "            (1): Conv2d(4992, 1664, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1): ResnetBlock(\n",
      "            (time_mlp): Sequential(\n",
      "              (0): SiLU()\n",
      "              (1): Linear(in_features=1664, out_features=3328, bias=True)\n",
      "            )\n",
      "            (block1): Block(\n",
      "              (project): Conv2d(1664, 1664, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (norm): GroupNorm(8, 1664, eps=1e-05, affine=True)\n",
      "              (act): SiLU()\n",
      "            )\n",
      "            (block2): Block(\n",
      "              (project): Conv2d(1664, 1664, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (norm): GroupNorm(8, 1664, eps=1e-05, affine=True)\n",
      "              (act): SiLU()\n",
      "            )\n",
      "            (res_conv): Identity()\n",
      "          )\n",
      "          (2): ModuleList(\n",
      "            (0-3): 4 x ResnetBlock(\n",
      "              (time_mlp): Sequential(\n",
      "                (0): SiLU()\n",
      "                (1): Linear(in_features=1664, out_features=3328, bias=True)\n",
      "              )\n",
      "              (cross_attn): CrossAttention(\n",
      "                (norm): LayerNorm()\n",
      "                (norm_context): Identity()\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "                (to_q): Linear(in_features=1664, out_features=512, bias=False)\n",
      "                (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
      "                (to_out): Sequential(\n",
      "                  (0): Linear(in_features=512, out_features=1664, bias=False)\n",
      "                  (1): LayerNorm()\n",
      "                )\n",
      "              )\n",
      "              (block1): Block(\n",
      "                (project): Conv2d(1664, 1664, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (norm): GroupNorm(8, 1664, eps=1e-05, affine=True)\n",
      "                (act): SiLU()\n",
      "              )\n",
      "              (block2): Block(\n",
      "                (project): Conv2d(1664, 1664, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (norm): GroupNorm(8, 1664, eps=1e-05, affine=True)\n",
      "                (act): SiLU()\n",
      "              )\n",
      "              (res_conv): Identity()\n",
      "            )\n",
      "          )\n",
      "          (3): Residual(\n",
      "            (fn): LinearAttention(\n",
      "              (norm): ChanLayerNorm()\n",
      "              (nonlin): GELU(approximate='none')\n",
      "              (to_qkv): Conv2d(1664, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Conv2d(512, 1664, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (1): ChanLayerNorm()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (4): Conv2d(1664, 1664, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (ups): ModuleList(\n",
      "        (0): ModuleList(\n",
      "          (0): ResnetBlock(\n",
      "            (time_mlp): Sequential(\n",
      "              (0): SiLU()\n",
      "              (1): Linear(in_features=1664, out_features=3328, bias=True)\n",
      "            )\n",
      "            (cross_attn): CrossAttention(\n",
      "              (norm): LayerNorm()\n",
      "              (norm_context): Identity()\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (to_q): Linear(in_features=1664, out_features=512, bias=False)\n",
      "              (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=512, out_features=1664, bias=False)\n",
      "                (1): LayerNorm()\n",
      "              )\n",
      "            )\n",
      "            (block1): Block(\n",
      "              (project): Conv2d(3328, 1664, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (norm): GroupNorm(8, 1664, eps=1e-05, affine=True)\n",
      "              (act): SiLU()\n",
      "            )\n",
      "            (block2): Block(\n",
      "              (project): Conv2d(1664, 1664, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (norm): GroupNorm(8, 1664, eps=1e-05, affine=True)\n",
      "              (act): SiLU()\n",
      "            )\n",
      "            (res_conv): Conv2d(3328, 1664, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0-3): 4 x ResnetBlock(\n",
      "              (time_mlp): Sequential(\n",
      "                (0): SiLU()\n",
      "                (1): Linear(in_features=1664, out_features=3328, bias=True)\n",
      "              )\n",
      "              (cross_attn): CrossAttention(\n",
      "                (norm): LayerNorm()\n",
      "                (norm_context): Identity()\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "                (to_q): Linear(in_features=1664, out_features=512, bias=False)\n",
      "                (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
      "                (to_out): Sequential(\n",
      "                  (0): Linear(in_features=512, out_features=1664, bias=False)\n",
      "                  (1): LayerNorm()\n",
      "                )\n",
      "              )\n",
      "              (block1): Block(\n",
      "                (project): Conv2d(3328, 1664, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (norm): GroupNorm(8, 1664, eps=1e-05, affine=True)\n",
      "                (act): SiLU()\n",
      "              )\n",
      "              (block2): Block(\n",
      "                (project): Conv2d(1664, 1664, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (norm): GroupNorm(8, 1664, eps=1e-05, affine=True)\n",
      "                (act): SiLU()\n",
      "              )\n",
      "              (res_conv): Conv2d(3328, 1664, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (2): Residual(\n",
      "            (fn): LinearAttention(\n",
      "              (norm): ChanLayerNorm()\n",
      "              (nonlin): GELU(approximate='none')\n",
      "              (to_qkv): Conv2d(1664, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Conv2d(512, 1664, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (1): ChanLayerNorm()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): PixelShuffleUpsample(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(1664, 4992, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): SiLU()\n",
      "              (2): PixelShuffle(upscale_factor=2)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): ModuleList(\n",
      "          (0): ResnetBlock(\n",
      "            (time_mlp): Sequential(\n",
      "              (0): SiLU()\n",
      "              (1): Linear(in_features=1664, out_features=2496, bias=True)\n",
      "            )\n",
      "            (cross_attn): CrossAttention(\n",
      "              (norm): LayerNorm()\n",
      "              (norm_context): Identity()\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (to_q): Linear(in_features=1248, out_features=512, bias=False)\n",
      "              (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=512, out_features=1248, bias=False)\n",
      "                (1): LayerNorm()\n",
      "              )\n",
      "            )\n",
      "            (block1): Block(\n",
      "              (project): Conv2d(2496, 1248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (norm): GroupNorm(8, 1248, eps=1e-05, affine=True)\n",
      "              (act): SiLU()\n",
      "            )\n",
      "            (block2): Block(\n",
      "              (project): Conv2d(1248, 1248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (norm): GroupNorm(8, 1248, eps=1e-05, affine=True)\n",
      "              (act): SiLU()\n",
      "            )\n",
      "            (res_conv): Conv2d(2496, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0-3): 4 x ResnetBlock(\n",
      "              (time_mlp): Sequential(\n",
      "                (0): SiLU()\n",
      "                (1): Linear(in_features=1664, out_features=2496, bias=True)\n",
      "              )\n",
      "              (cross_attn): CrossAttention(\n",
      "                (norm): LayerNorm()\n",
      "                (norm_context): Identity()\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "                (to_q): Linear(in_features=1248, out_features=512, bias=False)\n",
      "                (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
      "                (to_out): Sequential(\n",
      "                  (0): Linear(in_features=512, out_features=1248, bias=False)\n",
      "                  (1): LayerNorm()\n",
      "                )\n",
      "              )\n",
      "              (block1): Block(\n",
      "                (project): Conv2d(2496, 1248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (norm): GroupNorm(8, 1248, eps=1e-05, affine=True)\n",
      "                (act): SiLU()\n",
      "              )\n",
      "              (block2): Block(\n",
      "                (project): Conv2d(1248, 1248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (norm): GroupNorm(8, 1248, eps=1e-05, affine=True)\n",
      "                (act): SiLU()\n",
      "              )\n",
      "              (res_conv): Conv2d(2496, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (2): Residual(\n",
      "            (fn): LinearAttention(\n",
      "              (norm): ChanLayerNorm()\n",
      "              (nonlin): GELU(approximate='none')\n",
      "              (to_qkv): Conv2d(1248, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Conv2d(512, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (1): ChanLayerNorm()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): PixelShuffleUpsample(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(1248, 3328, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): SiLU()\n",
      "              (2): PixelShuffle(upscale_factor=2)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): ModuleList(\n",
      "          (0): ResnetBlock(\n",
      "            (time_mlp): Sequential(\n",
      "              (0): SiLU()\n",
      "              (1): Linear(in_features=1664, out_features=1664, bias=True)\n",
      "            )\n",
      "            (cross_attn): CrossAttention(\n",
      "              (norm): LayerNorm()\n",
      "              (norm_context): Identity()\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (to_q): Linear(in_features=832, out_features=512, bias=False)\n",
      "              (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=512, out_features=832, bias=False)\n",
      "                (1): LayerNorm()\n",
      "              )\n",
      "            )\n",
      "            (block1): Block(\n",
      "              (project): Conv2d(1664, 832, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (norm): GroupNorm(8, 832, eps=1e-05, affine=True)\n",
      "              (act): SiLU()\n",
      "            )\n",
      "            (block2): Block(\n",
      "              (project): Conv2d(832, 832, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (norm): GroupNorm(8, 832, eps=1e-05, affine=True)\n",
      "              (act): SiLU()\n",
      "            )\n",
      "            (res_conv): Conv2d(1664, 832, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0-3): 4 x ResnetBlock(\n",
      "              (time_mlp): Sequential(\n",
      "                (0): SiLU()\n",
      "                (1): Linear(in_features=1664, out_features=1664, bias=True)\n",
      "              )\n",
      "              (cross_attn): CrossAttention(\n",
      "                (norm): LayerNorm()\n",
      "                (norm_context): Identity()\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "                (to_q): Linear(in_features=832, out_features=512, bias=False)\n",
      "                (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
      "                (to_out): Sequential(\n",
      "                  (0): Linear(in_features=512, out_features=832, bias=False)\n",
      "                  (1): LayerNorm()\n",
      "                )\n",
      "              )\n",
      "              (block1): Block(\n",
      "                (project): Conv2d(1664, 832, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (norm): GroupNorm(8, 832, eps=1e-05, affine=True)\n",
      "                (act): SiLU()\n",
      "              )\n",
      "              (block2): Block(\n",
      "                (project): Conv2d(832, 832, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (norm): GroupNorm(8, 832, eps=1e-05, affine=True)\n",
      "                (act): SiLU()\n",
      "              )\n",
      "              (res_conv): Conv2d(1664, 832, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (2): Residual(\n",
      "            (fn): LinearAttention(\n",
      "              (norm): ChanLayerNorm()\n",
      "              (nonlin): GELU(approximate='none')\n",
      "              (to_qkv): Conv2d(832, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Conv2d(512, 832, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (1): ChanLayerNorm()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): PixelShuffleUpsample(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(832, 1664, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): SiLU()\n",
      "              (2): PixelShuffle(upscale_factor=2)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): ModuleList(\n",
      "          (0): ResnetBlock(\n",
      "            (time_mlp): Sequential(\n",
      "              (0): SiLU()\n",
      "              (1): Linear(in_features=1664, out_features=832, bias=True)\n",
      "            )\n",
      "            (block1): Block(\n",
      "              (project): Conv2d(832, 416, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (norm): GroupNorm(8, 416, eps=1e-05, affine=True)\n",
      "              (act): SiLU()\n",
      "            )\n",
      "            (block2): Block(\n",
      "              (project): Conv2d(416, 416, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (norm): GroupNorm(8, 416, eps=1e-05, affine=True)\n",
      "              (act): SiLU()\n",
      "            )\n",
      "            (res_conv): Conv2d(832, 416, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0-3): 4 x ResnetBlock(\n",
      "              (time_mlp): Sequential(\n",
      "                (0): SiLU()\n",
      "                (1): Linear(in_features=1664, out_features=832, bias=True)\n",
      "              )\n",
      "              (block1): Block(\n",
      "                (project): Conv2d(832, 416, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (norm): GroupNorm(8, 416, eps=1e-05, affine=True)\n",
      "                (act): SiLU()\n",
      "              )\n",
      "              (block2): Block(\n",
      "                (project): Conv2d(416, 416, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (norm): GroupNorm(8, 416, eps=1e-05, affine=True)\n",
      "                (act): SiLU()\n",
      "              )\n",
      "              (res_conv): Conv2d(832, 416, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (2): Residual(\n",
      "            (fn): LinearAttention(\n",
      "              (norm): ChanLayerNorm()\n",
      "              (nonlin): GELU(approximate='none')\n",
      "              (to_qkv): Conv2d(416, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (to_out): Sequential(\n",
      "                (0): Conv2d(512, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (1): ChanLayerNorm()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): PixelShuffleUpsample(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(416, 1664, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): SiLU()\n",
      "              (2): PixelShuffle(upscale_factor=2)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mid_block1): ResnetBlock(\n",
      "        (time_mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=1664, out_features=3328, bias=True)\n",
      "        )\n",
      "        (cross_attn): CrossAttention(\n",
      "          (norm): LayerNorm()\n",
      "          (norm_context): Identity()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (to_q): Linear(in_features=1664, out_features=512, bias=False)\n",
      "          (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=512, out_features=1664, bias=False)\n",
      "            (1): LayerNorm()\n",
      "          )\n",
      "        )\n",
      "        (block1): Block(\n",
      "          (project): Conv2d(1664, 1664, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 1664, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): Block(\n",
      "          (project): Conv2d(1664, 1664, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 1664, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Identity()\n",
      "      )\n",
      "      (mid_attn): RearrangeToSequence(\n",
      "        (fn): Residual(\n",
      "          (fn): Attention(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (to_q): Linear(in_features=1664, out_features=512, bias=False)\n",
      "            (to_kv): Linear(in_features=1664, out_features=128, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=512, out_features=1664, bias=False)\n",
      "              (1): LayerNorm()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mid_block2): ResnetBlock(\n",
      "        (time_mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=1664, out_features=3328, bias=True)\n",
      "        )\n",
      "        (cross_attn): CrossAttention(\n",
      "          (norm): LayerNorm()\n",
      "          (norm_context): Identity()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (to_q): Linear(in_features=1664, out_features=512, bias=False)\n",
      "          (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=512, out_features=1664, bias=False)\n",
      "            (1): LayerNorm()\n",
      "          )\n",
      "        )\n",
      "        (block1): Block(\n",
      "          (project): Conv2d(1664, 1664, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 1664, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): Block(\n",
      "          (project): Conv2d(1664, 1664, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 1664, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Identity()\n",
      "      )\n",
      "      (upsample_combiner): UpsampleCombiner()\n",
      "      (final_resnet_block): ResnetBlock(\n",
      "        (time_mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=1664, out_features=832, bias=True)\n",
      "        )\n",
      "        (block1): Block(\n",
      "          (project): Conv2d(832, 416, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 416, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): Block(\n",
      "          (project): Conv2d(416, 416, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 416, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Conv2d(832, 416, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (to_out): Conv2d(416, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (vaes): ModuleList(\n",
      "    (0): NullVQGanVAE()\n",
      "  )\n",
      "  (noise_schedulers): ModuleList(\n",
      "    (0): NoiseScheduler()\n",
      "  )\n",
      "  (lowres_conds): ModuleList(\n",
      "    (0): None\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(decoder_model_state.keys())\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Decoder:\n\tMissing key(s) in state_dict: \"clip.clip.positional_embedding\", \"clip.clip.text_projection\", \"clip.clip.logit_scale\", \"clip.clip.visual.class_embedding\", \"clip.clip.visual.positional_embedding\", \"clip.clip.visual.proj\", \"clip.clip.visual.conv1.weight\", \"clip.clip.visual.ln_pre.weight\", \"clip.clip.visual.ln_pre.bias\", \"clip.clip.visual.transformer.resblocks.0.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.0.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.0.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.0.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.0.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.0.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.0.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.0.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.0.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.0.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.0.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.0.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.1.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.1.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.1.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.1.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.1.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.1.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.1.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.1.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.1.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.1.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.1.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.1.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.2.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.2.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.2.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.2.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.2.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.2.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.2.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.2.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.2.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.2.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.2.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.2.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.3.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.3.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.3.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.3.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.3.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.3.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.3.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.3.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.3.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.3.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.3.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.3.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.4.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.4.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.4.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.4.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.4.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.4.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.4.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.4.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.4.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.4.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.4.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.4.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.5.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.5.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.5.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.5.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.5.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.5.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.5.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.5.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.5.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.5.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.5.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.5.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.6.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.6.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.6.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.6.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.6.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.6.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.6.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.6.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.6.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.6.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.6.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.6.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.7.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.7.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.7.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.7.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.7.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.7.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.7.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.7.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.7.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.7.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.7.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.7.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.8.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.8.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.8.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.8.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.8.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.8.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.8.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.8.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.8.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.8.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.8.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.8.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.9.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.9.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.9.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.9.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.9.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.9.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.9.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.9.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.9.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.9.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.9.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.9.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.10.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.10.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.10.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.10.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.10.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.10.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.10.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.10.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.10.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.10.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.10.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.10.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.11.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.11.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.11.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.11.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.11.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.11.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.11.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.11.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.11.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.11.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.11.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.11.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.12.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.12.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.12.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.12.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.12.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.12.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.12.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.12.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.12.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.12.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.12.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.12.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.13.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.13.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.13.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.13.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.13.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.13.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.13.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.13.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.13.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.13.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.13.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.13.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.14.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.14.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.14.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.14.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.14.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.14.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.14.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.14.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.14.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.14.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.14.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.14.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.15.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.15.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.15.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.15.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.15.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.15.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.15.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.15.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.15.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.15.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.15.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.15.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.16.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.16.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.16.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.16.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.16.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.16.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.16.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.16.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.16.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.16.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.16.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.16.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.17.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.17.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.17.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.17.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.17.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.17.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.17.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.17.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.17.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.17.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.17.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.17.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.18.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.18.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.18.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.18.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.18.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.18.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.18.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.18.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.18.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.18.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.18.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.18.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.19.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.19.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.19.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.19.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.19.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.19.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.19.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.19.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.19.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.19.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.19.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.19.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.20.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.20.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.20.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.20.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.20.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.20.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.20.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.20.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.20.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.20.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.20.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.20.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.21.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.21.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.21.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.21.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.21.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.21.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.21.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.21.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.21.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.21.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.21.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.21.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.22.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.22.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.22.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.22.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.22.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.22.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.22.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.22.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.22.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.22.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.22.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.22.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.23.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.23.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.23.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.23.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.23.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.23.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.23.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.23.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.23.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.23.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.23.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.23.ln_2.bias\", \"clip.clip.visual.ln_post.weight\", \"clip.clip.visual.ln_post.bias\", \"clip.clip.transformer.resblocks.0.attn.in_proj_weight\", \"clip.clip.transformer.resblocks.0.attn.in_proj_bias\", \"clip.clip.transformer.resblocks.0.attn.out_proj.weight\", \"clip.clip.transformer.resblocks.0.attn.out_proj.bias\", \"clip.clip.transformer.resblocks.0.ln_1.weight\", \"clip.clip.transformer.resblocks.0.ln_1.bias\", \"clip.clip.transformer.resblocks.0.mlp.c_fc.weight\", \"clip.clip.transformer.resblocks.0.mlp.c_fc.bias\", \"clip.clip.transformer.resblocks.0.mlp.c_proj.weight\", \"clip.clip.transformer.resblocks.0.mlp.c_proj.bias\", \"clip.clip.transformer.resblocks.0.ln_2.weight\", \"clip.clip.transformer.resblocks.0.ln_2.bias\", \"clip.clip.transformer.resblocks.1.attn.in_proj_weight\", \"clip.clip.transformer.resblocks.1.attn.in_proj_bias\", \"clip.clip.transformer.resblocks.1.attn.out_proj.weight\", \"clip.clip.transformer.resblocks.1.attn.out_proj.bias\", \"clip.clip.transformer.resblocks.1.ln_1.weight\", \"clip.clip.transformer.resblocks.1.ln_1.bias\", \"clip.clip.transformer.resblocks.1.mlp.c_fc.weight\", \"clip.clip.transformer.resblocks.1.mlp.c_fc.bias\", \"clip.clip.transformer.resblocks.1.mlp.c_proj.weight\", \"clip.clip.transformer.resblocks.1.mlp.c_proj.bias\", \"clip.clip.transformer.resblocks.1.ln_2.weight\", \"clip.clip.transformer.resblocks.1.ln_2.bias\", \"clip.clip.transformer.resblocks.2.attn.in_proj_weight\", \"clip.clip.transformer.resblocks.2.attn.in_proj_bias\", \"clip.clip.transformer.resblocks.2.attn.out_proj.weight\", \"clip.clip.transformer.resblocks.2.attn.out_proj.bias\", \"clip.clip.transformer.resblocks.2.ln_1.weight\", \"clip.clip.transformer.resblocks.2.ln_1.bias\", \"clip.clip.transformer.resblocks.2.mlp.c_fc.weight\", \"clip.clip.transformer.resblocks.2.mlp.c_fc.bias\", \"clip.clip.transformer.resblocks.2.mlp.c_proj.weight\", \"clip.clip.transformer.resblocks.2.mlp.c_proj.bias\", \"clip.clip.transformer.resblocks.2.ln_2.weight\", \"clip.clip.transformer.resblocks.2.ln_2.bias\", \"clip.clip.transformer.resblocks.3.attn.in_proj_weight\", \"clip.clip.transformer.resblocks.3.attn.in_proj_bias\", \"clip.clip.transformer.resblocks.3.attn.out_proj.weight\", \"clip.clip.transformer.resblocks.3.attn.out_proj.bias\", \"clip.clip.transformer.resblocks.3.ln_1.weight\", \"clip.clip.transformer.resblocks.3.ln_1.bias\", \"clip.clip.transformer.resblocks.3.mlp.c_fc.weight\", \"clip.clip.transformer.resblocks.3.mlp.c_fc.bias\", \"clip.clip.transformer.resblocks.3.mlp.c_proj.weight\", \"clip.clip.transformer.resblocks.3.mlp.c_proj.bias\", \"clip.clip.transformer.resblocks.3.ln_2.weight\", \"clip.clip.transformer.resblocks.3.ln_2.bias\", \"clip.clip.transformer.resblocks.4.attn.in_proj_weight\", \"clip.clip.transformer.resblocks.4.attn.in_proj_bias\", \"clip.clip.transformer.resblocks.4.attn.out_proj.weight\", \"clip.clip.transformer.resblocks.4.attn.out_proj.bias\", \"clip.clip.transformer.resblocks.4.ln_1.weight\", \"clip.clip.transformer.resblocks.4.ln_1.bias\", \"clip.clip.transformer.resblocks.4.mlp.c_fc.weight\", \"clip.clip.transformer.resblocks.4.mlp.c_fc.bias\", \"clip.clip.transformer.resblocks.4.mlp.c_proj.weight\", \"clip.clip.transformer.resblocks.4.mlp.c_proj.bias\", \"clip.clip.transformer.resblocks.4.ln_2.weight\", \"clip.clip.transformer.resblocks.4.ln_2.bias\", \"clip.clip.transformer.resblocks.5.attn.in_proj_weight\", \"clip.clip.transformer.resblocks.5.attn.in_proj_bias\", \"clip.clip.transformer.resblocks.5.attn.out_proj.weight\", \"clip.clip.transformer.resblocks.5.attn.out_proj.bias\", \"clip.clip.transformer.resblocks.5.ln_1.weight\", \"clip.clip.transformer.resblocks.5.ln_1.bias\", \"clip.clip.transformer.resblocks.5.mlp.c_fc.weight\", \"clip.clip.transformer.resblocks.5.mlp.c_fc.bias\", \"clip.clip.transformer.resblocks.5.mlp.c_proj.weight\", \"clip.clip.transformer.resblocks.5.mlp.c_proj.bias\", \"clip.clip.transformer.resblocks.5.ln_2.weight\", \"clip.clip.transformer.resblocks.5.ln_2.bias\", \"clip.clip.transformer.resblocks.6.attn.in_proj_weight\", \"clip.clip.transformer.resblocks.6.attn.in_proj_bias\", \"clip.clip.transformer.resblocks.6.attn.out_proj.weight\", \"clip.clip.transformer.resblocks.6.attn.out_proj.bias\", \"clip.clip.transformer.resblocks.6.ln_1.weight\", \"clip.clip.transformer.resblocks.6.ln_1.bias\", \"clip.clip.transformer.resblocks.6.mlp.c_fc.weight\", \"clip.clip.transformer.resblocks.6.mlp.c_fc.bias\", \"clip.clip.transformer.resblocks.6.mlp.c_proj.weight\", \"clip.clip.transformer.resblocks.6.mlp.c_proj.bias\", \"clip.clip.transformer.resblocks.6.ln_2.weight\", \"clip.clip.transformer.resblocks.6.ln_2.bias\", \"clip.clip.transformer.resblocks.7.attn.in_proj_weight\", \"clip.clip.transformer.resblocks.7.attn.in_proj_bias\", \"clip.clip.transformer.resblocks.7.attn.out_proj.weight\", \"clip.clip.transformer.resblocks.7.attn.out_proj.bias\", \"clip.clip.transformer.resblocks.7.ln_1.weight\", \"clip.clip.transformer.resblocks.7.ln_1.bias\", \"clip.clip.transformer.resblocks.7.mlp.c_fc.weight\", \"clip.clip.transformer.resblocks.7.mlp.c_fc.bias\", \"clip.clip.transformer.resblocks.7.mlp.c_proj.weight\", \"clip.clip.transformer.resblocks.7.mlp.c_proj.bias\", \"clip.clip.transformer.resblocks.7.ln_2.weight\", \"clip.clip.transformer.resblocks.7.ln_2.bias\", \"clip.clip.transformer.resblocks.8.attn.in_proj_weight\", \"clip.clip.transformer.resblocks.8.attn.in_proj_bias\", \"clip.clip.transformer.resblocks.8.attn.out_proj.weight\", \"clip.clip.transformer.resblocks.8.attn.out_proj.bias\", \"clip.clip.transformer.resblocks.8.ln_1.weight\", \"clip.clip.transformer.resblocks.8.ln_1.bias\", \"clip.clip.transformer.resblocks.8.mlp.c_fc.weight\", \"clip.clip.transformer.resblocks.8.mlp.c_fc.bias\", \"clip.clip.transformer.resblocks.8.mlp.c_proj.weight\", \"clip.clip.transformer.resblocks.8.mlp.c_proj.bias\", \"clip.clip.transformer.resblocks.8.ln_2.weight\", \"clip.clip.transformer.resblocks.8.ln_2.bias\", \"clip.clip.transformer.resblocks.9.attn.in_proj_weight\", \"clip.clip.transformer.resblocks.9.attn.in_proj_bias\", \"clip.clip.transformer.resblocks.9.attn.out_proj.weight\", \"clip.clip.transformer.resblocks.9.attn.out_proj.bias\", \"clip.clip.transformer.resblocks.9.ln_1.weight\", \"clip.clip.transformer.resblocks.9.ln_1.bias\", \"clip.clip.transformer.resblocks.9.mlp.c_fc.weight\", \"clip.clip.transformer.resblocks.9.mlp.c_fc.bias\", \"clip.clip.transformer.resblocks.9.mlp.c_proj.weight\", \"clip.clip.transformer.resblocks.9.mlp.c_proj.bias\", \"clip.clip.transformer.resblocks.9.ln_2.weight\", \"clip.clip.transformer.resblocks.9.ln_2.bias\", \"clip.clip.transformer.resblocks.10.attn.in_proj_weight\", \"clip.clip.transformer.resblocks.10.attn.in_proj_bias\", \"clip.clip.transformer.resblocks.10.attn.out_proj.weight\", \"clip.clip.transformer.resblocks.10.attn.out_proj.bias\", \"clip.clip.transformer.resblocks.10.ln_1.weight\", \"clip.clip.transformer.resblocks.10.ln_1.bias\", \"clip.clip.transformer.resblocks.10.mlp.c_fc.weight\", \"clip.clip.transformer.resblocks.10.mlp.c_fc.bias\", \"clip.clip.transformer.resblocks.10.mlp.c_proj.weight\", \"clip.clip.transformer.resblocks.10.mlp.c_proj.bias\", \"clip.clip.transformer.resblocks.10.ln_2.weight\", \"clip.clip.transformer.resblocks.10.ln_2.bias\", \"clip.clip.transformer.resblocks.11.attn.in_proj_weight\", \"clip.clip.transformer.resblocks.11.attn.in_proj_bias\", \"clip.clip.transformer.resblocks.11.attn.out_proj.weight\", \"clip.clip.transformer.resblocks.11.attn.out_proj.bias\", \"clip.clip.transformer.resblocks.11.ln_1.weight\", \"clip.clip.transformer.resblocks.11.ln_1.bias\", \"clip.clip.transformer.resblocks.11.mlp.c_fc.weight\", \"clip.clip.transformer.resblocks.11.mlp.c_fc.bias\", \"clip.clip.transformer.resblocks.11.mlp.c_proj.weight\", \"clip.clip.transformer.resblocks.11.mlp.c_proj.bias\", \"clip.clip.transformer.resblocks.11.ln_2.weight\", \"clip.clip.transformer.resblocks.11.ln_2.bias\", \"clip.clip.token_embedding.weight\", \"clip.clip.ln_final.weight\", \"clip.clip.ln_final.bias\", \"unets.0.text_to_cond.weight\", \"unets.0.text_to_cond.bias\", \"unets.0.init_resnet_block.time_mlp.1.weight\", \"unets.0.init_resnet_block.time_mlp.1.bias\", \"unets.0.init_resnet_block.block1.project.weight\", \"unets.0.init_resnet_block.block1.project.bias\", \"unets.0.init_resnet_block.block1.norm.weight\", \"unets.0.init_resnet_block.block1.norm.bias\", \"unets.0.init_resnet_block.block2.project.weight\", \"unets.0.init_resnet_block.block2.project.bias\", \"unets.0.init_resnet_block.block2.norm.weight\", \"unets.0.init_resnet_block.block2.norm.bias\", \"unets.0.downs.0.0.1.weight\", \"unets.0.downs.0.0.1.bias\", \"unets.0.downs.0.2.0.time_mlp.1.weight\", \"unets.0.downs.0.2.0.time_mlp.1.bias\", \"unets.0.downs.0.2.0.block1.project.weight\", \"unets.0.downs.0.2.0.block1.project.bias\", \"unets.0.downs.0.2.0.block1.norm.weight\", \"unets.0.downs.0.2.0.block1.norm.bias\", \"unets.0.downs.0.2.0.block2.project.weight\", \"unets.0.downs.0.2.0.block2.project.bias\", \"unets.0.downs.0.2.0.block2.norm.weight\", \"unets.0.downs.0.2.0.block2.norm.bias\", \"unets.0.downs.0.2.1.time_mlp.1.weight\", \"unets.0.downs.0.2.1.time_mlp.1.bias\", \"unets.0.downs.0.2.1.block1.project.weight\", \"unets.0.downs.0.2.1.block1.project.bias\", \"unets.0.downs.0.2.1.block1.norm.weight\", \"unets.0.downs.0.2.1.block1.norm.bias\", \"unets.0.downs.0.2.1.block2.project.weight\", \"unets.0.downs.0.2.1.block2.project.bias\", \"unets.0.downs.0.2.1.block2.norm.weight\", \"unets.0.downs.0.2.1.block2.norm.bias\", \"unets.0.downs.0.2.2.time_mlp.1.weight\", \"unets.0.downs.0.2.2.time_mlp.1.bias\", \"unets.0.downs.0.2.2.block1.project.weight\", \"unets.0.downs.0.2.2.block1.project.bias\", \"unets.0.downs.0.2.2.block1.norm.weight\", \"unets.0.downs.0.2.2.block1.norm.bias\", \"unets.0.downs.0.2.2.block2.project.weight\", \"unets.0.downs.0.2.2.block2.project.bias\", \"unets.0.downs.0.2.2.block2.norm.weight\", \"unets.0.downs.0.2.2.block2.norm.bias\", \"unets.0.downs.0.2.3.time_mlp.1.weight\", \"unets.0.downs.0.2.3.time_mlp.1.bias\", \"unets.0.downs.0.2.3.block1.project.weight\", \"unets.0.downs.0.2.3.block1.project.bias\", \"unets.0.downs.0.2.3.block1.norm.weight\", \"unets.0.downs.0.2.3.block1.norm.bias\", \"unets.0.downs.0.2.3.block2.project.weight\", \"unets.0.downs.0.2.3.block2.project.bias\", \"unets.0.downs.0.2.3.block2.norm.weight\", \"unets.0.downs.0.2.3.block2.norm.bias\", \"unets.0.downs.0.3.fn.norm.g\", \"unets.0.downs.0.3.fn.to_qkv.weight\", \"unets.0.downs.0.3.fn.to_out.0.weight\", \"unets.0.downs.0.3.fn.to_out.1.g\", \"unets.0.downs.1.0.1.weight\", \"unets.0.downs.1.0.1.bias\", \"unets.0.downs.1.2.0.time_mlp.1.weight\", \"unets.0.downs.1.2.0.time_mlp.1.bias\", \"unets.0.downs.1.2.0.cross_attn.null_kv\", \"unets.0.downs.1.2.0.cross_attn.norm.g\", \"unets.0.downs.1.2.0.cross_attn.to_q.weight\", \"unets.0.downs.1.2.0.cross_attn.to_kv.weight\", \"unets.0.downs.1.2.0.cross_attn.to_out.0.weight\", \"unets.0.downs.1.2.0.cross_attn.to_out.1.g\", \"unets.0.downs.1.2.0.block1.project.weight\", \"unets.0.downs.1.2.0.block1.project.bias\", \"unets.0.downs.1.2.0.block1.norm.weight\", \"unets.0.downs.1.2.0.block1.norm.bias\", \"unets.0.downs.1.2.0.block2.project.weight\", \"unets.0.downs.1.2.0.block2.project.bias\", \"unets.0.downs.1.2.0.block2.norm.weight\", \"unets.0.downs.1.2.0.block2.norm.bias\", \"unets.0.downs.1.2.1.time_mlp.1.weight\", \"unets.0.downs.1.2.1.time_mlp.1.bias\", \"unets.0.downs.1.2.1.cross_attn.null_kv\", \"unets.0.downs.1.2.1.cross_attn.norm.g\", \"unets.0.downs.1.2.1.cross_attn.to_q.weight\", \"unets.0.downs.1.2.1.cross_attn.to_kv.weight\", \"unets.0.downs.1.2.1.cross_attn.to_out.0.weight\", \"unets.0.downs.1.2.1.cross_attn.to_out.1.g\", \"unets.0.downs.1.2.1.block1.project.weight\", \"unets.0.downs.1.2.1.block1.project.bias\", \"unets.0.downs.1.2.1.block1.norm.weight\", \"unets.0.downs.1.2.1.block1.norm.bias\", \"unets.0.downs.1.2.1.block2.project.weight\", \"unets.0.downs.1.2.1.block2.project.bias\", \"unets.0.downs.1.2.1.block2.norm.weight\", \"unets.0.downs.1.2.1.block2.norm.bias\", \"unets.0.downs.1.2.2.time_mlp.1.weight\", \"unets.0.downs.1.2.2.time_mlp.1.bias\", \"unets.0.downs.1.2.2.cross_attn.null_kv\", \"unets.0.downs.1.2.2.cross_attn.norm.g\", \"unets.0.downs.1.2.2.cross_attn.to_q.weight\", \"unets.0.downs.1.2.2.cross_attn.to_kv.weight\", \"unets.0.downs.1.2.2.cross_attn.to_out.0.weight\", \"unets.0.downs.1.2.2.cross_attn.to_out.1.g\", \"unets.0.downs.1.2.2.block1.project.weight\", \"unets.0.downs.1.2.2.block1.project.bias\", \"unets.0.downs.1.2.2.block1.norm.weight\", \"unets.0.downs.1.2.2.block1.norm.bias\", \"unets.0.downs.1.2.2.block2.project.weight\", \"unets.0.downs.1.2.2.block2.project.bias\", \"unets.0.downs.1.2.2.block2.norm.weight\", \"unets.0.downs.1.2.2.block2.norm.bias\", \"unets.0.downs.1.2.3.time_mlp.1.weight\", \"unets.0.downs.1.2.3.time_mlp.1.bias\", \"unets.0.downs.1.2.3.cross_attn.null_kv\", \"unets.0.downs.1.2.3.cross_attn.norm.g\", \"unets.0.downs.1.2.3.cross_attn.to_q.weight\", \"unets.0.downs.1.2.3.cross_attn.to_kv.weight\", \"unets.0.downs.1.2.3.cross_attn.to_out.0.weight\", \"unets.0.downs.1.2.3.cross_attn.to_out.1.g\", \"unets.0.downs.1.2.3.block1.project.weight\", \"unets.0.downs.1.2.3.block1.project.bias\", \"unets.0.downs.1.2.3.block1.norm.weight\", \"unets.0.downs.1.2.3.block1.norm.bias\", \"unets.0.downs.1.2.3.block2.project.weight\", \"unets.0.downs.1.2.3.block2.project.bias\", \"unets.0.downs.1.2.3.block2.norm.weight\", \"unets.0.downs.1.2.3.block2.norm.bias\", \"unets.0.downs.1.3.fn.norm.g\", \"unets.0.downs.1.3.fn.to_qkv.weight\", \"unets.0.downs.1.3.fn.to_out.0.weight\", \"unets.0.downs.1.3.fn.to_out.1.g\", \"unets.0.downs.2.0.1.weight\", \"unets.0.downs.2.0.1.bias\", \"unets.0.downs.2.2.0.time_mlp.1.weight\", \"unets.0.downs.2.2.0.time_mlp.1.bias\", \"unets.0.downs.2.2.0.cross_attn.null_kv\", \"unets.0.downs.2.2.0.cross_attn.norm.g\", \"unets.0.downs.2.2.0.cross_attn.to_q.weight\", \"unets.0.downs.2.2.0.cross_attn.to_kv.weight\", \"unets.0.downs.2.2.0.cross_attn.to_out.0.weight\", \"unets.0.downs.2.2.0.cross_attn.to_out.1.g\", \"unets.0.downs.2.2.0.block1.project.weight\", \"unets.0.downs.2.2.0.block1.project.bias\", \"unets.0.downs.2.2.0.block1.norm.weight\", \"unets.0.downs.2.2.0.block1.norm.bias\", \"unets.0.downs.2.2.0.block2.project.weight\", \"unets.0.downs.2.2.0.block2.project.bias\", \"unets.0.downs.2.2.0.block2.norm.weight\", \"unets.0.downs.2.2.0.block2.norm.bias\", \"unets.0.downs.2.2.1.time_mlp.1.weight\", \"unets.0.downs.2.2.1.time_mlp.1.bias\", \"unets.0.downs.2.2.1.cross_attn.null_kv\", \"unets.0.downs.2.2.1.cross_attn.norm.g\", \"unets.0.downs.2.2.1.cross_attn.to_q.weight\", \"unets.0.downs.2.2.1.cross_attn.to_kv.weight\", \"unets.0.downs.2.2.1.cross_attn.to_out.0.weight\", \"unets.0.downs.2.2.1.cross_attn.to_out.1.g\", \"unets.0.downs.2.2.1.block1.project.weight\", \"unets.0.downs.2.2.1.block1.project.bias\", \"unets.0.downs.2.2.1.block1.norm.weight\", \"unets.0.downs.2.2.1.block1.norm.bias\", \"unets.0.downs.2.2.1.block2.project.weight\", \"unets.0.downs.2.2.1.block2.project.bias\", \"unets.0.downs.2.2.1.block2.norm.weight\", \"unets.0.downs.2.2.1.block2.norm.bias\", \"unets.0.downs.2.2.2.time_mlp.1.weight\", \"unets.0.downs.2.2.2.time_mlp.1.bias\", \"unets.0.downs.2.2.2.cross_attn.null_kv\", \"unets.0.downs.2.2.2.cross_attn.norm.g\", \"unets.0.downs.2.2.2.cross_attn.to_q.weight\", \"unets.0.downs.2.2.2.cross_attn.to_kv.weight\", \"unets.0.downs.2.2.2.cross_attn.to_out.0.weight\", \"unets.0.downs.2.2.2.cross_attn.to_out.1.g\", \"unets.0.downs.2.2.2.block1.project.weight\", \"unets.0.downs.2.2.2.block1.project.bias\", \"unets.0.downs.2.2.2.block1.norm.weight\", \"unets.0.downs.2.2.2.block1.norm.bias\", \"unets.0.downs.2.2.2.block2.project.weight\", \"unets.0.downs.2.2.2.block2.project.bias\", \"unets.0.downs.2.2.2.block2.norm.weight\", \"unets.0.downs.2.2.2.block2.norm.bias\", \"unets.0.downs.2.2.3.time_mlp.1.weight\", \"unets.0.downs.2.2.3.time_mlp.1.bias\", \"unets.0.downs.2.2.3.cross_attn.null_kv\", \"unets.0.downs.2.2.3.cross_attn.norm.g\", \"unets.0.downs.2.2.3.cross_attn.to_q.weight\", \"unets.0.downs.2.2.3.cross_attn.to_kv.weight\", \"unets.0.downs.2.2.3.cross_attn.to_out.0.weight\", \"unets.0.downs.2.2.3.cross_attn.to_out.1.g\", \"unets.0.downs.2.2.3.block1.project.weight\", \"unets.0.downs.2.2.3.block1.project.bias\", \"unets.0.downs.2.2.3.block1.norm.weight\", \"unets.0.downs.2.2.3.block1.norm.bias\", \"unets.0.downs.2.2.3.block2.project.weight\", \"unets.0.downs.2.2.3.block2.project.bias\", \"unets.0.downs.2.2.3.block2.norm.weight\", \"unets.0.downs.2.2.3.block2.norm.bias\", \"unets.0.downs.2.3.fn.norm.g\", \"unets.0.downs.2.3.fn.to_qkv.weight\", \"unets.0.downs.2.3.fn.to_out.0.weight\", \"unets.0.downs.2.3.fn.to_out.1.g\", \"unets.0.downs.3.0.1.weight\", \"unets.0.downs.3.0.1.bias\", \"unets.0.downs.3.2.0.time_mlp.1.weight\", \"unets.0.downs.3.2.0.time_mlp.1.bias\", \"unets.0.downs.3.2.0.cross_attn.null_kv\", \"unets.0.downs.3.2.0.cross_attn.norm.g\", \"unets.0.downs.3.2.0.cross_attn.to_q.weight\", \"unets.0.downs.3.2.0.cross_attn.to_kv.weight\", \"unets.0.downs.3.2.0.cross_attn.to_out.0.weight\", \"unets.0.downs.3.2.0.cross_attn.to_out.1.g\", \"unets.0.downs.3.2.0.block1.project.weight\", \"unets.0.downs.3.2.0.block1.project.bias\", \"unets.0.downs.3.2.0.block1.norm.weight\", \"unets.0.downs.3.2.0.block1.norm.bias\", \"unets.0.downs.3.2.0.block2.project.weight\", \"unets.0.downs.3.2.0.block2.project.bias\", \"unets.0.downs.3.2.0.block2.norm.weight\", \"unets.0.downs.3.2.0.block2.norm.bias\", \"unets.0.downs.3.2.1.time_mlp.1.weight\", \"unets.0.downs.3.2.1.time_mlp.1.bias\", \"unets.0.downs.3.2.1.cross_attn.null_kv\", \"unets.0.downs.3.2.1.cross_attn.norm.g\", \"unets.0.downs.3.2.1.cross_attn.to_q.weight\", \"unets.0.downs.3.2.1.cross_attn.to_kv.weight\", \"unets.0.downs.3.2.1.cross_attn.to_out.0.weight\", \"unets.0.downs.3.2.1.cross_attn.to_out.1.g\", \"unets.0.downs.3.2.1.block1.project.weight\", \"unets.0.downs.3.2.1.block1.project.bias\", \"unets.0.downs.3.2.1.block1.norm.weight\", \"unets.0.downs.3.2.1.block1.norm.bias\", \"unets.0.downs.3.2.1.block2.project.weight\", \"unets.0.downs.3.2.1.block2.project.bias\", \"unets.0.downs.3.2.1.block2.norm.weight\", \"unets.0.downs.3.2.1.block2.norm.bias\", \"unets.0.downs.3.2.2.time_mlp.1.weight\", \"unets.0.downs.3.2.2.time_mlp.1.bias\", \"unets.0.downs.3.2.2.cross_attn.null_kv\", \"unets.0.downs.3.2.2.cross_attn.norm.g\", \"unets.0.downs.3.2.2.cross_attn.to_q.weight\", \"unets.0.downs.3.2.2.cross_attn.to_kv.weight\", \"unets.0.downs.3.2.2.cross_attn.to_out.0.weight\", \"unets.0.downs.3.2.2.cross_attn.to_out.1.g\", \"unets.0.downs.3.2.2.block1.project.weight\", \"unets.0.downs.3.2.2.block1.project.bias\", \"unets.0.downs.3.2.2.block1.norm.weight\", \"unets.0.downs.3.2.2.block1.norm.bias\", \"unets.0.downs.3.2.2.block2.project.weight\", \"unets.0.downs.3.2.2.block2.project.bias\", \"unets.0.downs.3.2.2.block2.norm.weight\", \"unets.0.downs.3.2.2.block2.norm.bias\", \"unets.0.downs.3.2.3.time_mlp.1.weight\", \"unets.0.downs.3.2.3.time_mlp.1.bias\", \"unets.0.downs.3.2.3.cross_attn.null_kv\", \"unets.0.downs.3.2.3.cross_attn.norm.g\", \"unets.0.downs.3.2.3.cross_attn.to_q.weight\", \"unets.0.downs.3.2.3.cross_attn.to_kv.weight\", \"unets.0.downs.3.2.3.cross_attn.to_out.0.weight\", \"unets.0.downs.3.2.3.cross_attn.to_out.1.g\", \"unets.0.downs.3.2.3.block1.project.weight\", \"unets.0.downs.3.2.3.block1.project.bias\", \"unets.0.downs.3.2.3.block1.norm.weight\", \"unets.0.downs.3.2.3.block1.norm.bias\", \"unets.0.downs.3.2.3.block2.project.weight\", \"unets.0.downs.3.2.3.block2.project.bias\", \"unets.0.downs.3.2.3.block2.norm.weight\", \"unets.0.downs.3.2.3.block2.norm.bias\", \"unets.0.downs.3.3.fn.norm.g\", \"unets.0.downs.3.3.fn.to_qkv.weight\", \"unets.0.downs.3.3.fn.to_out.0.weight\", \"unets.0.downs.3.3.fn.to_out.1.g\", \"unets.0.downs.3.4.weight\", \"unets.0.downs.3.4.bias\", \"unets.0.ups.0.0.cross_attn.null_kv\", \"unets.0.ups.0.0.cross_attn.norm.g\", \"unets.0.ups.0.0.cross_attn.to_q.weight\", \"unets.0.ups.0.0.cross_attn.to_kv.weight\", \"unets.0.ups.0.0.cross_attn.to_out.0.weight\", \"unets.0.ups.0.0.cross_attn.to_out.1.g\", \"unets.0.ups.0.1.0.time_mlp.1.weight\", \"unets.0.ups.0.1.0.time_mlp.1.bias\", \"unets.0.ups.0.1.0.cross_attn.null_kv\", \"unets.0.ups.0.1.0.cross_attn.norm.g\", \"unets.0.ups.0.1.0.cross_attn.to_q.weight\", \"unets.0.ups.0.1.0.cross_attn.to_kv.weight\", \"unets.0.ups.0.1.0.cross_attn.to_out.0.weight\", \"unets.0.ups.0.1.0.cross_attn.to_out.1.g\", \"unets.0.ups.0.1.0.block1.project.weight\", \"unets.0.ups.0.1.0.block1.project.bias\", \"unets.0.ups.0.1.0.block1.norm.weight\", \"unets.0.ups.0.1.0.block1.norm.bias\", \"unets.0.ups.0.1.0.block2.project.weight\", \"unets.0.ups.0.1.0.block2.project.bias\", \"unets.0.ups.0.1.0.block2.norm.weight\", \"unets.0.ups.0.1.0.block2.norm.bias\", \"unets.0.ups.0.1.0.res_conv.weight\", \"unets.0.ups.0.1.0.res_conv.bias\", \"unets.0.ups.0.1.1.time_mlp.1.weight\", \"unets.0.ups.0.1.1.time_mlp.1.bias\", \"unets.0.ups.0.1.1.cross_attn.null_kv\", \"unets.0.ups.0.1.1.cross_attn.norm.g\", \"unets.0.ups.0.1.1.cross_attn.to_q.weight\", \"unets.0.ups.0.1.1.cross_attn.to_kv.weight\", \"unets.0.ups.0.1.1.cross_attn.to_out.0.weight\", \"unets.0.ups.0.1.1.cross_attn.to_out.1.g\", \"unets.0.ups.0.1.1.block1.project.weight\", \"unets.0.ups.0.1.1.block1.project.bias\", \"unets.0.ups.0.1.1.block1.norm.weight\", \"unets.0.ups.0.1.1.block1.norm.bias\", \"unets.0.ups.0.1.1.block2.project.weight\", \"unets.0.ups.0.1.1.block2.project.bias\", \"unets.0.ups.0.1.1.block2.norm.weight\", \"unets.0.ups.0.1.1.block2.norm.bias\", \"unets.0.ups.0.1.1.res_conv.weight\", \"unets.0.ups.0.1.1.res_conv.bias\", \"unets.0.ups.0.1.2.time_mlp.1.weight\", \"unets.0.ups.0.1.2.time_mlp.1.bias\", \"unets.0.ups.0.1.2.cross_attn.null_kv\", \"unets.0.ups.0.1.2.cross_attn.norm.g\", \"unets.0.ups.0.1.2.cross_attn.to_q.weight\", \"unets.0.ups.0.1.2.cross_attn.to_kv.weight\", \"unets.0.ups.0.1.2.cross_attn.to_out.0.weight\", \"unets.0.ups.0.1.2.cross_attn.to_out.1.g\", \"unets.0.ups.0.1.2.block1.project.weight\", \"unets.0.ups.0.1.2.block1.project.bias\", \"unets.0.ups.0.1.2.block1.norm.weight\", \"unets.0.ups.0.1.2.block1.norm.bias\", \"unets.0.ups.0.1.2.block2.project.weight\", \"unets.0.ups.0.1.2.block2.project.bias\", \"unets.0.ups.0.1.2.block2.norm.weight\", \"unets.0.ups.0.1.2.block2.norm.bias\", \"unets.0.ups.0.1.2.res_conv.weight\", \"unets.0.ups.0.1.2.res_conv.bias\", \"unets.0.ups.0.1.3.time_mlp.1.weight\", \"unets.0.ups.0.1.3.time_mlp.1.bias\", \"unets.0.ups.0.1.3.cross_attn.null_kv\", \"unets.0.ups.0.1.3.cross_attn.norm.g\", \"unets.0.ups.0.1.3.cross_attn.to_q.weight\", \"unets.0.ups.0.1.3.cross_attn.to_kv.weight\", \"unets.0.ups.0.1.3.cross_attn.to_out.0.weight\", \"unets.0.ups.0.1.3.cross_attn.to_out.1.g\", \"unets.0.ups.0.1.3.block1.project.weight\", \"unets.0.ups.0.1.3.block1.project.bias\", \"unets.0.ups.0.1.3.block1.norm.weight\", \"unets.0.ups.0.1.3.block1.norm.bias\", \"unets.0.ups.0.1.3.block2.project.weight\", \"unets.0.ups.0.1.3.block2.project.bias\", \"unets.0.ups.0.1.3.block2.norm.weight\", \"unets.0.ups.0.1.3.block2.norm.bias\", \"unets.0.ups.0.1.3.res_conv.weight\", \"unets.0.ups.0.1.3.res_conv.bias\", \"unets.0.ups.0.2.fn.norm.g\", \"unets.0.ups.0.2.fn.to_qkv.weight\", \"unets.0.ups.0.2.fn.to_out.0.weight\", \"unets.0.ups.0.2.fn.to_out.1.g\", \"unets.0.ups.0.3.net.0.weight\", \"unets.0.ups.0.3.net.0.bias\", \"unets.0.ups.1.0.cross_attn.null_kv\", \"unets.0.ups.1.0.cross_attn.norm.g\", \"unets.0.ups.1.0.cross_attn.to_q.weight\", \"unets.0.ups.1.0.cross_attn.to_kv.weight\", \"unets.0.ups.1.0.cross_attn.to_out.0.weight\", \"unets.0.ups.1.0.cross_attn.to_out.1.g\", \"unets.0.ups.1.1.0.time_mlp.1.weight\", \"unets.0.ups.1.1.0.time_mlp.1.bias\", \"unets.0.ups.1.1.0.cross_attn.null_kv\", \"unets.0.ups.1.1.0.cross_attn.norm.g\", \"unets.0.ups.1.1.0.cross_attn.to_q.weight\", \"unets.0.ups.1.1.0.cross_attn.to_kv.weight\", \"unets.0.ups.1.1.0.cross_attn.to_out.0.weight\", \"unets.0.ups.1.1.0.cross_attn.to_out.1.g\", \"unets.0.ups.1.1.0.block1.project.weight\", \"unets.0.ups.1.1.0.block1.project.bias\", \"unets.0.ups.1.1.0.block1.norm.weight\", \"unets.0.ups.1.1.0.block1.norm.bias\", \"unets.0.ups.1.1.0.block2.project.weight\", \"unets.0.ups.1.1.0.block2.project.bias\", \"unets.0.ups.1.1.0.block2.norm.weight\", \"unets.0.ups.1.1.0.block2.norm.bias\", \"unets.0.ups.1.1.0.res_conv.weight\", \"unets.0.ups.1.1.0.res_conv.bias\", \"unets.0.ups.1.1.1.time_mlp.1.weight\", \"unets.0.ups.1.1.1.time_mlp.1.bias\", \"unets.0.ups.1.1.1.cross_attn.null_kv\", \"unets.0.ups.1.1.1.cross_attn.norm.g\", \"unets.0.ups.1.1.1.cross_attn.to_q.weight\", \"unets.0.ups.1.1.1.cross_attn.to_kv.weight\", \"unets.0.ups.1.1.1.cross_attn.to_out.0.weight\", \"unets.0.ups.1.1.1.cross_attn.to_out.1.g\", \"unets.0.ups.1.1.1.block1.project.weight\", \"unets.0.ups.1.1.1.block1.project.bias\", \"unets.0.ups.1.1.1.block1.norm.weight\", \"unets.0.ups.1.1.1.block1.norm.bias\", \"unets.0.ups.1.1.1.block2.project.weight\", \"unets.0.ups.1.1.1.block2.project.bias\", \"unets.0.ups.1.1.1.block2.norm.weight\", \"unets.0.ups.1.1.1.block2.norm.bias\", \"unets.0.ups.1.1.1.res_conv.weight\", \"unets.0.ups.1.1.1.res_conv.bias\", \"unets.0.ups.1.1.2.time_mlp.1.weight\", \"unets.0.ups.1.1.2.time_mlp.1.bias\", \"unets.0.ups.1.1.2.cross_attn.null_kv\", \"unets.0.ups.1.1.2.cross_attn.norm.g\", \"unets.0.ups.1.1.2.cross_attn.to_q.weight\", \"unets.0.ups.1.1.2.cross_attn.to_kv.weight\", \"unets.0.ups.1.1.2.cross_attn.to_out.0.weight\", \"unets.0.ups.1.1.2.cross_attn.to_out.1.g\", \"unets.0.ups.1.1.2.block1.project.weight\", \"unets.0.ups.1.1.2.block1.project.bias\", \"unets.0.ups.1.1.2.block1.norm.weight\", \"unets.0.ups.1.1.2.block1.norm.bias\", \"unets.0.ups.1.1.2.block2.project.weight\", \"unets.0.ups.1.1.2.block2.project.bias\", \"unets.0.ups.1.1.2.block2.norm.weight\", \"unets.0.ups.1.1.2.block2.norm.bias\", \"unets.0.ups.1.1.2.res_conv.weight\", \"unets.0.ups.1.1.2.res_conv.bias\", \"unets.0.ups.1.1.3.time_mlp.1.weight\", \"unets.0.ups.1.1.3.time_mlp.1.bias\", \"unets.0.ups.1.1.3.cross_attn.null_kv\", \"unets.0.ups.1.1.3.cross_attn.norm.g\", \"unets.0.ups.1.1.3.cross_attn.to_q.weight\", \"unets.0.ups.1.1.3.cross_attn.to_kv.weight\", \"unets.0.ups.1.1.3.cross_attn.to_out.0.weight\", \"unets.0.ups.1.1.3.cross_attn.to_out.1.g\", \"unets.0.ups.1.1.3.block1.project.weight\", \"unets.0.ups.1.1.3.block1.project.bias\", \"unets.0.ups.1.1.3.block1.norm.weight\", \"unets.0.ups.1.1.3.block1.norm.bias\", \"unets.0.ups.1.1.3.block2.project.weight\", \"unets.0.ups.1.1.3.block2.project.bias\", \"unets.0.ups.1.1.3.block2.norm.weight\", \"unets.0.ups.1.1.3.block2.norm.bias\", \"unets.0.ups.1.1.3.res_conv.weight\", \"unets.0.ups.1.1.3.res_conv.bias\", \"unets.0.ups.1.2.fn.norm.g\", \"unets.0.ups.1.2.fn.to_qkv.weight\", \"unets.0.ups.1.2.fn.to_out.0.weight\", \"unets.0.ups.1.2.fn.to_out.1.g\", \"unets.0.ups.1.3.net.0.weight\", \"unets.0.ups.1.3.net.0.bias\", \"unets.0.ups.2.0.cross_attn.null_kv\", \"unets.0.ups.2.0.cross_attn.norm.g\", \"unets.0.ups.2.0.cross_attn.to_q.weight\", \"unets.0.ups.2.0.cross_attn.to_kv.weight\", \"unets.0.ups.2.0.cross_attn.to_out.0.weight\", \"unets.0.ups.2.0.cross_attn.to_out.1.g\", \"unets.0.ups.2.1.0.time_mlp.1.weight\", \"unets.0.ups.2.1.0.time_mlp.1.bias\", \"unets.0.ups.2.1.0.cross_attn.null_kv\", \"unets.0.ups.2.1.0.cross_attn.norm.g\", \"unets.0.ups.2.1.0.cross_attn.to_q.weight\", \"unets.0.ups.2.1.0.cross_attn.to_kv.weight\", \"unets.0.ups.2.1.0.cross_attn.to_out.0.weight\", \"unets.0.ups.2.1.0.cross_attn.to_out.1.g\", \"unets.0.ups.2.1.0.block1.project.weight\", \"unets.0.ups.2.1.0.block1.project.bias\", \"unets.0.ups.2.1.0.block1.norm.weight\", \"unets.0.ups.2.1.0.block1.norm.bias\", \"unets.0.ups.2.1.0.block2.project.weight\", \"unets.0.ups.2.1.0.block2.project.bias\", \"unets.0.ups.2.1.0.block2.norm.weight\", \"unets.0.ups.2.1.0.block2.norm.bias\", \"unets.0.ups.2.1.0.res_conv.weight\", \"unets.0.ups.2.1.0.res_conv.bias\", \"unets.0.ups.2.1.1.time_mlp.1.weight\", \"unets.0.ups.2.1.1.time_mlp.1.bias\", \"unets.0.ups.2.1.1.cross_attn.null_kv\", \"unets.0.ups.2.1.1.cross_attn.norm.g\", \"unets.0.ups.2.1.1.cross_attn.to_q.weight\", \"unets.0.ups.2.1.1.cross_attn.to_kv.weight\", \"unets.0.ups.2.1.1.cross_attn.to_out.0.weight\", \"unets.0.ups.2.1.1.cross_attn.to_out.1.g\", \"unets.0.ups.2.1.1.block1.project.weight\", \"unets.0.ups.2.1.1.block1.project.bias\", \"unets.0.ups.2.1.1.block1.norm.weight\", \"unets.0.ups.2.1.1.block1.norm.bias\", \"unets.0.ups.2.1.1.block2.project.weight\", \"unets.0.ups.2.1.1.block2.project.bias\", \"unets.0.ups.2.1.1.block2.norm.weight\", \"unets.0.ups.2.1.1.block2.norm.bias\", \"unets.0.ups.2.1.1.res_conv.weight\", \"unets.0.ups.2.1.1.res_conv.bias\", \"unets.0.ups.2.1.2.time_mlp.1.weight\", \"unets.0.ups.2.1.2.time_mlp.1.bias\", \"unets.0.ups.2.1.2.cross_attn.null_kv\", \"unets.0.ups.2.1.2.cross_attn.norm.g\", \"unets.0.ups.2.1.2.cross_attn.to_q.weight\", \"unets.0.ups.2.1.2.cross_attn.to_kv.weight\", \"unets.0.ups.2.1.2.cross_attn.to_out.0.weight\", \"unets.0.ups.2.1.2.cross_attn.to_out.1.g\", \"unets.0.ups.2.1.2.block1.project.weight\", \"unets.0.ups.2.1.2.block1.project.bias\", \"unets.0.ups.2.1.2.block1.norm.weight\", \"unets.0.ups.2.1.2.block1.norm.bias\", \"unets.0.ups.2.1.2.block2.project.weight\", \"unets.0.ups.2.1.2.block2.project.bias\", \"unets.0.ups.2.1.2.block2.norm.weight\", \"unets.0.ups.2.1.2.block2.norm.bias\", \"unets.0.ups.2.1.2.res_conv.weight\", \"unets.0.ups.2.1.2.res_conv.bias\", \"unets.0.ups.2.1.3.time_mlp.1.weight\", \"unets.0.ups.2.1.3.time_mlp.1.bias\", \"unets.0.ups.2.1.3.cross_attn.null_kv\", \"unets.0.ups.2.1.3.cross_attn.norm.g\", \"unets.0.ups.2.1.3.cross_attn.to_q.weight\", \"unets.0.ups.2.1.3.cross_attn.to_kv.weight\", \"unets.0.ups.2.1.3.cross_attn.to_out.0.weight\", \"unets.0.ups.2.1.3.cross_attn.to_out.1.g\", \"unets.0.ups.2.1.3.block1.project.weight\", \"unets.0.ups.2.1.3.block1.project.bias\", \"unets.0.ups.2.1.3.block1.norm.weight\", \"unets.0.ups.2.1.3.block1.norm.bias\", \"unets.0.ups.2.1.3.block2.project.weight\", \"unets.0.ups.2.1.3.block2.project.bias\", \"unets.0.ups.2.1.3.block2.norm.weight\", \"unets.0.ups.2.1.3.block2.norm.bias\", \"unets.0.ups.2.1.3.res_conv.weight\", \"unets.0.ups.2.1.3.res_conv.bias\", \"unets.0.ups.2.2.fn.norm.g\", \"unets.0.ups.2.2.fn.to_qkv.weight\", \"unets.0.ups.2.2.fn.to_out.0.weight\", \"unets.0.ups.2.2.fn.to_out.1.g\", \"unets.0.ups.2.3.net.0.weight\", \"unets.0.ups.2.3.net.0.bias\", \"unets.0.ups.3.1.0.time_mlp.1.weight\", \"unets.0.ups.3.1.0.time_mlp.1.bias\", \"unets.0.ups.3.1.0.block1.project.weight\", \"unets.0.ups.3.1.0.block1.project.bias\", \"unets.0.ups.3.1.0.block1.norm.weight\", \"unets.0.ups.3.1.0.block1.norm.bias\", \"unets.0.ups.3.1.0.block2.project.weight\", \"unets.0.ups.3.1.0.block2.project.bias\", \"unets.0.ups.3.1.0.block2.norm.weight\", \"unets.0.ups.3.1.0.block2.norm.bias\", \"unets.0.ups.3.1.0.res_conv.weight\", \"unets.0.ups.3.1.0.res_conv.bias\", \"unets.0.ups.3.1.1.time_mlp.1.weight\", \"unets.0.ups.3.1.1.time_mlp.1.bias\", \"unets.0.ups.3.1.1.block1.project.weight\", \"unets.0.ups.3.1.1.block1.project.bias\", \"unets.0.ups.3.1.1.block1.norm.weight\", \"unets.0.ups.3.1.1.block1.norm.bias\", \"unets.0.ups.3.1.1.block2.project.weight\", \"unets.0.ups.3.1.1.block2.project.bias\", \"unets.0.ups.3.1.1.block2.norm.weight\", \"unets.0.ups.3.1.1.block2.norm.bias\", \"unets.0.ups.3.1.1.res_conv.weight\", \"unets.0.ups.3.1.1.res_conv.bias\", \"unets.0.ups.3.1.2.time_mlp.1.weight\", \"unets.0.ups.3.1.2.time_mlp.1.bias\", \"unets.0.ups.3.1.2.block1.project.weight\", \"unets.0.ups.3.1.2.block1.project.bias\", \"unets.0.ups.3.1.2.block1.norm.weight\", \"unets.0.ups.3.1.2.block1.norm.bias\", \"unets.0.ups.3.1.2.block2.project.weight\", \"unets.0.ups.3.1.2.block2.project.bias\", \"unets.0.ups.3.1.2.block2.norm.weight\", \"unets.0.ups.3.1.2.block2.norm.bias\", \"unets.0.ups.3.1.2.res_conv.weight\", \"unets.0.ups.3.1.2.res_conv.bias\", \"unets.0.ups.3.1.3.time_mlp.1.weight\", \"unets.0.ups.3.1.3.time_mlp.1.bias\", \"unets.0.ups.3.1.3.block1.project.weight\", \"unets.0.ups.3.1.3.block1.project.bias\", \"unets.0.ups.3.1.3.block1.norm.weight\", \"unets.0.ups.3.1.3.block1.norm.bias\", \"unets.0.ups.3.1.3.block2.project.weight\", \"unets.0.ups.3.1.3.block2.project.bias\", \"unets.0.ups.3.1.3.block2.norm.weight\", \"unets.0.ups.3.1.3.block2.norm.bias\", \"unets.0.ups.3.1.3.res_conv.weight\", \"unets.0.ups.3.1.3.res_conv.bias\", \"unets.0.ups.3.2.fn.norm.g\", \"unets.0.ups.3.2.fn.to_qkv.weight\", \"unets.0.ups.3.2.fn.to_out.0.weight\", \"unets.0.ups.3.2.fn.to_out.1.g\", \"unets.0.ups.3.3.net.0.weight\", \"unets.0.ups.3.3.net.0.bias\", \"unets.0.mid_block1.cross_attn.null_kv\", \"unets.0.mid_block1.cross_attn.norm.g\", \"unets.0.mid_block1.cross_attn.to_q.weight\", \"unets.0.mid_block1.cross_attn.to_kv.weight\", \"unets.0.mid_block1.cross_attn.to_out.0.weight\", \"unets.0.mid_block1.cross_attn.to_out.1.g\", \"unets.0.mid_attn.fn.fn.norm.g\", \"unets.0.mid_attn.fn.fn.to_out.1.g\", \"unets.0.mid_block2.cross_attn.null_kv\", \"unets.0.mid_block2.cross_attn.norm.g\", \"unets.0.mid_block2.cross_attn.to_q.weight\", \"unets.0.mid_block2.cross_attn.to_kv.weight\", \"unets.0.mid_block2.cross_attn.to_out.0.weight\", \"unets.0.mid_block2.cross_attn.to_out.1.g\", \"unets.0.final_resnet_block.time_mlp.1.weight\", \"unets.0.final_resnet_block.time_mlp.1.bias\", \"unets.0.final_resnet_block.block1.project.weight\", \"unets.0.final_resnet_block.block1.project.bias\", \"unets.0.final_resnet_block.block1.norm.weight\", \"unets.0.final_resnet_block.block1.norm.bias\", \"unets.0.final_resnet_block.block2.project.weight\", \"unets.0.final_resnet_block.block2.project.bias\", \"unets.0.final_resnet_block.block2.norm.weight\", \"unets.0.final_resnet_block.block2.norm.bias\", \"unets.0.final_resnet_block.res_conv.weight\", \"unets.0.final_resnet_block.res_conv.bias\", \"unets.0.to_out.weight\", \"unets.0.to_out.bias\". \n\tUnexpected key(s) in state_dict: \"unets.0.final_conv.0.block1.project.weight\", \"unets.0.final_conv.0.block1.project.bias\", \"unets.0.final_conv.0.block1.norm.weight\", \"unets.0.final_conv.0.block1.norm.bias\", \"unets.0.final_conv.0.block2.project.weight\", \"unets.0.final_conv.0.block2.project.bias\", \"unets.0.final_conv.0.block2.norm.weight\", \"unets.0.final_conv.0.block2.norm.bias\", \"unets.0.final_conv.0.res_conv.weight\", \"unets.0.final_conv.0.res_conv.bias\", \"unets.0.final_conv.1.weight\", \"unets.0.final_conv.1.bias\", \"unets.0.downs.0.2.fn.norm.g\", \"unets.0.downs.0.2.fn.to_qkv.weight\", \"unets.0.downs.0.2.fn.to_out.0.weight\", \"unets.0.downs.0.2.fn.to_out.1.g\", \"unets.0.downs.0.3.0.time_mlp.1.weight\", \"unets.0.downs.0.3.0.time_mlp.1.bias\", \"unets.0.downs.0.3.0.block1.project.weight\", \"unets.0.downs.0.3.0.block1.project.bias\", \"unets.0.downs.0.3.0.block1.norm.weight\", \"unets.0.downs.0.3.0.block1.norm.bias\", \"unets.0.downs.0.3.0.block2.project.weight\", \"unets.0.downs.0.3.0.block2.project.bias\", \"unets.0.downs.0.3.0.block2.norm.weight\", \"unets.0.downs.0.3.0.block2.norm.bias\", \"unets.0.downs.0.3.1.time_mlp.1.weight\", \"unets.0.downs.0.3.1.time_mlp.1.bias\", \"unets.0.downs.0.3.1.block1.project.weight\", \"unets.0.downs.0.3.1.block1.project.bias\", \"unets.0.downs.0.3.1.block1.norm.weight\", \"unets.0.downs.0.3.1.block1.norm.bias\", \"unets.0.downs.0.3.1.block2.project.weight\", \"unets.0.downs.0.3.1.block2.project.bias\", \"unets.0.downs.0.3.1.block2.norm.weight\", \"unets.0.downs.0.3.1.block2.norm.bias\", \"unets.0.downs.0.3.2.time_mlp.1.weight\", \"unets.0.downs.0.3.2.time_mlp.1.bias\", \"unets.0.downs.0.3.2.block1.project.weight\", \"unets.0.downs.0.3.2.block1.project.bias\", \"unets.0.downs.0.3.2.block1.norm.weight\", \"unets.0.downs.0.3.2.block1.norm.bias\", \"unets.0.downs.0.3.2.block2.project.weight\", \"unets.0.downs.0.3.2.block2.project.bias\", \"unets.0.downs.0.3.2.block2.norm.weight\", \"unets.0.downs.0.3.2.block2.norm.bias\", \"unets.0.downs.0.3.3.time_mlp.1.weight\", \"unets.0.downs.0.3.3.time_mlp.1.bias\", \"unets.0.downs.0.3.3.block1.project.weight\", \"unets.0.downs.0.3.3.block1.project.bias\", \"unets.0.downs.0.3.3.block1.norm.weight\", \"unets.0.downs.0.3.3.block1.norm.bias\", \"unets.0.downs.0.3.3.block2.project.weight\", \"unets.0.downs.0.3.3.block2.project.bias\", \"unets.0.downs.0.3.3.block2.norm.weight\", \"unets.0.downs.0.3.3.block2.norm.bias\", \"unets.0.downs.1.1.res_conv.weight\", \"unets.0.downs.1.1.res_conv.bias\", \"unets.0.downs.1.2.fn.norm.g\", \"unets.0.downs.1.2.fn.to_qkv.weight\", \"unets.0.downs.1.2.fn.to_out.0.weight\", \"unets.0.downs.1.2.fn.to_out.1.g\", \"unets.0.downs.1.3.0.time_mlp.1.weight\", \"unets.0.downs.1.3.0.time_mlp.1.bias\", \"unets.0.downs.1.3.0.cross_attn.fn.null_kv\", \"unets.0.downs.1.3.0.cross_attn.fn.norm.gamma\", \"unets.0.downs.1.3.0.cross_attn.fn.norm.beta\", \"unets.0.downs.1.3.0.cross_attn.fn.to_q.weight\", \"unets.0.downs.1.3.0.cross_attn.fn.to_kv.weight\", \"unets.0.downs.1.3.0.cross_attn.fn.to_out.0.weight\", \"unets.0.downs.1.3.0.cross_attn.fn.to_out.1.gamma\", \"unets.0.downs.1.3.0.cross_attn.fn.to_out.1.beta\", \"unets.0.downs.1.3.0.block1.project.weight\", \"unets.0.downs.1.3.0.block1.project.bias\", \"unets.0.downs.1.3.0.block1.norm.weight\", \"unets.0.downs.1.3.0.block1.norm.bias\", \"unets.0.downs.1.3.0.block2.project.weight\", \"unets.0.downs.1.3.0.block2.project.bias\", \"unets.0.downs.1.3.0.block2.norm.weight\", \"unets.0.downs.1.3.0.block2.norm.bias\", \"unets.0.downs.1.3.1.time_mlp.1.weight\", \"unets.0.downs.1.3.1.time_mlp.1.bias\", \"unets.0.downs.1.3.1.cross_attn.fn.null_kv\", \"unets.0.downs.1.3.1.cross_attn.fn.norm.gamma\", \"unets.0.downs.1.3.1.cross_attn.fn.norm.beta\", \"unets.0.downs.1.3.1.cross_attn.fn.to_q.weight\", \"unets.0.downs.1.3.1.cross_attn.fn.to_kv.weight\", \"unets.0.downs.1.3.1.cross_attn.fn.to_out.0.weight\", \"unets.0.downs.1.3.1.cross_attn.fn.to_out.1.gamma\", \"unets.0.downs.1.3.1.cross_attn.fn.to_out.1.beta\", \"unets.0.downs.1.3.1.block1.project.weight\", \"unets.0.downs.1.3.1.block1.project.bias\", \"unets.0.downs.1.3.1.block1.norm.weight\", \"unets.0.downs.1.3.1.block1.norm.bias\", \"unets.0.downs.1.3.1.block2.project.weight\", \"unets.0.downs.1.3.1.block2.project.bias\", \"unets.0.downs.1.3.1.block2.norm.weight\", \"unets.0.downs.1.3.1.block2.norm.bias\", \"unets.0.downs.1.3.2.time_mlp.1.weight\", \"unets.0.downs.1.3.2.time_mlp.1.bias\", \"unets.0.downs.1.3.2.cross_attn.fn.null_kv\", \"unets.0.downs.1.3.2.cross_attn.fn.norm.gamma\", \"unets.0.downs.1.3.2.cross_attn.fn.norm.beta\", \"unets.0.downs.1.3.2.cross_attn.fn.to_q.weight\", \"unets.0.downs.1.3.2.cross_attn.fn.to_kv.weight\", \"unets.0.downs.1.3.2.cross_attn.fn.to_out.0.weight\", \"unets.0.downs.1.3.2.cross_attn.fn.to_out.1.gamma\", \"unets.0.downs.1.3.2.cross_attn.fn.to_out.1.beta\", \"unets.0.downs.1.3.2.block1.project.weight\", \"unets.0.downs.1.3.2.block1.project.bias\", \"unets.0.downs.1.3.2.block1.norm.weight\", \"unets.0.downs.1.3.2.block1.norm.bias\", \"unets.0.downs.1.3.2.block2.project.weight\", \"unets.0.downs.1.3.2.block2.project.bias\", \"unets.0.downs.1.3.2.block2.norm.weight\", \"unets.0.downs.1.3.2.block2.norm.bias\", \"unets.0.downs.1.3.3.time_mlp.1.weight\", \"unets.0.downs.1.3.3.time_mlp.1.bias\", \"unets.0.downs.1.3.3.cross_attn.fn.null_kv\", \"unets.0.downs.1.3.3.cross_attn.fn.norm.gamma\", \"unets.0.downs.1.3.3.cross_attn.fn.norm.beta\", \"unets.0.downs.1.3.3.cross_attn.fn.to_q.weight\", \"unets.0.downs.1.3.3.cross_attn.fn.to_kv.weight\", \"unets.0.downs.1.3.3.cross_attn.fn.to_out.0.weight\", \"unets.0.downs.1.3.3.cross_attn.fn.to_out.1.gamma\", \"unets.0.downs.1.3.3.cross_attn.fn.to_out.1.beta\", \"unets.0.downs.1.3.3.block1.project.weight\", \"unets.0.downs.1.3.3.block1.project.bias\", \"unets.0.downs.1.3.3.block1.norm.weight\", \"unets.0.downs.1.3.3.block1.norm.bias\", \"unets.0.downs.1.3.3.block2.project.weight\", \"unets.0.downs.1.3.3.block2.project.bias\", \"unets.0.downs.1.3.3.block2.norm.weight\", \"unets.0.downs.1.3.3.block2.norm.bias\", \"unets.0.downs.2.1.res_conv.weight\", \"unets.0.downs.2.1.res_conv.bias\", \"unets.0.downs.2.2.fn.norm.g\", \"unets.0.downs.2.2.fn.to_qkv.weight\", \"unets.0.downs.2.2.fn.to_out.0.weight\", \"unets.0.downs.2.2.fn.to_out.1.g\", \"unets.0.downs.2.3.0.time_mlp.1.weight\", \"unets.0.downs.2.3.0.time_mlp.1.bias\", \"unets.0.downs.2.3.0.cross_attn.fn.null_kv\", \"unets.0.downs.2.3.0.cross_attn.fn.norm.gamma\", \"unets.0.downs.2.3.0.cross_attn.fn.norm.beta\", \"unets.0.downs.2.3.0.cross_attn.fn.to_q.weight\", \"unets.0.downs.2.3.0.cross_attn.fn.to_kv.weight\", \"unets.0.downs.2.3.0.cross_attn.fn.to_out.0.weight\", \"unets.0.downs.2.3.0.cross_attn.fn.to_out.1.gamma\", \"unets.0.downs.2.3.0.cross_attn.fn.to_out.1.beta\", \"unets.0.downs.2.3.0.block1.project.weight\", \"unets.0.downs.2.3.0.block1.project.bias\", \"unets.0.downs.2.3.0.block1.norm.weight\", \"unets.0.downs.2.3.0.block1.norm.bias\", \"unets.0.downs.2.3.0.block2.project.weight\", \"unets.0.downs.2.3.0.block2.project.bias\", \"unets.0.downs.2.3.0.block2.norm.weight\", \"unets.0.downs.2.3.0.block2.norm.bias\", \"unets.0.downs.2.3.1.time_mlp.1.weight\", \"unets.0.downs.2.3.1.time_mlp.1.bias\", \"unets.0.downs.2.3.1.cross_attn.fn.null_kv\", \"unets.0.downs.2.3.1.cross_attn.fn.norm.gamma\", \"unets.0.downs.2.3.1.cross_attn.fn.norm.beta\", \"unets.0.downs.2.3.1.cross_attn.fn.to_q.weight\", \"unets.0.downs.2.3.1.cross_attn.fn.to_kv.weight\", \"unets.0.downs.2.3.1.cross_attn.fn.to_out.0.weight\", \"unets.0.downs.2.3.1.cross_attn.fn.to_out.1.gamma\", \"unets.0.downs.2.3.1.cross_attn.fn.to_out.1.beta\", \"unets.0.downs.2.3.1.block1.project.weight\", \"unets.0.downs.2.3.1.block1.project.bias\", \"unets.0.downs.2.3.1.block1.norm.weight\", \"unets.0.downs.2.3.1.block1.norm.bias\", \"unets.0.downs.2.3.1.block2.project.weight\", \"unets.0.downs.2.3.1.block2.project.bias\", \"unets.0.downs.2.3.1.block2.norm.weight\", \"unets.0.downs.2.3.1.block2.norm.bias\", \"unets.0.downs.2.3.2.time_mlp.1.weight\", \"unets.0.downs.2.3.2.time_mlp.1.bias\", \"unets.0.downs.2.3.2.cross_attn.fn.null_kv\", \"unets.0.downs.2.3.2.cross_attn.fn.norm.gamma\", \"unets.0.downs.2.3.2.cross_attn.fn.norm.beta\", \"unets.0.downs.2.3.2.cross_attn.fn.to_q.weight\", \"unets.0.downs.2.3.2.cross_attn.fn.to_kv.weight\", \"unets.0.downs.2.3.2.cross_attn.fn.to_out.0.weight\", \"unets.0.downs.2.3.2.cross_attn.fn.to_out.1.gamma\", \"unets.0.downs.2.3.2.cross_attn.fn.to_out.1.beta\", \"unets.0.downs.2.3.2.block1.project.weight\", \"unets.0.downs.2.3.2.block1.project.bias\", \"unets.0.downs.2.3.2.block1.norm.weight\", \"unets.0.downs.2.3.2.block1.norm.bias\", \"unets.0.downs.2.3.2.block2.project.weight\", \"unets.0.downs.2.3.2.block2.project.bias\", \"unets.0.downs.2.3.2.block2.norm.weight\", \"unets.0.downs.2.3.2.block2.norm.bias\", \"unets.0.downs.2.3.3.time_mlp.1.weight\", \"unets.0.downs.2.3.3.time_mlp.1.bias\", \"unets.0.downs.2.3.3.cross_attn.fn.null_kv\", \"unets.0.downs.2.3.3.cross_attn.fn.norm.gamma\", \"unets.0.downs.2.3.3.cross_attn.fn.norm.beta\", \"unets.0.downs.2.3.3.cross_attn.fn.to_q.weight\", \"unets.0.downs.2.3.3.cross_attn.fn.to_kv.weight\", \"unets.0.downs.2.3.3.cross_attn.fn.to_out.0.weight\", \"unets.0.downs.2.3.3.cross_attn.fn.to_out.1.gamma\", \"unets.0.downs.2.3.3.cross_attn.fn.to_out.1.beta\", \"unets.0.downs.2.3.3.block1.project.weight\", \"unets.0.downs.2.3.3.block1.project.bias\", \"unets.0.downs.2.3.3.block1.norm.weight\", \"unets.0.downs.2.3.3.block1.norm.bias\", \"unets.0.downs.2.3.3.block2.project.weight\", \"unets.0.downs.2.3.3.block2.project.bias\", \"unets.0.downs.2.3.3.block2.norm.weight\", \"unets.0.downs.2.3.3.block2.norm.bias\", \"unets.0.downs.3.1.res_conv.weight\", \"unets.0.downs.3.1.res_conv.bias\", \"unets.0.downs.3.2.fn.norm.g\", \"unets.0.downs.3.2.fn.to_qkv.weight\", \"unets.0.downs.3.2.fn.to_out.0.weight\", \"unets.0.downs.3.2.fn.to_out.1.g\", \"unets.0.downs.3.3.0.time_mlp.1.weight\", \"unets.0.downs.3.3.0.time_mlp.1.bias\", \"unets.0.downs.3.3.0.cross_attn.fn.null_kv\", \"unets.0.downs.3.3.0.cross_attn.fn.norm.gamma\", \"unets.0.downs.3.3.0.cross_attn.fn.norm.beta\", \"unets.0.downs.3.3.0.cross_attn.fn.to_q.weight\", \"unets.0.downs.3.3.0.cross_attn.fn.to_kv.weight\", \"unets.0.downs.3.3.0.cross_attn.fn.to_out.0.weight\", \"unets.0.downs.3.3.0.cross_attn.fn.to_out.1.gamma\", \"unets.0.downs.3.3.0.cross_attn.fn.to_out.1.beta\", \"unets.0.downs.3.3.0.block1.project.weight\", \"unets.0.downs.3.3.0.block1.project.bias\", \"unets.0.downs.3.3.0.block1.norm.weight\", \"unets.0.downs.3.3.0.block1.norm.bias\", \"unets.0.downs.3.3.0.block2.project.weight\", \"unets.0.downs.3.3.0.block2.project.bias\", \"unets.0.downs.3.3.0.block2.norm.weight\", \"unets.0.downs.3.3.0.block2.norm.bias\", \"unets.0.downs.3.3.1.time_mlp.1.weight\", \"unets.0.downs.3.3.1.time_mlp.1.bias\", \"unets.0.downs.3.3.1.cross_attn.fn.null_kv\", \"unets.0.downs.3.3.1.cross_attn.fn.norm.gamma\", \"unets.0.downs.3.3.1.cross_attn.fn.norm.beta\", \"unets.0.downs.3.3.1.cross_attn.fn.to_q.weight\", \"unets.0.downs.3.3.1.cross_attn.fn.to_kv.weight\", \"unets.0.downs.3.3.1.cross_attn.fn.to_out.0.weight\", \"unets.0.downs.3.3.1.cross_attn.fn.to_out.1.gamma\", \"unets.0.downs.3.3.1.cross_attn.fn.to_out.1.beta\", \"unets.0.downs.3.3.1.block1.project.weight\", \"unets.0.downs.3.3.1.block1.project.bias\", \"unets.0.downs.3.3.1.block1.norm.weight\", \"unets.0.downs.3.3.1.block1.norm.bias\", \"unets.0.downs.3.3.1.block2.project.weight\", \"unets.0.downs.3.3.1.block2.project.bias\", \"unets.0.downs.3.3.1.block2.norm.weight\", \"unets.0.downs.3.3.1.block2.norm.bias\", \"unets.0.downs.3.3.2.time_mlp.1.weight\", \"unets.0.downs.3.3.2.time_mlp.1.bias\", \"unets.0.downs.3.3.2.cross_attn.fn.null_kv\", \"unets.0.downs.3.3.2.cross_attn.fn.norm.gamma\", \"unets.0.downs.3.3.2.cross_attn.fn.norm.beta\", \"unets.0.downs.3.3.2.cross_attn.fn.to_q.weight\", \"unets.0.downs.3.3.2.cross_attn.fn.to_kv.weight\", \"unets.0.downs.3.3.2.cross_attn.fn.to_out.0.weight\", \"unets.0.downs.3.3.2.cross_attn.fn.to_out.1.gamma\", \"unets.0.downs.3.3.2.cross_attn.fn.to_out.1.beta\", \"unets.0.downs.3.3.2.block1.project.weight\", \"unets.0.downs.3.3.2.block1.project.bias\", \"unets.0.downs.3.3.2.block1.norm.weight\", \"unets.0.downs.3.3.2.block1.norm.bias\", \"unets.0.downs.3.3.2.block2.project.weight\", \"unets.0.downs.3.3.2.block2.project.bias\", \"unets.0.downs.3.3.2.block2.norm.weight\", \"unets.0.downs.3.3.2.block2.norm.bias\", \"unets.0.downs.3.3.3.time_mlp.1.weight\", \"unets.0.downs.3.3.3.time_mlp.1.bias\", \"unets.0.downs.3.3.3.cross_attn.fn.null_kv\", \"unets.0.downs.3.3.3.cross_attn.fn.norm.gamma\", \"unets.0.downs.3.3.3.cross_attn.fn.norm.beta\", \"unets.0.downs.3.3.3.cross_attn.fn.to_q.weight\", \"unets.0.downs.3.3.3.cross_attn.fn.to_kv.weight\", \"unets.0.downs.3.3.3.cross_attn.fn.to_out.0.weight\", \"unets.0.downs.3.3.3.cross_attn.fn.to_out.1.gamma\", \"unets.0.downs.3.3.3.cross_attn.fn.to_out.1.beta\", \"unets.0.downs.3.3.3.block1.project.weight\", \"unets.0.downs.3.3.3.block1.project.bias\", \"unets.0.downs.3.3.3.block1.norm.weight\", \"unets.0.downs.3.3.3.block1.norm.bias\", \"unets.0.downs.3.3.3.block2.project.weight\", \"unets.0.downs.3.3.3.block2.project.bias\", \"unets.0.downs.3.3.3.block2.norm.weight\", \"unets.0.downs.3.3.3.block2.norm.bias\", \"unets.0.ups.0.0.cross_attn.fn.null_kv\", \"unets.0.ups.0.0.cross_attn.fn.norm.gamma\", \"unets.0.ups.0.0.cross_attn.fn.norm.beta\", \"unets.0.ups.0.0.cross_attn.fn.to_q.weight\", \"unets.0.ups.0.0.cross_attn.fn.to_kv.weight\", \"unets.0.ups.0.0.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.0.0.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.0.0.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.0.1.fn.norm.g\", \"unets.0.ups.0.1.fn.to_qkv.weight\", \"unets.0.ups.0.1.fn.to_out.0.weight\", \"unets.0.ups.0.1.fn.to_out.1.g\", \"unets.0.ups.0.2.0.time_mlp.1.weight\", \"unets.0.ups.0.2.0.time_mlp.1.bias\", \"unets.0.ups.0.2.0.cross_attn.fn.null_kv\", \"unets.0.ups.0.2.0.cross_attn.fn.norm.gamma\", \"unets.0.ups.0.2.0.cross_attn.fn.norm.beta\", \"unets.0.ups.0.2.0.cross_attn.fn.to_q.weight\", \"unets.0.ups.0.2.0.cross_attn.fn.to_kv.weight\", \"unets.0.ups.0.2.0.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.0.2.0.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.0.2.0.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.0.2.0.block1.project.weight\", \"unets.0.ups.0.2.0.block1.project.bias\", \"unets.0.ups.0.2.0.block1.norm.weight\", \"unets.0.ups.0.2.0.block1.norm.bias\", \"unets.0.ups.0.2.0.block2.project.weight\", \"unets.0.ups.0.2.0.block2.project.bias\", \"unets.0.ups.0.2.0.block2.norm.weight\", \"unets.0.ups.0.2.0.block2.norm.bias\", \"unets.0.ups.0.2.1.time_mlp.1.weight\", \"unets.0.ups.0.2.1.time_mlp.1.bias\", \"unets.0.ups.0.2.1.cross_attn.fn.null_kv\", \"unets.0.ups.0.2.1.cross_attn.fn.norm.gamma\", \"unets.0.ups.0.2.1.cross_attn.fn.norm.beta\", \"unets.0.ups.0.2.1.cross_attn.fn.to_q.weight\", \"unets.0.ups.0.2.1.cross_attn.fn.to_kv.weight\", \"unets.0.ups.0.2.1.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.0.2.1.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.0.2.1.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.0.2.1.block1.project.weight\", \"unets.0.ups.0.2.1.block1.project.bias\", \"unets.0.ups.0.2.1.block1.norm.weight\", \"unets.0.ups.0.2.1.block1.norm.bias\", \"unets.0.ups.0.2.1.block2.project.weight\", \"unets.0.ups.0.2.1.block2.project.bias\", \"unets.0.ups.0.2.1.block2.norm.weight\", \"unets.0.ups.0.2.1.block2.norm.bias\", \"unets.0.ups.0.2.2.time_mlp.1.weight\", \"unets.0.ups.0.2.2.time_mlp.1.bias\", \"unets.0.ups.0.2.2.cross_attn.fn.null_kv\", \"unets.0.ups.0.2.2.cross_attn.fn.norm.gamma\", \"unets.0.ups.0.2.2.cross_attn.fn.norm.beta\", \"unets.0.ups.0.2.2.cross_attn.fn.to_q.weight\", \"unets.0.ups.0.2.2.cross_attn.fn.to_kv.weight\", \"unets.0.ups.0.2.2.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.0.2.2.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.0.2.2.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.0.2.2.block1.project.weight\", \"unets.0.ups.0.2.2.block1.project.bias\", \"unets.0.ups.0.2.2.block1.norm.weight\", \"unets.0.ups.0.2.2.block1.norm.bias\", \"unets.0.ups.0.2.2.block2.project.weight\", \"unets.0.ups.0.2.2.block2.project.bias\", \"unets.0.ups.0.2.2.block2.norm.weight\", \"unets.0.ups.0.2.2.block2.norm.bias\", \"unets.0.ups.0.2.3.time_mlp.1.weight\", \"unets.0.ups.0.2.3.time_mlp.1.bias\", \"unets.0.ups.0.2.3.cross_attn.fn.null_kv\", \"unets.0.ups.0.2.3.cross_attn.fn.norm.gamma\", \"unets.0.ups.0.2.3.cross_attn.fn.norm.beta\", \"unets.0.ups.0.2.3.cross_attn.fn.to_q.weight\", \"unets.0.ups.0.2.3.cross_attn.fn.to_kv.weight\", \"unets.0.ups.0.2.3.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.0.2.3.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.0.2.3.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.0.2.3.block1.project.weight\", \"unets.0.ups.0.2.3.block1.project.bias\", \"unets.0.ups.0.2.3.block1.norm.weight\", \"unets.0.ups.0.2.3.block1.norm.bias\", \"unets.0.ups.0.2.3.block2.project.weight\", \"unets.0.ups.0.2.3.block2.project.bias\", \"unets.0.ups.0.2.3.block2.norm.weight\", \"unets.0.ups.0.2.3.block2.norm.bias\", \"unets.0.ups.0.3.weight\", \"unets.0.ups.0.3.bias\", \"unets.0.ups.1.0.cross_attn.fn.null_kv\", \"unets.0.ups.1.0.cross_attn.fn.norm.gamma\", \"unets.0.ups.1.0.cross_attn.fn.norm.beta\", \"unets.0.ups.1.0.cross_attn.fn.to_q.weight\", \"unets.0.ups.1.0.cross_attn.fn.to_kv.weight\", \"unets.0.ups.1.0.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.1.0.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.1.0.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.1.1.fn.norm.g\", \"unets.0.ups.1.1.fn.to_qkv.weight\", \"unets.0.ups.1.1.fn.to_out.0.weight\", \"unets.0.ups.1.1.fn.to_out.1.g\", \"unets.0.ups.1.2.0.time_mlp.1.weight\", \"unets.0.ups.1.2.0.time_mlp.1.bias\", \"unets.0.ups.1.2.0.cross_attn.fn.null_kv\", \"unets.0.ups.1.2.0.cross_attn.fn.norm.gamma\", \"unets.0.ups.1.2.0.cross_attn.fn.norm.beta\", \"unets.0.ups.1.2.0.cross_attn.fn.to_q.weight\", \"unets.0.ups.1.2.0.cross_attn.fn.to_kv.weight\", \"unets.0.ups.1.2.0.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.1.2.0.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.1.2.0.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.1.2.0.block1.project.weight\", \"unets.0.ups.1.2.0.block1.project.bias\", \"unets.0.ups.1.2.0.block1.norm.weight\", \"unets.0.ups.1.2.0.block1.norm.bias\", \"unets.0.ups.1.2.0.block2.project.weight\", \"unets.0.ups.1.2.0.block2.project.bias\", \"unets.0.ups.1.2.0.block2.norm.weight\", \"unets.0.ups.1.2.0.block2.norm.bias\", \"unets.0.ups.1.2.1.time_mlp.1.weight\", \"unets.0.ups.1.2.1.time_mlp.1.bias\", \"unets.0.ups.1.2.1.cross_attn.fn.null_kv\", \"unets.0.ups.1.2.1.cross_attn.fn.norm.gamma\", \"unets.0.ups.1.2.1.cross_attn.fn.norm.beta\", \"unets.0.ups.1.2.1.cross_attn.fn.to_q.weight\", \"unets.0.ups.1.2.1.cross_attn.fn.to_kv.weight\", \"unets.0.ups.1.2.1.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.1.2.1.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.1.2.1.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.1.2.1.block1.project.weight\", \"unets.0.ups.1.2.1.block1.project.bias\", \"unets.0.ups.1.2.1.block1.norm.weight\", \"unets.0.ups.1.2.1.block1.norm.bias\", \"unets.0.ups.1.2.1.block2.project.weight\", \"unets.0.ups.1.2.1.block2.project.bias\", \"unets.0.ups.1.2.1.block2.norm.weight\", \"unets.0.ups.1.2.1.block2.norm.bias\", \"unets.0.ups.1.2.2.time_mlp.1.weight\", \"unets.0.ups.1.2.2.time_mlp.1.bias\", \"unets.0.ups.1.2.2.cross_attn.fn.null_kv\", \"unets.0.ups.1.2.2.cross_attn.fn.norm.gamma\", \"unets.0.ups.1.2.2.cross_attn.fn.norm.beta\", \"unets.0.ups.1.2.2.cross_attn.fn.to_q.weight\", \"unets.0.ups.1.2.2.cross_attn.fn.to_kv.weight\", \"unets.0.ups.1.2.2.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.1.2.2.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.1.2.2.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.1.2.2.block1.project.weight\", \"unets.0.ups.1.2.2.block1.project.bias\", \"unets.0.ups.1.2.2.block1.norm.weight\", \"unets.0.ups.1.2.2.block1.norm.bias\", \"unets.0.ups.1.2.2.block2.project.weight\", \"unets.0.ups.1.2.2.block2.project.bias\", \"unets.0.ups.1.2.2.block2.norm.weight\", \"unets.0.ups.1.2.2.block2.norm.bias\", \"unets.0.ups.1.2.3.time_mlp.1.weight\", \"unets.0.ups.1.2.3.time_mlp.1.bias\", \"unets.0.ups.1.2.3.cross_attn.fn.null_kv\", \"unets.0.ups.1.2.3.cross_attn.fn.norm.gamma\", \"unets.0.ups.1.2.3.cross_attn.fn.norm.beta\", \"unets.0.ups.1.2.3.cross_attn.fn.to_q.weight\", \"unets.0.ups.1.2.3.cross_attn.fn.to_kv.weight\", \"unets.0.ups.1.2.3.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.1.2.3.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.1.2.3.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.1.2.3.block1.project.weight\", \"unets.0.ups.1.2.3.block1.project.bias\", \"unets.0.ups.1.2.3.block1.norm.weight\", \"unets.0.ups.1.2.3.block1.norm.bias\", \"unets.0.ups.1.2.3.block2.project.weight\", \"unets.0.ups.1.2.3.block2.project.bias\", \"unets.0.ups.1.2.3.block2.norm.weight\", \"unets.0.ups.1.2.3.block2.norm.bias\", \"unets.0.ups.1.3.weight\", \"unets.0.ups.1.3.bias\", \"unets.0.ups.2.0.cross_attn.fn.null_kv\", \"unets.0.ups.2.0.cross_attn.fn.norm.gamma\", \"unets.0.ups.2.0.cross_attn.fn.norm.beta\", \"unets.0.ups.2.0.cross_attn.fn.to_q.weight\", \"unets.0.ups.2.0.cross_attn.fn.to_kv.weight\", \"unets.0.ups.2.0.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.2.0.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.2.0.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.2.1.fn.norm.g\", \"unets.0.ups.2.1.fn.to_qkv.weight\", \"unets.0.ups.2.1.fn.to_out.0.weight\", \"unets.0.ups.2.1.fn.to_out.1.g\", \"unets.0.ups.2.2.0.time_mlp.1.weight\", \"unets.0.ups.2.2.0.time_mlp.1.bias\", \"unets.0.ups.2.2.0.cross_attn.fn.null_kv\", \"unets.0.ups.2.2.0.cross_attn.fn.norm.gamma\", \"unets.0.ups.2.2.0.cross_attn.fn.norm.beta\", \"unets.0.ups.2.2.0.cross_attn.fn.to_q.weight\", \"unets.0.ups.2.2.0.cross_attn.fn.to_kv.weight\", \"unets.0.ups.2.2.0.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.2.2.0.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.2.2.0.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.2.2.0.block1.project.weight\", \"unets.0.ups.2.2.0.block1.project.bias\", \"unets.0.ups.2.2.0.block1.norm.weight\", \"unets.0.ups.2.2.0.block1.norm.bias\", \"unets.0.ups.2.2.0.block2.project.weight\", \"unets.0.ups.2.2.0.block2.project.bias\", \"unets.0.ups.2.2.0.block2.norm.weight\", \"unets.0.ups.2.2.0.block2.norm.bias\", \"unets.0.ups.2.2.1.time_mlp.1.weight\", \"unets.0.ups.2.2.1.time_mlp.1.bias\", \"unets.0.ups.2.2.1.cross_attn.fn.null_kv\", \"unets.0.ups.2.2.1.cross_attn.fn.norm.gamma\", \"unets.0.ups.2.2.1.cross_attn.fn.norm.beta\", \"unets.0.ups.2.2.1.cross_attn.fn.to_q.weight\", \"unets.0.ups.2.2.1.cross_attn.fn.to_kv.weight\", \"unets.0.ups.2.2.1.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.2.2.1.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.2.2.1.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.2.2.1.block1.project.weight\", \"unets.0.ups.2.2.1.block1.project.bias\", \"unets.0.ups.2.2.1.block1.norm.weight\", \"unets.0.ups.2.2.1.block1.norm.bias\", \"unets.0.ups.2.2.1.block2.project.weight\", \"unets.0.ups.2.2.1.block2.project.bias\", \"unets.0.ups.2.2.1.block2.norm.weight\", \"unets.0.ups.2.2.1.block2.norm.bias\", \"unets.0.ups.2.2.2.time_mlp.1.weight\", \"unets.0.ups.2.2.2.time_mlp.1.bias\", \"unets.0.ups.2.2.2.cross_attn.fn.null_kv\", \"unets.0.ups.2.2.2.cross_attn.fn.norm.gamma\", \"unets.0.ups.2.2.2.cross_attn.fn.norm.beta\", \"unets.0.ups.2.2.2.cross_attn.fn.to_q.weight\", \"unets.0.ups.2.2.2.cross_attn.fn.to_kv.weight\", \"unets.0.ups.2.2.2.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.2.2.2.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.2.2.2.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.2.2.2.block1.project.weight\", \"unets.0.ups.2.2.2.block1.project.bias\", \"unets.0.ups.2.2.2.block1.norm.weight\", \"unets.0.ups.2.2.2.block1.norm.bias\", \"unets.0.ups.2.2.2.block2.project.weight\", \"unets.0.ups.2.2.2.block2.project.bias\", \"unets.0.ups.2.2.2.block2.norm.weight\", \"unets.0.ups.2.2.2.block2.norm.bias\", \"unets.0.ups.2.2.3.time_mlp.1.weight\", \"unets.0.ups.2.2.3.time_mlp.1.bias\", \"unets.0.ups.2.2.3.cross_attn.fn.null_kv\", \"unets.0.ups.2.2.3.cross_attn.fn.norm.gamma\", \"unets.0.ups.2.2.3.cross_attn.fn.norm.beta\", \"unets.0.ups.2.2.3.cross_attn.fn.to_q.weight\", \"unets.0.ups.2.2.3.cross_attn.fn.to_kv.weight\", \"unets.0.ups.2.2.3.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.2.2.3.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.2.2.3.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.2.2.3.block1.project.weight\", \"unets.0.ups.2.2.3.block1.project.bias\", \"unets.0.ups.2.2.3.block1.norm.weight\", \"unets.0.ups.2.2.3.block1.norm.bias\", \"unets.0.ups.2.2.3.block2.project.weight\", \"unets.0.ups.2.2.3.block2.project.bias\", \"unets.0.ups.2.2.3.block2.norm.weight\", \"unets.0.ups.2.2.3.block2.norm.bias\", \"unets.0.ups.2.3.weight\", \"unets.0.ups.2.3.bias\", \"unets.0.ups.3.1.fn.norm.g\", \"unets.0.ups.3.1.fn.to_qkv.weight\", \"unets.0.ups.3.1.fn.to_out.0.weight\", \"unets.0.ups.3.1.fn.to_out.1.g\", \"unets.0.ups.3.2.0.time_mlp.1.weight\", \"unets.0.ups.3.2.0.time_mlp.1.bias\", \"unets.0.ups.3.2.0.block1.project.weight\", \"unets.0.ups.3.2.0.block1.project.bias\", \"unets.0.ups.3.2.0.block1.norm.weight\", \"unets.0.ups.3.2.0.block1.norm.bias\", \"unets.0.ups.3.2.0.block2.project.weight\", \"unets.0.ups.3.2.0.block2.project.bias\", \"unets.0.ups.3.2.0.block2.norm.weight\", \"unets.0.ups.3.2.0.block2.norm.bias\", \"unets.0.ups.3.2.1.time_mlp.1.weight\", \"unets.0.ups.3.2.1.time_mlp.1.bias\", \"unets.0.ups.3.2.1.block1.project.weight\", \"unets.0.ups.3.2.1.block1.project.bias\", \"unets.0.ups.3.2.1.block1.norm.weight\", \"unets.0.ups.3.2.1.block1.norm.bias\", \"unets.0.ups.3.2.1.block2.project.weight\", \"unets.0.ups.3.2.1.block2.project.bias\", \"unets.0.ups.3.2.1.block2.norm.weight\", \"unets.0.ups.3.2.1.block2.norm.bias\", \"unets.0.ups.3.2.2.time_mlp.1.weight\", \"unets.0.ups.3.2.2.time_mlp.1.bias\", \"unets.0.ups.3.2.2.block1.project.weight\", \"unets.0.ups.3.2.2.block1.project.bias\", \"unets.0.ups.3.2.2.block1.norm.weight\", \"unets.0.ups.3.2.2.block1.norm.bias\", \"unets.0.ups.3.2.2.block2.project.weight\", \"unets.0.ups.3.2.2.block2.project.bias\", \"unets.0.ups.3.2.2.block2.norm.weight\", \"unets.0.ups.3.2.2.block2.norm.bias\", \"unets.0.ups.3.2.3.time_mlp.1.weight\", \"unets.0.ups.3.2.3.time_mlp.1.bias\", \"unets.0.ups.3.2.3.block1.project.weight\", \"unets.0.ups.3.2.3.block1.project.bias\", \"unets.0.ups.3.2.3.block1.norm.weight\", \"unets.0.ups.3.2.3.block1.norm.bias\", \"unets.0.ups.3.2.3.block2.project.weight\", \"unets.0.ups.3.2.3.block2.project.bias\", \"unets.0.ups.3.2.3.block2.norm.weight\", \"unets.0.ups.3.2.3.block2.norm.bias\", \"unets.0.mid_block1.cross_attn.fn.null_kv\", \"unets.0.mid_block1.cross_attn.fn.norm.gamma\", \"unets.0.mid_block1.cross_attn.fn.norm.beta\", \"unets.0.mid_block1.cross_attn.fn.to_q.weight\", \"unets.0.mid_block1.cross_attn.fn.to_kv.weight\", \"unets.0.mid_block1.cross_attn.fn.to_out.0.weight\", \"unets.0.mid_block1.cross_attn.fn.to_out.1.gamma\", \"unets.0.mid_block1.cross_attn.fn.to_out.1.beta\", \"unets.0.mid_attn.fn.fn.norm.gamma\", \"unets.0.mid_attn.fn.fn.norm.beta\", \"unets.0.mid_attn.fn.fn.to_out.1.gamma\", \"unets.0.mid_attn.fn.fn.to_out.1.beta\", \"unets.0.mid_block2.cross_attn.fn.null_kv\", \"unets.0.mid_block2.cross_attn.fn.norm.gamma\", \"unets.0.mid_block2.cross_attn.fn.norm.beta\", \"unets.0.mid_block2.cross_attn.fn.to_q.weight\", \"unets.0.mid_block2.cross_attn.fn.to_kv.weight\", \"unets.0.mid_block2.cross_attn.fn.to_out.0.weight\", \"unets.0.mid_block2.cross_attn.fn.to_out.1.gamma\", \"unets.0.mid_block2.cross_attn.fn.to_out.1.beta\". \n\tsize mismatch for unets.0.downs.0.4.weight: copying a param with shape torch.Size([416, 416, 4, 4]) from checkpoint, the shape in current model is torch.Size([416, 416, 1, 1]).\n\tsize mismatch for unets.0.downs.1.1.block1.project.weight: copying a param with shape torch.Size([832, 416, 3, 3]) from checkpoint, the shape in current model is torch.Size([832, 832, 3, 3]).\n\tsize mismatch for unets.0.downs.1.4.weight: copying a param with shape torch.Size([832, 832, 4, 4]) from checkpoint, the shape in current model is torch.Size([832, 832, 1, 1]).\n\tsize mismatch for unets.0.downs.2.1.block1.project.weight: copying a param with shape torch.Size([1248, 832, 3, 3]) from checkpoint, the shape in current model is torch.Size([1248, 1248, 3, 3]).\n\tsize mismatch for unets.0.downs.2.4.weight: copying a param with shape torch.Size([1248, 1248, 4, 4]) from checkpoint, the shape in current model is torch.Size([1248, 1248, 1, 1]).\n\tsize mismatch for unets.0.downs.3.1.block1.project.weight: copying a param with shape torch.Size([1664, 1248, 3, 3]) from checkpoint, the shape in current model is torch.Size([1664, 1664, 3, 3]).\n\tsize mismatch for unets.0.ups.0.0.time_mlp.1.weight: copying a param with shape torch.Size([2496, 1664]) from checkpoint, the shape in current model is torch.Size([3328, 1664]).\n\tsize mismatch for unets.0.ups.0.0.time_mlp.1.bias: copying a param with shape torch.Size([2496]) from checkpoint, the shape in current model is torch.Size([3328]).\n\tsize mismatch for unets.0.ups.0.0.block1.project.weight: copying a param with shape torch.Size([1248, 3328, 3, 3]) from checkpoint, the shape in current model is torch.Size([1664, 3328, 3, 3]).\n\tsize mismatch for unets.0.ups.0.0.block1.project.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1664]).\n\tsize mismatch for unets.0.ups.0.0.block1.norm.weight: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1664]).\n\tsize mismatch for unets.0.ups.0.0.block1.norm.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1664]).\n\tsize mismatch for unets.0.ups.0.0.block2.project.weight: copying a param with shape torch.Size([1248, 1248, 3, 3]) from checkpoint, the shape in current model is torch.Size([1664, 1664, 3, 3]).\n\tsize mismatch for unets.0.ups.0.0.block2.project.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1664]).\n\tsize mismatch for unets.0.ups.0.0.block2.norm.weight: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1664]).\n\tsize mismatch for unets.0.ups.0.0.block2.norm.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1664]).\n\tsize mismatch for unets.0.ups.0.0.res_conv.weight: copying a param with shape torch.Size([1248, 3328, 1, 1]) from checkpoint, the shape in current model is torch.Size([1664, 3328, 1, 1]).\n\tsize mismatch for unets.0.ups.0.0.res_conv.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1664]).\n\tsize mismatch for unets.0.ups.1.0.time_mlp.1.weight: copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape in current model is torch.Size([2496, 1664]).\n\tsize mismatch for unets.0.ups.1.0.time_mlp.1.bias: copying a param with shape torch.Size([1664]) from checkpoint, the shape in current model is torch.Size([2496]).\n\tsize mismatch for unets.0.ups.1.0.block1.project.weight: copying a param with shape torch.Size([832, 2496, 3, 3]) from checkpoint, the shape in current model is torch.Size([1248, 2496, 3, 3]).\n\tsize mismatch for unets.0.ups.1.0.block1.project.bias: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([1248]).\n\tsize mismatch for unets.0.ups.1.0.block1.norm.weight: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([1248]).\n\tsize mismatch for unets.0.ups.1.0.block1.norm.bias: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([1248]).\n\tsize mismatch for unets.0.ups.1.0.block2.project.weight: copying a param with shape torch.Size([832, 832, 3, 3]) from checkpoint, the shape in current model is torch.Size([1248, 1248, 3, 3]).\n\tsize mismatch for unets.0.ups.1.0.block2.project.bias: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([1248]).\n\tsize mismatch for unets.0.ups.1.0.block2.norm.weight: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([1248]).\n\tsize mismatch for unets.0.ups.1.0.block2.norm.bias: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([1248]).\n\tsize mismatch for unets.0.ups.1.0.res_conv.weight: copying a param with shape torch.Size([832, 2496, 1, 1]) from checkpoint, the shape in current model is torch.Size([1248, 2496, 1, 1]).\n\tsize mismatch for unets.0.ups.1.0.res_conv.bias: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([1248]).\n\tsize mismatch for unets.0.ups.2.0.time_mlp.1.weight: copying a param with shape torch.Size([832, 1664]) from checkpoint, the shape in current model is torch.Size([1664, 1664]).\n\tsize mismatch for unets.0.ups.2.0.time_mlp.1.bias: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([1664]).\n\tsize mismatch for unets.0.ups.2.0.block1.project.weight: copying a param with shape torch.Size([416, 1664, 3, 3]) from checkpoint, the shape in current model is torch.Size([832, 1664, 3, 3]).\n\tsize mismatch for unets.0.ups.2.0.block1.project.bias: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([832]).\n\tsize mismatch for unets.0.ups.2.0.block1.norm.weight: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([832]).\n\tsize mismatch for unets.0.ups.2.0.block1.norm.bias: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([832]).\n\tsize mismatch for unets.0.ups.2.0.block2.project.weight: copying a param with shape torch.Size([416, 416, 3, 3]) from checkpoint, the shape in current model is torch.Size([832, 832, 3, 3]).\n\tsize mismatch for unets.0.ups.2.0.block2.project.bias: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([832]).\n\tsize mismatch for unets.0.ups.2.0.block2.norm.weight: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([832]).\n\tsize mismatch for unets.0.ups.2.0.block2.norm.bias: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([832]).\n\tsize mismatch for unets.0.ups.2.0.res_conv.weight: copying a param with shape torch.Size([416, 1664, 1, 1]) from checkpoint, the shape in current model is torch.Size([832, 1664, 1, 1]).\n\tsize mismatch for unets.0.ups.2.0.res_conv.bias: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([832]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# for k in decoder.clip.state_dict().keys():\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#     decoder_model_state[\"clip.\" + k] = decoder.clip.state_dict()[k]\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_model_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Decoder:\n\tMissing key(s) in state_dict: \"clip.clip.positional_embedding\", \"clip.clip.text_projection\", \"clip.clip.logit_scale\", \"clip.clip.visual.class_embedding\", \"clip.clip.visual.positional_embedding\", \"clip.clip.visual.proj\", \"clip.clip.visual.conv1.weight\", \"clip.clip.visual.ln_pre.weight\", \"clip.clip.visual.ln_pre.bias\", \"clip.clip.visual.transformer.resblocks.0.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.0.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.0.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.0.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.0.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.0.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.0.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.0.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.0.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.0.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.0.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.0.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.1.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.1.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.1.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.1.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.1.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.1.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.1.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.1.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.1.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.1.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.1.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.1.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.2.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.2.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.2.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.2.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.2.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.2.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.2.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.2.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.2.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.2.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.2.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.2.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.3.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.3.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.3.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.3.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.3.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.3.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.3.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.3.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.3.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.3.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.3.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.3.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.4.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.4.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.4.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.4.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.4.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.4.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.4.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.4.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.4.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.4.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.4.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.4.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.5.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.5.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.5.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.5.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.5.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.5.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.5.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.5.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.5.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.5.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.5.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.5.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.6.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.6.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.6.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.6.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.6.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.6.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.6.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.6.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.6.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.6.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.6.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.6.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.7.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.7.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.7.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.7.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.7.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.7.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.7.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.7.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.7.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.7.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.7.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.7.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.8.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.8.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.8.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.8.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.8.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.8.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.8.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.8.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.8.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.8.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.8.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.8.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.9.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.9.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.9.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.9.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.9.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.9.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.9.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.9.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.9.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.9.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.9.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.9.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.10.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.10.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.10.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.10.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.10.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.10.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.10.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.10.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.10.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.10.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.10.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.10.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.11.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.11.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.11.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.11.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.11.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.11.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.11.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.11.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.11.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.11.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.11.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.11.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.12.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.12.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.12.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.12.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.12.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.12.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.12.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.12.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.12.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.12.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.12.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.12.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.13.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.13.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.13.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.13.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.13.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.13.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.13.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.13.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.13.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.13.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.13.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.13.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.14.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.14.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.14.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.14.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.14.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.14.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.14.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.14.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.14.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.14.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.14.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.14.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.15.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.15.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.15.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.15.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.15.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.15.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.15.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.15.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.15.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.15.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.15.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.15.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.16.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.16.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.16.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.16.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.16.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.16.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.16.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.16.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.16.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.16.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.16.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.16.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.17.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.17.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.17.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.17.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.17.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.17.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.17.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.17.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.17.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.17.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.17.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.17.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.18.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.18.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.18.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.18.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.18.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.18.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.18.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.18.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.18.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.18.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.18.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.18.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.19.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.19.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.19.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.19.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.19.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.19.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.19.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.19.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.19.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.19.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.19.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.19.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.20.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.20.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.20.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.20.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.20.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.20.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.20.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.20.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.20.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.20.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.20.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.20.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.21.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.21.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.21.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.21.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.21.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.21.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.21.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.21.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.21.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.21.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.21.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.21.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.22.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.22.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.22.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.22.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.22.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.22.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.22.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.22.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.22.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.22.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.22.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.22.ln_2.bias\", \"clip.clip.visual.transformer.resblocks.23.attn.in_proj_weight\", \"clip.clip.visual.transformer.resblocks.23.attn.in_proj_bias\", \"clip.clip.visual.transformer.resblocks.23.attn.out_proj.weight\", \"clip.clip.visual.transformer.resblocks.23.attn.out_proj.bias\", \"clip.clip.visual.transformer.resblocks.23.ln_1.weight\", \"clip.clip.visual.transformer.resblocks.23.ln_1.bias\", \"clip.clip.visual.transformer.resblocks.23.mlp.c_fc.weight\", \"clip.clip.visual.transformer.resblocks.23.mlp.c_fc.bias\", \"clip.clip.visual.transformer.resblocks.23.mlp.c_proj.weight\", \"clip.clip.visual.transformer.resblocks.23.mlp.c_proj.bias\", \"clip.clip.visual.transformer.resblocks.23.ln_2.weight\", \"clip.clip.visual.transformer.resblocks.23.ln_2.bias\", \"clip.clip.visual.ln_post.weight\", \"clip.clip.visual.ln_post.bias\", \"clip.clip.transformer.resblocks.0.attn.in_proj_weight\", \"clip.clip.transformer.resblocks.0.attn.in_proj_bias\", \"clip.clip.transformer.resblocks.0.attn.out_proj.weight\", \"clip.clip.transformer.resblocks.0.attn.out_proj.bias\", \"clip.clip.transformer.resblocks.0.ln_1.weight\", \"clip.clip.transformer.resblocks.0.ln_1.bias\", \"clip.clip.transformer.resblocks.0.mlp.c_fc.weight\", \"clip.clip.transformer.resblocks.0.mlp.c_fc.bias\", \"clip.clip.transformer.resblocks.0.mlp.c_proj.weight\", \"clip.clip.transformer.resblocks.0.mlp.c_proj.bias\", \"clip.clip.transformer.resblocks.0.ln_2.weight\", \"clip.clip.transformer.resblocks.0.ln_2.bias\", \"clip.clip.transformer.resblocks.1.attn.in_proj_weight\", \"clip.clip.transformer.resblocks.1.attn.in_proj_bias\", \"clip.clip.transformer.resblocks.1.attn.out_proj.weight\", \"clip.clip.transformer.resblocks.1.attn.out_proj.bias\", \"clip.clip.transformer.resblocks.1.ln_1.weight\", \"clip.clip.transformer.resblocks.1.ln_1.bias\", \"clip.clip.transformer.resblocks.1.mlp.c_fc.weight\", \"clip.clip.transformer.resblocks.1.mlp.c_fc.bias\", \"clip.clip.transformer.resblocks.1.mlp.c_proj.weight\", \"clip.clip.transformer.resblocks.1.mlp.c_proj.bias\", \"clip.clip.transformer.resblocks.1.ln_2.weight\", \"clip.clip.transformer.resblocks.1.ln_2.bias\", \"clip.clip.transformer.resblocks.2.attn.in_proj_weight\", \"clip.clip.transformer.resblocks.2.attn.in_proj_bias\", \"clip.clip.transformer.resblocks.2.attn.out_proj.weight\", \"clip.clip.transformer.resblocks.2.attn.out_proj.bias\", \"clip.clip.transformer.resblocks.2.ln_1.weight\", \"clip.clip.transformer.resblocks.2.ln_1.bias\", \"clip.clip.transformer.resblocks.2.mlp.c_fc.weight\", \"clip.clip.transformer.resblocks.2.mlp.c_fc.bias\", \"clip.clip.transformer.resblocks.2.mlp.c_proj.weight\", \"clip.clip.transformer.resblocks.2.mlp.c_proj.bias\", \"clip.clip.transformer.resblocks.2.ln_2.weight\", \"clip.clip.transformer.resblocks.2.ln_2.bias\", \"clip.clip.transformer.resblocks.3.attn.in_proj_weight\", \"clip.clip.transformer.resblocks.3.attn.in_proj_bias\", \"clip.clip.transformer.resblocks.3.attn.out_proj.weight\", \"clip.clip.transformer.resblocks.3.attn.out_proj.bias\", \"clip.clip.transformer.resblocks.3.ln_1.weight\", \"clip.clip.transformer.resblocks.3.ln_1.bias\", \"clip.clip.transformer.resblocks.3.mlp.c_fc.weight\", \"clip.clip.transformer.resblocks.3.mlp.c_fc.bias\", \"clip.clip.transformer.resblocks.3.mlp.c_proj.weight\", \"clip.clip.transformer.resblocks.3.mlp.c_proj.bias\", \"clip.clip.transformer.resblocks.3.ln_2.weight\", \"clip.clip.transformer.resblocks.3.ln_2.bias\", \"clip.clip.transformer.resblocks.4.attn.in_proj_weight\", \"clip.clip.transformer.resblocks.4.attn.in_proj_bias\", \"clip.clip.transformer.resblocks.4.attn.out_proj.weight\", \"clip.clip.transformer.resblocks.4.attn.out_proj.bias\", \"clip.clip.transformer.resblocks.4.ln_1.weight\", \"clip.clip.transformer.resblocks.4.ln_1.bias\", \"clip.clip.transformer.resblocks.4.mlp.c_fc.weight\", \"clip.clip.transformer.resblocks.4.mlp.c_fc.bias\", \"clip.clip.transformer.resblocks.4.mlp.c_proj.weight\", \"clip.clip.transformer.resblocks.4.mlp.c_proj.bias\", \"clip.clip.transformer.resblocks.4.ln_2.weight\", \"clip.clip.transformer.resblocks.4.ln_2.bias\", \"clip.clip.transformer.resblocks.5.attn.in_proj_weight\", \"clip.clip.transformer.resblocks.5.attn.in_proj_bias\", \"clip.clip.transformer.resblocks.5.attn.out_proj.weight\", \"clip.clip.transformer.resblocks.5.attn.out_proj.bias\", \"clip.clip.transformer.resblocks.5.ln_1.weight\", \"clip.clip.transformer.resblocks.5.ln_1.bias\", \"clip.clip.transformer.resblocks.5.mlp.c_fc.weight\", \"clip.clip.transformer.resblocks.5.mlp.c_fc.bias\", \"clip.clip.transformer.resblocks.5.mlp.c_proj.weight\", \"clip.clip.transformer.resblocks.5.mlp.c_proj.bias\", \"clip.clip.transformer.resblocks.5.ln_2.weight\", \"clip.clip.transformer.resblocks.5.ln_2.bias\", \"clip.clip.transformer.resblocks.6.attn.in_proj_weight\", \"clip.clip.transformer.resblocks.6.attn.in_proj_bias\", \"clip.clip.transformer.resblocks.6.attn.out_proj.weight\", \"clip.clip.transformer.resblocks.6.attn.out_proj.bias\", \"clip.clip.transformer.resblocks.6.ln_1.weight\", \"clip.clip.transformer.resblocks.6.ln_1.bias\", \"clip.clip.transformer.resblocks.6.mlp.c_fc.weight\", \"clip.clip.transformer.resblocks.6.mlp.c_fc.bias\", \"clip.clip.transformer.resblocks.6.mlp.c_proj.weight\", \"clip.clip.transformer.resblocks.6.mlp.c_proj.bias\", \"clip.clip.transformer.resblocks.6.ln_2.weight\", \"clip.clip.transformer.resblocks.6.ln_2.bias\", \"clip.clip.transformer.resblocks.7.attn.in_proj_weight\", \"clip.clip.transformer.resblocks.7.attn.in_proj_bias\", \"clip.clip.transformer.resblocks.7.attn.out_proj.weight\", \"clip.clip.transformer.resblocks.7.attn.out_proj.bias\", \"clip.clip.transformer.resblocks.7.ln_1.weight\", \"clip.clip.transformer.resblocks.7.ln_1.bias\", \"clip.clip.transformer.resblocks.7.mlp.c_fc.weight\", \"clip.clip.transformer.resblocks.7.mlp.c_fc.bias\", \"clip.clip.transformer.resblocks.7.mlp.c_proj.weight\", \"clip.clip.transformer.resblocks.7.mlp.c_proj.bias\", \"clip.clip.transformer.resblocks.7.ln_2.weight\", \"clip.clip.transformer.resblocks.7.ln_2.bias\", \"clip.clip.transformer.resblocks.8.attn.in_proj_weight\", \"clip.clip.transformer.resblocks.8.attn.in_proj_bias\", \"clip.clip.transformer.resblocks.8.attn.out_proj.weight\", \"clip.clip.transformer.resblocks.8.attn.out_proj.bias\", \"clip.clip.transformer.resblocks.8.ln_1.weight\", \"clip.clip.transformer.resblocks.8.ln_1.bias\", \"clip.clip.transformer.resblocks.8.mlp.c_fc.weight\", \"clip.clip.transformer.resblocks.8.mlp.c_fc.bias\", \"clip.clip.transformer.resblocks.8.mlp.c_proj.weight\", \"clip.clip.transformer.resblocks.8.mlp.c_proj.bias\", \"clip.clip.transformer.resblocks.8.ln_2.weight\", \"clip.clip.transformer.resblocks.8.ln_2.bias\", \"clip.clip.transformer.resblocks.9.attn.in_proj_weight\", \"clip.clip.transformer.resblocks.9.attn.in_proj_bias\", \"clip.clip.transformer.resblocks.9.attn.out_proj.weight\", \"clip.clip.transformer.resblocks.9.attn.out_proj.bias\", \"clip.clip.transformer.resblocks.9.ln_1.weight\", \"clip.clip.transformer.resblocks.9.ln_1.bias\", \"clip.clip.transformer.resblocks.9.mlp.c_fc.weight\", \"clip.clip.transformer.resblocks.9.mlp.c_fc.bias\", \"clip.clip.transformer.resblocks.9.mlp.c_proj.weight\", \"clip.clip.transformer.resblocks.9.mlp.c_proj.bias\", \"clip.clip.transformer.resblocks.9.ln_2.weight\", \"clip.clip.transformer.resblocks.9.ln_2.bias\", \"clip.clip.transformer.resblocks.10.attn.in_proj_weight\", \"clip.clip.transformer.resblocks.10.attn.in_proj_bias\", \"clip.clip.transformer.resblocks.10.attn.out_proj.weight\", \"clip.clip.transformer.resblocks.10.attn.out_proj.bias\", \"clip.clip.transformer.resblocks.10.ln_1.weight\", \"clip.clip.transformer.resblocks.10.ln_1.bias\", \"clip.clip.transformer.resblocks.10.mlp.c_fc.weight\", \"clip.clip.transformer.resblocks.10.mlp.c_fc.bias\", \"clip.clip.transformer.resblocks.10.mlp.c_proj.weight\", \"clip.clip.transformer.resblocks.10.mlp.c_proj.bias\", \"clip.clip.transformer.resblocks.10.ln_2.weight\", \"clip.clip.transformer.resblocks.10.ln_2.bias\", \"clip.clip.transformer.resblocks.11.attn.in_proj_weight\", \"clip.clip.transformer.resblocks.11.attn.in_proj_bias\", \"clip.clip.transformer.resblocks.11.attn.out_proj.weight\", \"clip.clip.transformer.resblocks.11.attn.out_proj.bias\", \"clip.clip.transformer.resblocks.11.ln_1.weight\", \"clip.clip.transformer.resblocks.11.ln_1.bias\", \"clip.clip.transformer.resblocks.11.mlp.c_fc.weight\", \"clip.clip.transformer.resblocks.11.mlp.c_fc.bias\", \"clip.clip.transformer.resblocks.11.mlp.c_proj.weight\", \"clip.clip.transformer.resblocks.11.mlp.c_proj.bias\", \"clip.clip.transformer.resblocks.11.ln_2.weight\", \"clip.clip.transformer.resblocks.11.ln_2.bias\", \"clip.clip.token_embedding.weight\", \"clip.clip.ln_final.weight\", \"clip.clip.ln_final.bias\", \"unets.0.text_to_cond.weight\", \"unets.0.text_to_cond.bias\", \"unets.0.init_resnet_block.time_mlp.1.weight\", \"unets.0.init_resnet_block.time_mlp.1.bias\", \"unets.0.init_resnet_block.block1.project.weight\", \"unets.0.init_resnet_block.block1.project.bias\", \"unets.0.init_resnet_block.block1.norm.weight\", \"unets.0.init_resnet_block.block1.norm.bias\", \"unets.0.init_resnet_block.block2.project.weight\", \"unets.0.init_resnet_block.block2.project.bias\", \"unets.0.init_resnet_block.block2.norm.weight\", \"unets.0.init_resnet_block.block2.norm.bias\", \"unets.0.downs.0.0.1.weight\", \"unets.0.downs.0.0.1.bias\", \"unets.0.downs.0.2.0.time_mlp.1.weight\", \"unets.0.downs.0.2.0.time_mlp.1.bias\", \"unets.0.downs.0.2.0.block1.project.weight\", \"unets.0.downs.0.2.0.block1.project.bias\", \"unets.0.downs.0.2.0.block1.norm.weight\", \"unets.0.downs.0.2.0.block1.norm.bias\", \"unets.0.downs.0.2.0.block2.project.weight\", \"unets.0.downs.0.2.0.block2.project.bias\", \"unets.0.downs.0.2.0.block2.norm.weight\", \"unets.0.downs.0.2.0.block2.norm.bias\", \"unets.0.downs.0.2.1.time_mlp.1.weight\", \"unets.0.downs.0.2.1.time_mlp.1.bias\", \"unets.0.downs.0.2.1.block1.project.weight\", \"unets.0.downs.0.2.1.block1.project.bias\", \"unets.0.downs.0.2.1.block1.norm.weight\", \"unets.0.downs.0.2.1.block1.norm.bias\", \"unets.0.downs.0.2.1.block2.project.weight\", \"unets.0.downs.0.2.1.block2.project.bias\", \"unets.0.downs.0.2.1.block2.norm.weight\", \"unets.0.downs.0.2.1.block2.norm.bias\", \"unets.0.downs.0.2.2.time_mlp.1.weight\", \"unets.0.downs.0.2.2.time_mlp.1.bias\", \"unets.0.downs.0.2.2.block1.project.weight\", \"unets.0.downs.0.2.2.block1.project.bias\", \"unets.0.downs.0.2.2.block1.norm.weight\", \"unets.0.downs.0.2.2.block1.norm.bias\", \"unets.0.downs.0.2.2.block2.project.weight\", \"unets.0.downs.0.2.2.block2.project.bias\", \"unets.0.downs.0.2.2.block2.norm.weight\", \"unets.0.downs.0.2.2.block2.norm.bias\", \"unets.0.downs.0.2.3.time_mlp.1.weight\", \"unets.0.downs.0.2.3.time_mlp.1.bias\", \"unets.0.downs.0.2.3.block1.project.weight\", \"unets.0.downs.0.2.3.block1.project.bias\", \"unets.0.downs.0.2.3.block1.norm.weight\", \"unets.0.downs.0.2.3.block1.norm.bias\", \"unets.0.downs.0.2.3.block2.project.weight\", \"unets.0.downs.0.2.3.block2.project.bias\", \"unets.0.downs.0.2.3.block2.norm.weight\", \"unets.0.downs.0.2.3.block2.norm.bias\", \"unets.0.downs.0.3.fn.norm.g\", \"unets.0.downs.0.3.fn.to_qkv.weight\", \"unets.0.downs.0.3.fn.to_out.0.weight\", \"unets.0.downs.0.3.fn.to_out.1.g\", \"unets.0.downs.1.0.1.weight\", \"unets.0.downs.1.0.1.bias\", \"unets.0.downs.1.2.0.time_mlp.1.weight\", \"unets.0.downs.1.2.0.time_mlp.1.bias\", \"unets.0.downs.1.2.0.cross_attn.null_kv\", \"unets.0.downs.1.2.0.cross_attn.norm.g\", \"unets.0.downs.1.2.0.cross_attn.to_q.weight\", \"unets.0.downs.1.2.0.cross_attn.to_kv.weight\", \"unets.0.downs.1.2.0.cross_attn.to_out.0.weight\", \"unets.0.downs.1.2.0.cross_attn.to_out.1.g\", \"unets.0.downs.1.2.0.block1.project.weight\", \"unets.0.downs.1.2.0.block1.project.bias\", \"unets.0.downs.1.2.0.block1.norm.weight\", \"unets.0.downs.1.2.0.block1.norm.bias\", \"unets.0.downs.1.2.0.block2.project.weight\", \"unets.0.downs.1.2.0.block2.project.bias\", \"unets.0.downs.1.2.0.block2.norm.weight\", \"unets.0.downs.1.2.0.block2.norm.bias\", \"unets.0.downs.1.2.1.time_mlp.1.weight\", \"unets.0.downs.1.2.1.time_mlp.1.bias\", \"unets.0.downs.1.2.1.cross_attn.null_kv\", \"unets.0.downs.1.2.1.cross_attn.norm.g\", \"unets.0.downs.1.2.1.cross_attn.to_q.weight\", \"unets.0.downs.1.2.1.cross_attn.to_kv.weight\", \"unets.0.downs.1.2.1.cross_attn.to_out.0.weight\", \"unets.0.downs.1.2.1.cross_attn.to_out.1.g\", \"unets.0.downs.1.2.1.block1.project.weight\", \"unets.0.downs.1.2.1.block1.project.bias\", \"unets.0.downs.1.2.1.block1.norm.weight\", \"unets.0.downs.1.2.1.block1.norm.bias\", \"unets.0.downs.1.2.1.block2.project.weight\", \"unets.0.downs.1.2.1.block2.project.bias\", \"unets.0.downs.1.2.1.block2.norm.weight\", \"unets.0.downs.1.2.1.block2.norm.bias\", \"unets.0.downs.1.2.2.time_mlp.1.weight\", \"unets.0.downs.1.2.2.time_mlp.1.bias\", \"unets.0.downs.1.2.2.cross_attn.null_kv\", \"unets.0.downs.1.2.2.cross_attn.norm.g\", \"unets.0.downs.1.2.2.cross_attn.to_q.weight\", \"unets.0.downs.1.2.2.cross_attn.to_kv.weight\", \"unets.0.downs.1.2.2.cross_attn.to_out.0.weight\", \"unets.0.downs.1.2.2.cross_attn.to_out.1.g\", \"unets.0.downs.1.2.2.block1.project.weight\", \"unets.0.downs.1.2.2.block1.project.bias\", \"unets.0.downs.1.2.2.block1.norm.weight\", \"unets.0.downs.1.2.2.block1.norm.bias\", \"unets.0.downs.1.2.2.block2.project.weight\", \"unets.0.downs.1.2.2.block2.project.bias\", \"unets.0.downs.1.2.2.block2.norm.weight\", \"unets.0.downs.1.2.2.block2.norm.bias\", \"unets.0.downs.1.2.3.time_mlp.1.weight\", \"unets.0.downs.1.2.3.time_mlp.1.bias\", \"unets.0.downs.1.2.3.cross_attn.null_kv\", \"unets.0.downs.1.2.3.cross_attn.norm.g\", \"unets.0.downs.1.2.3.cross_attn.to_q.weight\", \"unets.0.downs.1.2.3.cross_attn.to_kv.weight\", \"unets.0.downs.1.2.3.cross_attn.to_out.0.weight\", \"unets.0.downs.1.2.3.cross_attn.to_out.1.g\", \"unets.0.downs.1.2.3.block1.project.weight\", \"unets.0.downs.1.2.3.block1.project.bias\", \"unets.0.downs.1.2.3.block1.norm.weight\", \"unets.0.downs.1.2.3.block1.norm.bias\", \"unets.0.downs.1.2.3.block2.project.weight\", \"unets.0.downs.1.2.3.block2.project.bias\", \"unets.0.downs.1.2.3.block2.norm.weight\", \"unets.0.downs.1.2.3.block2.norm.bias\", \"unets.0.downs.1.3.fn.norm.g\", \"unets.0.downs.1.3.fn.to_qkv.weight\", \"unets.0.downs.1.3.fn.to_out.0.weight\", \"unets.0.downs.1.3.fn.to_out.1.g\", \"unets.0.downs.2.0.1.weight\", \"unets.0.downs.2.0.1.bias\", \"unets.0.downs.2.2.0.time_mlp.1.weight\", \"unets.0.downs.2.2.0.time_mlp.1.bias\", \"unets.0.downs.2.2.0.cross_attn.null_kv\", \"unets.0.downs.2.2.0.cross_attn.norm.g\", \"unets.0.downs.2.2.0.cross_attn.to_q.weight\", \"unets.0.downs.2.2.0.cross_attn.to_kv.weight\", \"unets.0.downs.2.2.0.cross_attn.to_out.0.weight\", \"unets.0.downs.2.2.0.cross_attn.to_out.1.g\", \"unets.0.downs.2.2.0.block1.project.weight\", \"unets.0.downs.2.2.0.block1.project.bias\", \"unets.0.downs.2.2.0.block1.norm.weight\", \"unets.0.downs.2.2.0.block1.norm.bias\", \"unets.0.downs.2.2.0.block2.project.weight\", \"unets.0.downs.2.2.0.block2.project.bias\", \"unets.0.downs.2.2.0.block2.norm.weight\", \"unets.0.downs.2.2.0.block2.norm.bias\", \"unets.0.downs.2.2.1.time_mlp.1.weight\", \"unets.0.downs.2.2.1.time_mlp.1.bias\", \"unets.0.downs.2.2.1.cross_attn.null_kv\", \"unets.0.downs.2.2.1.cross_attn.norm.g\", \"unets.0.downs.2.2.1.cross_attn.to_q.weight\", \"unets.0.downs.2.2.1.cross_attn.to_kv.weight\", \"unets.0.downs.2.2.1.cross_attn.to_out.0.weight\", \"unets.0.downs.2.2.1.cross_attn.to_out.1.g\", \"unets.0.downs.2.2.1.block1.project.weight\", \"unets.0.downs.2.2.1.block1.project.bias\", \"unets.0.downs.2.2.1.block1.norm.weight\", \"unets.0.downs.2.2.1.block1.norm.bias\", \"unets.0.downs.2.2.1.block2.project.weight\", \"unets.0.downs.2.2.1.block2.project.bias\", \"unets.0.downs.2.2.1.block2.norm.weight\", \"unets.0.downs.2.2.1.block2.norm.bias\", \"unets.0.downs.2.2.2.time_mlp.1.weight\", \"unets.0.downs.2.2.2.time_mlp.1.bias\", \"unets.0.downs.2.2.2.cross_attn.null_kv\", \"unets.0.downs.2.2.2.cross_attn.norm.g\", \"unets.0.downs.2.2.2.cross_attn.to_q.weight\", \"unets.0.downs.2.2.2.cross_attn.to_kv.weight\", \"unets.0.downs.2.2.2.cross_attn.to_out.0.weight\", \"unets.0.downs.2.2.2.cross_attn.to_out.1.g\", \"unets.0.downs.2.2.2.block1.project.weight\", \"unets.0.downs.2.2.2.block1.project.bias\", \"unets.0.downs.2.2.2.block1.norm.weight\", \"unets.0.downs.2.2.2.block1.norm.bias\", \"unets.0.downs.2.2.2.block2.project.weight\", \"unets.0.downs.2.2.2.block2.project.bias\", \"unets.0.downs.2.2.2.block2.norm.weight\", \"unets.0.downs.2.2.2.block2.norm.bias\", \"unets.0.downs.2.2.3.time_mlp.1.weight\", \"unets.0.downs.2.2.3.time_mlp.1.bias\", \"unets.0.downs.2.2.3.cross_attn.null_kv\", \"unets.0.downs.2.2.3.cross_attn.norm.g\", \"unets.0.downs.2.2.3.cross_attn.to_q.weight\", \"unets.0.downs.2.2.3.cross_attn.to_kv.weight\", \"unets.0.downs.2.2.3.cross_attn.to_out.0.weight\", \"unets.0.downs.2.2.3.cross_attn.to_out.1.g\", \"unets.0.downs.2.2.3.block1.project.weight\", \"unets.0.downs.2.2.3.block1.project.bias\", \"unets.0.downs.2.2.3.block1.norm.weight\", \"unets.0.downs.2.2.3.block1.norm.bias\", \"unets.0.downs.2.2.3.block2.project.weight\", \"unets.0.downs.2.2.3.block2.project.bias\", \"unets.0.downs.2.2.3.block2.norm.weight\", \"unets.0.downs.2.2.3.block2.norm.bias\", \"unets.0.downs.2.3.fn.norm.g\", \"unets.0.downs.2.3.fn.to_qkv.weight\", \"unets.0.downs.2.3.fn.to_out.0.weight\", \"unets.0.downs.2.3.fn.to_out.1.g\", \"unets.0.downs.3.0.1.weight\", \"unets.0.downs.3.0.1.bias\", \"unets.0.downs.3.2.0.time_mlp.1.weight\", \"unets.0.downs.3.2.0.time_mlp.1.bias\", \"unets.0.downs.3.2.0.cross_attn.null_kv\", \"unets.0.downs.3.2.0.cross_attn.norm.g\", \"unets.0.downs.3.2.0.cross_attn.to_q.weight\", \"unets.0.downs.3.2.0.cross_attn.to_kv.weight\", \"unets.0.downs.3.2.0.cross_attn.to_out.0.weight\", \"unets.0.downs.3.2.0.cross_attn.to_out.1.g\", \"unets.0.downs.3.2.0.block1.project.weight\", \"unets.0.downs.3.2.0.block1.project.bias\", \"unets.0.downs.3.2.0.block1.norm.weight\", \"unets.0.downs.3.2.0.block1.norm.bias\", \"unets.0.downs.3.2.0.block2.project.weight\", \"unets.0.downs.3.2.0.block2.project.bias\", \"unets.0.downs.3.2.0.block2.norm.weight\", \"unets.0.downs.3.2.0.block2.norm.bias\", \"unets.0.downs.3.2.1.time_mlp.1.weight\", \"unets.0.downs.3.2.1.time_mlp.1.bias\", \"unets.0.downs.3.2.1.cross_attn.null_kv\", \"unets.0.downs.3.2.1.cross_attn.norm.g\", \"unets.0.downs.3.2.1.cross_attn.to_q.weight\", \"unets.0.downs.3.2.1.cross_attn.to_kv.weight\", \"unets.0.downs.3.2.1.cross_attn.to_out.0.weight\", \"unets.0.downs.3.2.1.cross_attn.to_out.1.g\", \"unets.0.downs.3.2.1.block1.project.weight\", \"unets.0.downs.3.2.1.block1.project.bias\", \"unets.0.downs.3.2.1.block1.norm.weight\", \"unets.0.downs.3.2.1.block1.norm.bias\", \"unets.0.downs.3.2.1.block2.project.weight\", \"unets.0.downs.3.2.1.block2.project.bias\", \"unets.0.downs.3.2.1.block2.norm.weight\", \"unets.0.downs.3.2.1.block2.norm.bias\", \"unets.0.downs.3.2.2.time_mlp.1.weight\", \"unets.0.downs.3.2.2.time_mlp.1.bias\", \"unets.0.downs.3.2.2.cross_attn.null_kv\", \"unets.0.downs.3.2.2.cross_attn.norm.g\", \"unets.0.downs.3.2.2.cross_attn.to_q.weight\", \"unets.0.downs.3.2.2.cross_attn.to_kv.weight\", \"unets.0.downs.3.2.2.cross_attn.to_out.0.weight\", \"unets.0.downs.3.2.2.cross_attn.to_out.1.g\", \"unets.0.downs.3.2.2.block1.project.weight\", \"unets.0.downs.3.2.2.block1.project.bias\", \"unets.0.downs.3.2.2.block1.norm.weight\", \"unets.0.downs.3.2.2.block1.norm.bias\", \"unets.0.downs.3.2.2.block2.project.weight\", \"unets.0.downs.3.2.2.block2.project.bias\", \"unets.0.downs.3.2.2.block2.norm.weight\", \"unets.0.downs.3.2.2.block2.norm.bias\", \"unets.0.downs.3.2.3.time_mlp.1.weight\", \"unets.0.downs.3.2.3.time_mlp.1.bias\", \"unets.0.downs.3.2.3.cross_attn.null_kv\", \"unets.0.downs.3.2.3.cross_attn.norm.g\", \"unets.0.downs.3.2.3.cross_attn.to_q.weight\", \"unets.0.downs.3.2.3.cross_attn.to_kv.weight\", \"unets.0.downs.3.2.3.cross_attn.to_out.0.weight\", \"unets.0.downs.3.2.3.cross_attn.to_out.1.g\", \"unets.0.downs.3.2.3.block1.project.weight\", \"unets.0.downs.3.2.3.block1.project.bias\", \"unets.0.downs.3.2.3.block1.norm.weight\", \"unets.0.downs.3.2.3.block1.norm.bias\", \"unets.0.downs.3.2.3.block2.project.weight\", \"unets.0.downs.3.2.3.block2.project.bias\", \"unets.0.downs.3.2.3.block2.norm.weight\", \"unets.0.downs.3.2.3.block2.norm.bias\", \"unets.0.downs.3.3.fn.norm.g\", \"unets.0.downs.3.3.fn.to_qkv.weight\", \"unets.0.downs.3.3.fn.to_out.0.weight\", \"unets.0.downs.3.3.fn.to_out.1.g\", \"unets.0.downs.3.4.weight\", \"unets.0.downs.3.4.bias\", \"unets.0.ups.0.0.cross_attn.null_kv\", \"unets.0.ups.0.0.cross_attn.norm.g\", \"unets.0.ups.0.0.cross_attn.to_q.weight\", \"unets.0.ups.0.0.cross_attn.to_kv.weight\", \"unets.0.ups.0.0.cross_attn.to_out.0.weight\", \"unets.0.ups.0.0.cross_attn.to_out.1.g\", \"unets.0.ups.0.1.0.time_mlp.1.weight\", \"unets.0.ups.0.1.0.time_mlp.1.bias\", \"unets.0.ups.0.1.0.cross_attn.null_kv\", \"unets.0.ups.0.1.0.cross_attn.norm.g\", \"unets.0.ups.0.1.0.cross_attn.to_q.weight\", \"unets.0.ups.0.1.0.cross_attn.to_kv.weight\", \"unets.0.ups.0.1.0.cross_attn.to_out.0.weight\", \"unets.0.ups.0.1.0.cross_attn.to_out.1.g\", \"unets.0.ups.0.1.0.block1.project.weight\", \"unets.0.ups.0.1.0.block1.project.bias\", \"unets.0.ups.0.1.0.block1.norm.weight\", \"unets.0.ups.0.1.0.block1.norm.bias\", \"unets.0.ups.0.1.0.block2.project.weight\", \"unets.0.ups.0.1.0.block2.project.bias\", \"unets.0.ups.0.1.0.block2.norm.weight\", \"unets.0.ups.0.1.0.block2.norm.bias\", \"unets.0.ups.0.1.0.res_conv.weight\", \"unets.0.ups.0.1.0.res_conv.bias\", \"unets.0.ups.0.1.1.time_mlp.1.weight\", \"unets.0.ups.0.1.1.time_mlp.1.bias\", \"unets.0.ups.0.1.1.cross_attn.null_kv\", \"unets.0.ups.0.1.1.cross_attn.norm.g\", \"unets.0.ups.0.1.1.cross_attn.to_q.weight\", \"unets.0.ups.0.1.1.cross_attn.to_kv.weight\", \"unets.0.ups.0.1.1.cross_attn.to_out.0.weight\", \"unets.0.ups.0.1.1.cross_attn.to_out.1.g\", \"unets.0.ups.0.1.1.block1.project.weight\", \"unets.0.ups.0.1.1.block1.project.bias\", \"unets.0.ups.0.1.1.block1.norm.weight\", \"unets.0.ups.0.1.1.block1.norm.bias\", \"unets.0.ups.0.1.1.block2.project.weight\", \"unets.0.ups.0.1.1.block2.project.bias\", \"unets.0.ups.0.1.1.block2.norm.weight\", \"unets.0.ups.0.1.1.block2.norm.bias\", \"unets.0.ups.0.1.1.res_conv.weight\", \"unets.0.ups.0.1.1.res_conv.bias\", \"unets.0.ups.0.1.2.time_mlp.1.weight\", \"unets.0.ups.0.1.2.time_mlp.1.bias\", \"unets.0.ups.0.1.2.cross_attn.null_kv\", \"unets.0.ups.0.1.2.cross_attn.norm.g\", \"unets.0.ups.0.1.2.cross_attn.to_q.weight\", \"unets.0.ups.0.1.2.cross_attn.to_kv.weight\", \"unets.0.ups.0.1.2.cross_attn.to_out.0.weight\", \"unets.0.ups.0.1.2.cross_attn.to_out.1.g\", \"unets.0.ups.0.1.2.block1.project.weight\", \"unets.0.ups.0.1.2.block1.project.bias\", \"unets.0.ups.0.1.2.block1.norm.weight\", \"unets.0.ups.0.1.2.block1.norm.bias\", \"unets.0.ups.0.1.2.block2.project.weight\", \"unets.0.ups.0.1.2.block2.project.bias\", \"unets.0.ups.0.1.2.block2.norm.weight\", \"unets.0.ups.0.1.2.block2.norm.bias\", \"unets.0.ups.0.1.2.res_conv.weight\", \"unets.0.ups.0.1.2.res_conv.bias\", \"unets.0.ups.0.1.3.time_mlp.1.weight\", \"unets.0.ups.0.1.3.time_mlp.1.bias\", \"unets.0.ups.0.1.3.cross_attn.null_kv\", \"unets.0.ups.0.1.3.cross_attn.norm.g\", \"unets.0.ups.0.1.3.cross_attn.to_q.weight\", \"unets.0.ups.0.1.3.cross_attn.to_kv.weight\", \"unets.0.ups.0.1.3.cross_attn.to_out.0.weight\", \"unets.0.ups.0.1.3.cross_attn.to_out.1.g\", \"unets.0.ups.0.1.3.block1.project.weight\", \"unets.0.ups.0.1.3.block1.project.bias\", \"unets.0.ups.0.1.3.block1.norm.weight\", \"unets.0.ups.0.1.3.block1.norm.bias\", \"unets.0.ups.0.1.3.block2.project.weight\", \"unets.0.ups.0.1.3.block2.project.bias\", \"unets.0.ups.0.1.3.block2.norm.weight\", \"unets.0.ups.0.1.3.block2.norm.bias\", \"unets.0.ups.0.1.3.res_conv.weight\", \"unets.0.ups.0.1.3.res_conv.bias\", \"unets.0.ups.0.2.fn.norm.g\", \"unets.0.ups.0.2.fn.to_qkv.weight\", \"unets.0.ups.0.2.fn.to_out.0.weight\", \"unets.0.ups.0.2.fn.to_out.1.g\", \"unets.0.ups.0.3.net.0.weight\", \"unets.0.ups.0.3.net.0.bias\", \"unets.0.ups.1.0.cross_attn.null_kv\", \"unets.0.ups.1.0.cross_attn.norm.g\", \"unets.0.ups.1.0.cross_attn.to_q.weight\", \"unets.0.ups.1.0.cross_attn.to_kv.weight\", \"unets.0.ups.1.0.cross_attn.to_out.0.weight\", \"unets.0.ups.1.0.cross_attn.to_out.1.g\", \"unets.0.ups.1.1.0.time_mlp.1.weight\", \"unets.0.ups.1.1.0.time_mlp.1.bias\", \"unets.0.ups.1.1.0.cross_attn.null_kv\", \"unets.0.ups.1.1.0.cross_attn.norm.g\", \"unets.0.ups.1.1.0.cross_attn.to_q.weight\", \"unets.0.ups.1.1.0.cross_attn.to_kv.weight\", \"unets.0.ups.1.1.0.cross_attn.to_out.0.weight\", \"unets.0.ups.1.1.0.cross_attn.to_out.1.g\", \"unets.0.ups.1.1.0.block1.project.weight\", \"unets.0.ups.1.1.0.block1.project.bias\", \"unets.0.ups.1.1.0.block1.norm.weight\", \"unets.0.ups.1.1.0.block1.norm.bias\", \"unets.0.ups.1.1.0.block2.project.weight\", \"unets.0.ups.1.1.0.block2.project.bias\", \"unets.0.ups.1.1.0.block2.norm.weight\", \"unets.0.ups.1.1.0.block2.norm.bias\", \"unets.0.ups.1.1.0.res_conv.weight\", \"unets.0.ups.1.1.0.res_conv.bias\", \"unets.0.ups.1.1.1.time_mlp.1.weight\", \"unets.0.ups.1.1.1.time_mlp.1.bias\", \"unets.0.ups.1.1.1.cross_attn.null_kv\", \"unets.0.ups.1.1.1.cross_attn.norm.g\", \"unets.0.ups.1.1.1.cross_attn.to_q.weight\", \"unets.0.ups.1.1.1.cross_attn.to_kv.weight\", \"unets.0.ups.1.1.1.cross_attn.to_out.0.weight\", \"unets.0.ups.1.1.1.cross_attn.to_out.1.g\", \"unets.0.ups.1.1.1.block1.project.weight\", \"unets.0.ups.1.1.1.block1.project.bias\", \"unets.0.ups.1.1.1.block1.norm.weight\", \"unets.0.ups.1.1.1.block1.norm.bias\", \"unets.0.ups.1.1.1.block2.project.weight\", \"unets.0.ups.1.1.1.block2.project.bias\", \"unets.0.ups.1.1.1.block2.norm.weight\", \"unets.0.ups.1.1.1.block2.norm.bias\", \"unets.0.ups.1.1.1.res_conv.weight\", \"unets.0.ups.1.1.1.res_conv.bias\", \"unets.0.ups.1.1.2.time_mlp.1.weight\", \"unets.0.ups.1.1.2.time_mlp.1.bias\", \"unets.0.ups.1.1.2.cross_attn.null_kv\", \"unets.0.ups.1.1.2.cross_attn.norm.g\", \"unets.0.ups.1.1.2.cross_attn.to_q.weight\", \"unets.0.ups.1.1.2.cross_attn.to_kv.weight\", \"unets.0.ups.1.1.2.cross_attn.to_out.0.weight\", \"unets.0.ups.1.1.2.cross_attn.to_out.1.g\", \"unets.0.ups.1.1.2.block1.project.weight\", \"unets.0.ups.1.1.2.block1.project.bias\", \"unets.0.ups.1.1.2.block1.norm.weight\", \"unets.0.ups.1.1.2.block1.norm.bias\", \"unets.0.ups.1.1.2.block2.project.weight\", \"unets.0.ups.1.1.2.block2.project.bias\", \"unets.0.ups.1.1.2.block2.norm.weight\", \"unets.0.ups.1.1.2.block2.norm.bias\", \"unets.0.ups.1.1.2.res_conv.weight\", \"unets.0.ups.1.1.2.res_conv.bias\", \"unets.0.ups.1.1.3.time_mlp.1.weight\", \"unets.0.ups.1.1.3.time_mlp.1.bias\", \"unets.0.ups.1.1.3.cross_attn.null_kv\", \"unets.0.ups.1.1.3.cross_attn.norm.g\", \"unets.0.ups.1.1.3.cross_attn.to_q.weight\", \"unets.0.ups.1.1.3.cross_attn.to_kv.weight\", \"unets.0.ups.1.1.3.cross_attn.to_out.0.weight\", \"unets.0.ups.1.1.3.cross_attn.to_out.1.g\", \"unets.0.ups.1.1.3.block1.project.weight\", \"unets.0.ups.1.1.3.block1.project.bias\", \"unets.0.ups.1.1.3.block1.norm.weight\", \"unets.0.ups.1.1.3.block1.norm.bias\", \"unets.0.ups.1.1.3.block2.project.weight\", \"unets.0.ups.1.1.3.block2.project.bias\", \"unets.0.ups.1.1.3.block2.norm.weight\", \"unets.0.ups.1.1.3.block2.norm.bias\", \"unets.0.ups.1.1.3.res_conv.weight\", \"unets.0.ups.1.1.3.res_conv.bias\", \"unets.0.ups.1.2.fn.norm.g\", \"unets.0.ups.1.2.fn.to_qkv.weight\", \"unets.0.ups.1.2.fn.to_out.0.weight\", \"unets.0.ups.1.2.fn.to_out.1.g\", \"unets.0.ups.1.3.net.0.weight\", \"unets.0.ups.1.3.net.0.bias\", \"unets.0.ups.2.0.cross_attn.null_kv\", \"unets.0.ups.2.0.cross_attn.norm.g\", \"unets.0.ups.2.0.cross_attn.to_q.weight\", \"unets.0.ups.2.0.cross_attn.to_kv.weight\", \"unets.0.ups.2.0.cross_attn.to_out.0.weight\", \"unets.0.ups.2.0.cross_attn.to_out.1.g\", \"unets.0.ups.2.1.0.time_mlp.1.weight\", \"unets.0.ups.2.1.0.time_mlp.1.bias\", \"unets.0.ups.2.1.0.cross_attn.null_kv\", \"unets.0.ups.2.1.0.cross_attn.norm.g\", \"unets.0.ups.2.1.0.cross_attn.to_q.weight\", \"unets.0.ups.2.1.0.cross_attn.to_kv.weight\", \"unets.0.ups.2.1.0.cross_attn.to_out.0.weight\", \"unets.0.ups.2.1.0.cross_attn.to_out.1.g\", \"unets.0.ups.2.1.0.block1.project.weight\", \"unets.0.ups.2.1.0.block1.project.bias\", \"unets.0.ups.2.1.0.block1.norm.weight\", \"unets.0.ups.2.1.0.block1.norm.bias\", \"unets.0.ups.2.1.0.block2.project.weight\", \"unets.0.ups.2.1.0.block2.project.bias\", \"unets.0.ups.2.1.0.block2.norm.weight\", \"unets.0.ups.2.1.0.block2.norm.bias\", \"unets.0.ups.2.1.0.res_conv.weight\", \"unets.0.ups.2.1.0.res_conv.bias\", \"unets.0.ups.2.1.1.time_mlp.1.weight\", \"unets.0.ups.2.1.1.time_mlp.1.bias\", \"unets.0.ups.2.1.1.cross_attn.null_kv\", \"unets.0.ups.2.1.1.cross_attn.norm.g\", \"unets.0.ups.2.1.1.cross_attn.to_q.weight\", \"unets.0.ups.2.1.1.cross_attn.to_kv.weight\", \"unets.0.ups.2.1.1.cross_attn.to_out.0.weight\", \"unets.0.ups.2.1.1.cross_attn.to_out.1.g\", \"unets.0.ups.2.1.1.block1.project.weight\", \"unets.0.ups.2.1.1.block1.project.bias\", \"unets.0.ups.2.1.1.block1.norm.weight\", \"unets.0.ups.2.1.1.block1.norm.bias\", \"unets.0.ups.2.1.1.block2.project.weight\", \"unets.0.ups.2.1.1.block2.project.bias\", \"unets.0.ups.2.1.1.block2.norm.weight\", \"unets.0.ups.2.1.1.block2.norm.bias\", \"unets.0.ups.2.1.1.res_conv.weight\", \"unets.0.ups.2.1.1.res_conv.bias\", \"unets.0.ups.2.1.2.time_mlp.1.weight\", \"unets.0.ups.2.1.2.time_mlp.1.bias\", \"unets.0.ups.2.1.2.cross_attn.null_kv\", \"unets.0.ups.2.1.2.cross_attn.norm.g\", \"unets.0.ups.2.1.2.cross_attn.to_q.weight\", \"unets.0.ups.2.1.2.cross_attn.to_kv.weight\", \"unets.0.ups.2.1.2.cross_attn.to_out.0.weight\", \"unets.0.ups.2.1.2.cross_attn.to_out.1.g\", \"unets.0.ups.2.1.2.block1.project.weight\", \"unets.0.ups.2.1.2.block1.project.bias\", \"unets.0.ups.2.1.2.block1.norm.weight\", \"unets.0.ups.2.1.2.block1.norm.bias\", \"unets.0.ups.2.1.2.block2.project.weight\", \"unets.0.ups.2.1.2.block2.project.bias\", \"unets.0.ups.2.1.2.block2.norm.weight\", \"unets.0.ups.2.1.2.block2.norm.bias\", \"unets.0.ups.2.1.2.res_conv.weight\", \"unets.0.ups.2.1.2.res_conv.bias\", \"unets.0.ups.2.1.3.time_mlp.1.weight\", \"unets.0.ups.2.1.3.time_mlp.1.bias\", \"unets.0.ups.2.1.3.cross_attn.null_kv\", \"unets.0.ups.2.1.3.cross_attn.norm.g\", \"unets.0.ups.2.1.3.cross_attn.to_q.weight\", \"unets.0.ups.2.1.3.cross_attn.to_kv.weight\", \"unets.0.ups.2.1.3.cross_attn.to_out.0.weight\", \"unets.0.ups.2.1.3.cross_attn.to_out.1.g\", \"unets.0.ups.2.1.3.block1.project.weight\", \"unets.0.ups.2.1.3.block1.project.bias\", \"unets.0.ups.2.1.3.block1.norm.weight\", \"unets.0.ups.2.1.3.block1.norm.bias\", \"unets.0.ups.2.1.3.block2.project.weight\", \"unets.0.ups.2.1.3.block2.project.bias\", \"unets.0.ups.2.1.3.block2.norm.weight\", \"unets.0.ups.2.1.3.block2.norm.bias\", \"unets.0.ups.2.1.3.res_conv.weight\", \"unets.0.ups.2.1.3.res_conv.bias\", \"unets.0.ups.2.2.fn.norm.g\", \"unets.0.ups.2.2.fn.to_qkv.weight\", \"unets.0.ups.2.2.fn.to_out.0.weight\", \"unets.0.ups.2.2.fn.to_out.1.g\", \"unets.0.ups.2.3.net.0.weight\", \"unets.0.ups.2.3.net.0.bias\", \"unets.0.ups.3.1.0.time_mlp.1.weight\", \"unets.0.ups.3.1.0.time_mlp.1.bias\", \"unets.0.ups.3.1.0.block1.project.weight\", \"unets.0.ups.3.1.0.block1.project.bias\", \"unets.0.ups.3.1.0.block1.norm.weight\", \"unets.0.ups.3.1.0.block1.norm.bias\", \"unets.0.ups.3.1.0.block2.project.weight\", \"unets.0.ups.3.1.0.block2.project.bias\", \"unets.0.ups.3.1.0.block2.norm.weight\", \"unets.0.ups.3.1.0.block2.norm.bias\", \"unets.0.ups.3.1.0.res_conv.weight\", \"unets.0.ups.3.1.0.res_conv.bias\", \"unets.0.ups.3.1.1.time_mlp.1.weight\", \"unets.0.ups.3.1.1.time_mlp.1.bias\", \"unets.0.ups.3.1.1.block1.project.weight\", \"unets.0.ups.3.1.1.block1.project.bias\", \"unets.0.ups.3.1.1.block1.norm.weight\", \"unets.0.ups.3.1.1.block1.norm.bias\", \"unets.0.ups.3.1.1.block2.project.weight\", \"unets.0.ups.3.1.1.block2.project.bias\", \"unets.0.ups.3.1.1.block2.norm.weight\", \"unets.0.ups.3.1.1.block2.norm.bias\", \"unets.0.ups.3.1.1.res_conv.weight\", \"unets.0.ups.3.1.1.res_conv.bias\", \"unets.0.ups.3.1.2.time_mlp.1.weight\", \"unets.0.ups.3.1.2.time_mlp.1.bias\", \"unets.0.ups.3.1.2.block1.project.weight\", \"unets.0.ups.3.1.2.block1.project.bias\", \"unets.0.ups.3.1.2.block1.norm.weight\", \"unets.0.ups.3.1.2.block1.norm.bias\", \"unets.0.ups.3.1.2.block2.project.weight\", \"unets.0.ups.3.1.2.block2.project.bias\", \"unets.0.ups.3.1.2.block2.norm.weight\", \"unets.0.ups.3.1.2.block2.norm.bias\", \"unets.0.ups.3.1.2.res_conv.weight\", \"unets.0.ups.3.1.2.res_conv.bias\", \"unets.0.ups.3.1.3.time_mlp.1.weight\", \"unets.0.ups.3.1.3.time_mlp.1.bias\", \"unets.0.ups.3.1.3.block1.project.weight\", \"unets.0.ups.3.1.3.block1.project.bias\", \"unets.0.ups.3.1.3.block1.norm.weight\", \"unets.0.ups.3.1.3.block1.norm.bias\", \"unets.0.ups.3.1.3.block2.project.weight\", \"unets.0.ups.3.1.3.block2.project.bias\", \"unets.0.ups.3.1.3.block2.norm.weight\", \"unets.0.ups.3.1.3.block2.norm.bias\", \"unets.0.ups.3.1.3.res_conv.weight\", \"unets.0.ups.3.1.3.res_conv.bias\", \"unets.0.ups.3.2.fn.norm.g\", \"unets.0.ups.3.2.fn.to_qkv.weight\", \"unets.0.ups.3.2.fn.to_out.0.weight\", \"unets.0.ups.3.2.fn.to_out.1.g\", \"unets.0.ups.3.3.net.0.weight\", \"unets.0.ups.3.3.net.0.bias\", \"unets.0.mid_block1.cross_attn.null_kv\", \"unets.0.mid_block1.cross_attn.norm.g\", \"unets.0.mid_block1.cross_attn.to_q.weight\", \"unets.0.mid_block1.cross_attn.to_kv.weight\", \"unets.0.mid_block1.cross_attn.to_out.0.weight\", \"unets.0.mid_block1.cross_attn.to_out.1.g\", \"unets.0.mid_attn.fn.fn.norm.g\", \"unets.0.mid_attn.fn.fn.to_out.1.g\", \"unets.0.mid_block2.cross_attn.null_kv\", \"unets.0.mid_block2.cross_attn.norm.g\", \"unets.0.mid_block2.cross_attn.to_q.weight\", \"unets.0.mid_block2.cross_attn.to_kv.weight\", \"unets.0.mid_block2.cross_attn.to_out.0.weight\", \"unets.0.mid_block2.cross_attn.to_out.1.g\", \"unets.0.final_resnet_block.time_mlp.1.weight\", \"unets.0.final_resnet_block.time_mlp.1.bias\", \"unets.0.final_resnet_block.block1.project.weight\", \"unets.0.final_resnet_block.block1.project.bias\", \"unets.0.final_resnet_block.block1.norm.weight\", \"unets.0.final_resnet_block.block1.norm.bias\", \"unets.0.final_resnet_block.block2.project.weight\", \"unets.0.final_resnet_block.block2.project.bias\", \"unets.0.final_resnet_block.block2.norm.weight\", \"unets.0.final_resnet_block.block2.norm.bias\", \"unets.0.final_resnet_block.res_conv.weight\", \"unets.0.final_resnet_block.res_conv.bias\", \"unets.0.to_out.weight\", \"unets.0.to_out.bias\". \n\tUnexpected key(s) in state_dict: \"unets.0.final_conv.0.block1.project.weight\", \"unets.0.final_conv.0.block1.project.bias\", \"unets.0.final_conv.0.block1.norm.weight\", \"unets.0.final_conv.0.block1.norm.bias\", \"unets.0.final_conv.0.block2.project.weight\", \"unets.0.final_conv.0.block2.project.bias\", \"unets.0.final_conv.0.block2.norm.weight\", \"unets.0.final_conv.0.block2.norm.bias\", \"unets.0.final_conv.0.res_conv.weight\", \"unets.0.final_conv.0.res_conv.bias\", \"unets.0.final_conv.1.weight\", \"unets.0.final_conv.1.bias\", \"unets.0.downs.0.2.fn.norm.g\", \"unets.0.downs.0.2.fn.to_qkv.weight\", \"unets.0.downs.0.2.fn.to_out.0.weight\", \"unets.0.downs.0.2.fn.to_out.1.g\", \"unets.0.downs.0.3.0.time_mlp.1.weight\", \"unets.0.downs.0.3.0.time_mlp.1.bias\", \"unets.0.downs.0.3.0.block1.project.weight\", \"unets.0.downs.0.3.0.block1.project.bias\", \"unets.0.downs.0.3.0.block1.norm.weight\", \"unets.0.downs.0.3.0.block1.norm.bias\", \"unets.0.downs.0.3.0.block2.project.weight\", \"unets.0.downs.0.3.0.block2.project.bias\", \"unets.0.downs.0.3.0.block2.norm.weight\", \"unets.0.downs.0.3.0.block2.norm.bias\", \"unets.0.downs.0.3.1.time_mlp.1.weight\", \"unets.0.downs.0.3.1.time_mlp.1.bias\", \"unets.0.downs.0.3.1.block1.project.weight\", \"unets.0.downs.0.3.1.block1.project.bias\", \"unets.0.downs.0.3.1.block1.norm.weight\", \"unets.0.downs.0.3.1.block1.norm.bias\", \"unets.0.downs.0.3.1.block2.project.weight\", \"unets.0.downs.0.3.1.block2.project.bias\", \"unets.0.downs.0.3.1.block2.norm.weight\", \"unets.0.downs.0.3.1.block2.norm.bias\", \"unets.0.downs.0.3.2.time_mlp.1.weight\", \"unets.0.downs.0.3.2.time_mlp.1.bias\", \"unets.0.downs.0.3.2.block1.project.weight\", \"unets.0.downs.0.3.2.block1.project.bias\", \"unets.0.downs.0.3.2.block1.norm.weight\", \"unets.0.downs.0.3.2.block1.norm.bias\", \"unets.0.downs.0.3.2.block2.project.weight\", \"unets.0.downs.0.3.2.block2.project.bias\", \"unets.0.downs.0.3.2.block2.norm.weight\", \"unets.0.downs.0.3.2.block2.norm.bias\", \"unets.0.downs.0.3.3.time_mlp.1.weight\", \"unets.0.downs.0.3.3.time_mlp.1.bias\", \"unets.0.downs.0.3.3.block1.project.weight\", \"unets.0.downs.0.3.3.block1.project.bias\", \"unets.0.downs.0.3.3.block1.norm.weight\", \"unets.0.downs.0.3.3.block1.norm.bias\", \"unets.0.downs.0.3.3.block2.project.weight\", \"unets.0.downs.0.3.3.block2.project.bias\", \"unets.0.downs.0.3.3.block2.norm.weight\", \"unets.0.downs.0.3.3.block2.norm.bias\", \"unets.0.downs.1.1.res_conv.weight\", \"unets.0.downs.1.1.res_conv.bias\", \"unets.0.downs.1.2.fn.norm.g\", \"unets.0.downs.1.2.fn.to_qkv.weight\", \"unets.0.downs.1.2.fn.to_out.0.weight\", \"unets.0.downs.1.2.fn.to_out.1.g\", \"unets.0.downs.1.3.0.time_mlp.1.weight\", \"unets.0.downs.1.3.0.time_mlp.1.bias\", \"unets.0.downs.1.3.0.cross_attn.fn.null_kv\", \"unets.0.downs.1.3.0.cross_attn.fn.norm.gamma\", \"unets.0.downs.1.3.0.cross_attn.fn.norm.beta\", \"unets.0.downs.1.3.0.cross_attn.fn.to_q.weight\", \"unets.0.downs.1.3.0.cross_attn.fn.to_kv.weight\", \"unets.0.downs.1.3.0.cross_attn.fn.to_out.0.weight\", \"unets.0.downs.1.3.0.cross_attn.fn.to_out.1.gamma\", \"unets.0.downs.1.3.0.cross_attn.fn.to_out.1.beta\", \"unets.0.downs.1.3.0.block1.project.weight\", \"unets.0.downs.1.3.0.block1.project.bias\", \"unets.0.downs.1.3.0.block1.norm.weight\", \"unets.0.downs.1.3.0.block1.norm.bias\", \"unets.0.downs.1.3.0.block2.project.weight\", \"unets.0.downs.1.3.0.block2.project.bias\", \"unets.0.downs.1.3.0.block2.norm.weight\", \"unets.0.downs.1.3.0.block2.norm.bias\", \"unets.0.downs.1.3.1.time_mlp.1.weight\", \"unets.0.downs.1.3.1.time_mlp.1.bias\", \"unets.0.downs.1.3.1.cross_attn.fn.null_kv\", \"unets.0.downs.1.3.1.cross_attn.fn.norm.gamma\", \"unets.0.downs.1.3.1.cross_attn.fn.norm.beta\", \"unets.0.downs.1.3.1.cross_attn.fn.to_q.weight\", \"unets.0.downs.1.3.1.cross_attn.fn.to_kv.weight\", \"unets.0.downs.1.3.1.cross_attn.fn.to_out.0.weight\", \"unets.0.downs.1.3.1.cross_attn.fn.to_out.1.gamma\", \"unets.0.downs.1.3.1.cross_attn.fn.to_out.1.beta\", \"unets.0.downs.1.3.1.block1.project.weight\", \"unets.0.downs.1.3.1.block1.project.bias\", \"unets.0.downs.1.3.1.block1.norm.weight\", \"unets.0.downs.1.3.1.block1.norm.bias\", \"unets.0.downs.1.3.1.block2.project.weight\", \"unets.0.downs.1.3.1.block2.project.bias\", \"unets.0.downs.1.3.1.block2.norm.weight\", \"unets.0.downs.1.3.1.block2.norm.bias\", \"unets.0.downs.1.3.2.time_mlp.1.weight\", \"unets.0.downs.1.3.2.time_mlp.1.bias\", \"unets.0.downs.1.3.2.cross_attn.fn.null_kv\", \"unets.0.downs.1.3.2.cross_attn.fn.norm.gamma\", \"unets.0.downs.1.3.2.cross_attn.fn.norm.beta\", \"unets.0.downs.1.3.2.cross_attn.fn.to_q.weight\", \"unets.0.downs.1.3.2.cross_attn.fn.to_kv.weight\", \"unets.0.downs.1.3.2.cross_attn.fn.to_out.0.weight\", \"unets.0.downs.1.3.2.cross_attn.fn.to_out.1.gamma\", \"unets.0.downs.1.3.2.cross_attn.fn.to_out.1.beta\", \"unets.0.downs.1.3.2.block1.project.weight\", \"unets.0.downs.1.3.2.block1.project.bias\", \"unets.0.downs.1.3.2.block1.norm.weight\", \"unets.0.downs.1.3.2.block1.norm.bias\", \"unets.0.downs.1.3.2.block2.project.weight\", \"unets.0.downs.1.3.2.block2.project.bias\", \"unets.0.downs.1.3.2.block2.norm.weight\", \"unets.0.downs.1.3.2.block2.norm.bias\", \"unets.0.downs.1.3.3.time_mlp.1.weight\", \"unets.0.downs.1.3.3.time_mlp.1.bias\", \"unets.0.downs.1.3.3.cross_attn.fn.null_kv\", \"unets.0.downs.1.3.3.cross_attn.fn.norm.gamma\", \"unets.0.downs.1.3.3.cross_attn.fn.norm.beta\", \"unets.0.downs.1.3.3.cross_attn.fn.to_q.weight\", \"unets.0.downs.1.3.3.cross_attn.fn.to_kv.weight\", \"unets.0.downs.1.3.3.cross_attn.fn.to_out.0.weight\", \"unets.0.downs.1.3.3.cross_attn.fn.to_out.1.gamma\", \"unets.0.downs.1.3.3.cross_attn.fn.to_out.1.beta\", \"unets.0.downs.1.3.3.block1.project.weight\", \"unets.0.downs.1.3.3.block1.project.bias\", \"unets.0.downs.1.3.3.block1.norm.weight\", \"unets.0.downs.1.3.3.block1.norm.bias\", \"unets.0.downs.1.3.3.block2.project.weight\", \"unets.0.downs.1.3.3.block2.project.bias\", \"unets.0.downs.1.3.3.block2.norm.weight\", \"unets.0.downs.1.3.3.block2.norm.bias\", \"unets.0.downs.2.1.res_conv.weight\", \"unets.0.downs.2.1.res_conv.bias\", \"unets.0.downs.2.2.fn.norm.g\", \"unets.0.downs.2.2.fn.to_qkv.weight\", \"unets.0.downs.2.2.fn.to_out.0.weight\", \"unets.0.downs.2.2.fn.to_out.1.g\", \"unets.0.downs.2.3.0.time_mlp.1.weight\", \"unets.0.downs.2.3.0.time_mlp.1.bias\", \"unets.0.downs.2.3.0.cross_attn.fn.null_kv\", \"unets.0.downs.2.3.0.cross_attn.fn.norm.gamma\", \"unets.0.downs.2.3.0.cross_attn.fn.norm.beta\", \"unets.0.downs.2.3.0.cross_attn.fn.to_q.weight\", \"unets.0.downs.2.3.0.cross_attn.fn.to_kv.weight\", \"unets.0.downs.2.3.0.cross_attn.fn.to_out.0.weight\", \"unets.0.downs.2.3.0.cross_attn.fn.to_out.1.gamma\", \"unets.0.downs.2.3.0.cross_attn.fn.to_out.1.beta\", \"unets.0.downs.2.3.0.block1.project.weight\", \"unets.0.downs.2.3.0.block1.project.bias\", \"unets.0.downs.2.3.0.block1.norm.weight\", \"unets.0.downs.2.3.0.block1.norm.bias\", \"unets.0.downs.2.3.0.block2.project.weight\", \"unets.0.downs.2.3.0.block2.project.bias\", \"unets.0.downs.2.3.0.block2.norm.weight\", \"unets.0.downs.2.3.0.block2.norm.bias\", \"unets.0.downs.2.3.1.time_mlp.1.weight\", \"unets.0.downs.2.3.1.time_mlp.1.bias\", \"unets.0.downs.2.3.1.cross_attn.fn.null_kv\", \"unets.0.downs.2.3.1.cross_attn.fn.norm.gamma\", \"unets.0.downs.2.3.1.cross_attn.fn.norm.beta\", \"unets.0.downs.2.3.1.cross_attn.fn.to_q.weight\", \"unets.0.downs.2.3.1.cross_attn.fn.to_kv.weight\", \"unets.0.downs.2.3.1.cross_attn.fn.to_out.0.weight\", \"unets.0.downs.2.3.1.cross_attn.fn.to_out.1.gamma\", \"unets.0.downs.2.3.1.cross_attn.fn.to_out.1.beta\", \"unets.0.downs.2.3.1.block1.project.weight\", \"unets.0.downs.2.3.1.block1.project.bias\", \"unets.0.downs.2.3.1.block1.norm.weight\", \"unets.0.downs.2.3.1.block1.norm.bias\", \"unets.0.downs.2.3.1.block2.project.weight\", \"unets.0.downs.2.3.1.block2.project.bias\", \"unets.0.downs.2.3.1.block2.norm.weight\", \"unets.0.downs.2.3.1.block2.norm.bias\", \"unets.0.downs.2.3.2.time_mlp.1.weight\", \"unets.0.downs.2.3.2.time_mlp.1.bias\", \"unets.0.downs.2.3.2.cross_attn.fn.null_kv\", \"unets.0.downs.2.3.2.cross_attn.fn.norm.gamma\", \"unets.0.downs.2.3.2.cross_attn.fn.norm.beta\", \"unets.0.downs.2.3.2.cross_attn.fn.to_q.weight\", \"unets.0.downs.2.3.2.cross_attn.fn.to_kv.weight\", \"unets.0.downs.2.3.2.cross_attn.fn.to_out.0.weight\", \"unets.0.downs.2.3.2.cross_attn.fn.to_out.1.gamma\", \"unets.0.downs.2.3.2.cross_attn.fn.to_out.1.beta\", \"unets.0.downs.2.3.2.block1.project.weight\", \"unets.0.downs.2.3.2.block1.project.bias\", \"unets.0.downs.2.3.2.block1.norm.weight\", \"unets.0.downs.2.3.2.block1.norm.bias\", \"unets.0.downs.2.3.2.block2.project.weight\", \"unets.0.downs.2.3.2.block2.project.bias\", \"unets.0.downs.2.3.2.block2.norm.weight\", \"unets.0.downs.2.3.2.block2.norm.bias\", \"unets.0.downs.2.3.3.time_mlp.1.weight\", \"unets.0.downs.2.3.3.time_mlp.1.bias\", \"unets.0.downs.2.3.3.cross_attn.fn.null_kv\", \"unets.0.downs.2.3.3.cross_attn.fn.norm.gamma\", \"unets.0.downs.2.3.3.cross_attn.fn.norm.beta\", \"unets.0.downs.2.3.3.cross_attn.fn.to_q.weight\", \"unets.0.downs.2.3.3.cross_attn.fn.to_kv.weight\", \"unets.0.downs.2.3.3.cross_attn.fn.to_out.0.weight\", \"unets.0.downs.2.3.3.cross_attn.fn.to_out.1.gamma\", \"unets.0.downs.2.3.3.cross_attn.fn.to_out.1.beta\", \"unets.0.downs.2.3.3.block1.project.weight\", \"unets.0.downs.2.3.3.block1.project.bias\", \"unets.0.downs.2.3.3.block1.norm.weight\", \"unets.0.downs.2.3.3.block1.norm.bias\", \"unets.0.downs.2.3.3.block2.project.weight\", \"unets.0.downs.2.3.3.block2.project.bias\", \"unets.0.downs.2.3.3.block2.norm.weight\", \"unets.0.downs.2.3.3.block2.norm.bias\", \"unets.0.downs.3.1.res_conv.weight\", \"unets.0.downs.3.1.res_conv.bias\", \"unets.0.downs.3.2.fn.norm.g\", \"unets.0.downs.3.2.fn.to_qkv.weight\", \"unets.0.downs.3.2.fn.to_out.0.weight\", \"unets.0.downs.3.2.fn.to_out.1.g\", \"unets.0.downs.3.3.0.time_mlp.1.weight\", \"unets.0.downs.3.3.0.time_mlp.1.bias\", \"unets.0.downs.3.3.0.cross_attn.fn.null_kv\", \"unets.0.downs.3.3.0.cross_attn.fn.norm.gamma\", \"unets.0.downs.3.3.0.cross_attn.fn.norm.beta\", \"unets.0.downs.3.3.0.cross_attn.fn.to_q.weight\", \"unets.0.downs.3.3.0.cross_attn.fn.to_kv.weight\", \"unets.0.downs.3.3.0.cross_attn.fn.to_out.0.weight\", \"unets.0.downs.3.3.0.cross_attn.fn.to_out.1.gamma\", \"unets.0.downs.3.3.0.cross_attn.fn.to_out.1.beta\", \"unets.0.downs.3.3.0.block1.project.weight\", \"unets.0.downs.3.3.0.block1.project.bias\", \"unets.0.downs.3.3.0.block1.norm.weight\", \"unets.0.downs.3.3.0.block1.norm.bias\", \"unets.0.downs.3.3.0.block2.project.weight\", \"unets.0.downs.3.3.0.block2.project.bias\", \"unets.0.downs.3.3.0.block2.norm.weight\", \"unets.0.downs.3.3.0.block2.norm.bias\", \"unets.0.downs.3.3.1.time_mlp.1.weight\", \"unets.0.downs.3.3.1.time_mlp.1.bias\", \"unets.0.downs.3.3.1.cross_attn.fn.null_kv\", \"unets.0.downs.3.3.1.cross_attn.fn.norm.gamma\", \"unets.0.downs.3.3.1.cross_attn.fn.norm.beta\", \"unets.0.downs.3.3.1.cross_attn.fn.to_q.weight\", \"unets.0.downs.3.3.1.cross_attn.fn.to_kv.weight\", \"unets.0.downs.3.3.1.cross_attn.fn.to_out.0.weight\", \"unets.0.downs.3.3.1.cross_attn.fn.to_out.1.gamma\", \"unets.0.downs.3.3.1.cross_attn.fn.to_out.1.beta\", \"unets.0.downs.3.3.1.block1.project.weight\", \"unets.0.downs.3.3.1.block1.project.bias\", \"unets.0.downs.3.3.1.block1.norm.weight\", \"unets.0.downs.3.3.1.block1.norm.bias\", \"unets.0.downs.3.3.1.block2.project.weight\", \"unets.0.downs.3.3.1.block2.project.bias\", \"unets.0.downs.3.3.1.block2.norm.weight\", \"unets.0.downs.3.3.1.block2.norm.bias\", \"unets.0.downs.3.3.2.time_mlp.1.weight\", \"unets.0.downs.3.3.2.time_mlp.1.bias\", \"unets.0.downs.3.3.2.cross_attn.fn.null_kv\", \"unets.0.downs.3.3.2.cross_attn.fn.norm.gamma\", \"unets.0.downs.3.3.2.cross_attn.fn.norm.beta\", \"unets.0.downs.3.3.2.cross_attn.fn.to_q.weight\", \"unets.0.downs.3.3.2.cross_attn.fn.to_kv.weight\", \"unets.0.downs.3.3.2.cross_attn.fn.to_out.0.weight\", \"unets.0.downs.3.3.2.cross_attn.fn.to_out.1.gamma\", \"unets.0.downs.3.3.2.cross_attn.fn.to_out.1.beta\", \"unets.0.downs.3.3.2.block1.project.weight\", \"unets.0.downs.3.3.2.block1.project.bias\", \"unets.0.downs.3.3.2.block1.norm.weight\", \"unets.0.downs.3.3.2.block1.norm.bias\", \"unets.0.downs.3.3.2.block2.project.weight\", \"unets.0.downs.3.3.2.block2.project.bias\", \"unets.0.downs.3.3.2.block2.norm.weight\", \"unets.0.downs.3.3.2.block2.norm.bias\", \"unets.0.downs.3.3.3.time_mlp.1.weight\", \"unets.0.downs.3.3.3.time_mlp.1.bias\", \"unets.0.downs.3.3.3.cross_attn.fn.null_kv\", \"unets.0.downs.3.3.3.cross_attn.fn.norm.gamma\", \"unets.0.downs.3.3.3.cross_attn.fn.norm.beta\", \"unets.0.downs.3.3.3.cross_attn.fn.to_q.weight\", \"unets.0.downs.3.3.3.cross_attn.fn.to_kv.weight\", \"unets.0.downs.3.3.3.cross_attn.fn.to_out.0.weight\", \"unets.0.downs.3.3.3.cross_attn.fn.to_out.1.gamma\", \"unets.0.downs.3.3.3.cross_attn.fn.to_out.1.beta\", \"unets.0.downs.3.3.3.block1.project.weight\", \"unets.0.downs.3.3.3.block1.project.bias\", \"unets.0.downs.3.3.3.block1.norm.weight\", \"unets.0.downs.3.3.3.block1.norm.bias\", \"unets.0.downs.3.3.3.block2.project.weight\", \"unets.0.downs.3.3.3.block2.project.bias\", \"unets.0.downs.3.3.3.block2.norm.weight\", \"unets.0.downs.3.3.3.block2.norm.bias\", \"unets.0.ups.0.0.cross_attn.fn.null_kv\", \"unets.0.ups.0.0.cross_attn.fn.norm.gamma\", \"unets.0.ups.0.0.cross_attn.fn.norm.beta\", \"unets.0.ups.0.0.cross_attn.fn.to_q.weight\", \"unets.0.ups.0.0.cross_attn.fn.to_kv.weight\", \"unets.0.ups.0.0.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.0.0.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.0.0.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.0.1.fn.norm.g\", \"unets.0.ups.0.1.fn.to_qkv.weight\", \"unets.0.ups.0.1.fn.to_out.0.weight\", \"unets.0.ups.0.1.fn.to_out.1.g\", \"unets.0.ups.0.2.0.time_mlp.1.weight\", \"unets.0.ups.0.2.0.time_mlp.1.bias\", \"unets.0.ups.0.2.0.cross_attn.fn.null_kv\", \"unets.0.ups.0.2.0.cross_attn.fn.norm.gamma\", \"unets.0.ups.0.2.0.cross_attn.fn.norm.beta\", \"unets.0.ups.0.2.0.cross_attn.fn.to_q.weight\", \"unets.0.ups.0.2.0.cross_attn.fn.to_kv.weight\", \"unets.0.ups.0.2.0.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.0.2.0.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.0.2.0.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.0.2.0.block1.project.weight\", \"unets.0.ups.0.2.0.block1.project.bias\", \"unets.0.ups.0.2.0.block1.norm.weight\", \"unets.0.ups.0.2.0.block1.norm.bias\", \"unets.0.ups.0.2.0.block2.project.weight\", \"unets.0.ups.0.2.0.block2.project.bias\", \"unets.0.ups.0.2.0.block2.norm.weight\", \"unets.0.ups.0.2.0.block2.norm.bias\", \"unets.0.ups.0.2.1.time_mlp.1.weight\", \"unets.0.ups.0.2.1.time_mlp.1.bias\", \"unets.0.ups.0.2.1.cross_attn.fn.null_kv\", \"unets.0.ups.0.2.1.cross_attn.fn.norm.gamma\", \"unets.0.ups.0.2.1.cross_attn.fn.norm.beta\", \"unets.0.ups.0.2.1.cross_attn.fn.to_q.weight\", \"unets.0.ups.0.2.1.cross_attn.fn.to_kv.weight\", \"unets.0.ups.0.2.1.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.0.2.1.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.0.2.1.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.0.2.1.block1.project.weight\", \"unets.0.ups.0.2.1.block1.project.bias\", \"unets.0.ups.0.2.1.block1.norm.weight\", \"unets.0.ups.0.2.1.block1.norm.bias\", \"unets.0.ups.0.2.1.block2.project.weight\", \"unets.0.ups.0.2.1.block2.project.bias\", \"unets.0.ups.0.2.1.block2.norm.weight\", \"unets.0.ups.0.2.1.block2.norm.bias\", \"unets.0.ups.0.2.2.time_mlp.1.weight\", \"unets.0.ups.0.2.2.time_mlp.1.bias\", \"unets.0.ups.0.2.2.cross_attn.fn.null_kv\", \"unets.0.ups.0.2.2.cross_attn.fn.norm.gamma\", \"unets.0.ups.0.2.2.cross_attn.fn.norm.beta\", \"unets.0.ups.0.2.2.cross_attn.fn.to_q.weight\", \"unets.0.ups.0.2.2.cross_attn.fn.to_kv.weight\", \"unets.0.ups.0.2.2.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.0.2.2.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.0.2.2.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.0.2.2.block1.project.weight\", \"unets.0.ups.0.2.2.block1.project.bias\", \"unets.0.ups.0.2.2.block1.norm.weight\", \"unets.0.ups.0.2.2.block1.norm.bias\", \"unets.0.ups.0.2.2.block2.project.weight\", \"unets.0.ups.0.2.2.block2.project.bias\", \"unets.0.ups.0.2.2.block2.norm.weight\", \"unets.0.ups.0.2.2.block2.norm.bias\", \"unets.0.ups.0.2.3.time_mlp.1.weight\", \"unets.0.ups.0.2.3.time_mlp.1.bias\", \"unets.0.ups.0.2.3.cross_attn.fn.null_kv\", \"unets.0.ups.0.2.3.cross_attn.fn.norm.gamma\", \"unets.0.ups.0.2.3.cross_attn.fn.norm.beta\", \"unets.0.ups.0.2.3.cross_attn.fn.to_q.weight\", \"unets.0.ups.0.2.3.cross_attn.fn.to_kv.weight\", \"unets.0.ups.0.2.3.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.0.2.3.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.0.2.3.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.0.2.3.block1.project.weight\", \"unets.0.ups.0.2.3.block1.project.bias\", \"unets.0.ups.0.2.3.block1.norm.weight\", \"unets.0.ups.0.2.3.block1.norm.bias\", \"unets.0.ups.0.2.3.block2.project.weight\", \"unets.0.ups.0.2.3.block2.project.bias\", \"unets.0.ups.0.2.3.block2.norm.weight\", \"unets.0.ups.0.2.3.block2.norm.bias\", \"unets.0.ups.0.3.weight\", \"unets.0.ups.0.3.bias\", \"unets.0.ups.1.0.cross_attn.fn.null_kv\", \"unets.0.ups.1.0.cross_attn.fn.norm.gamma\", \"unets.0.ups.1.0.cross_attn.fn.norm.beta\", \"unets.0.ups.1.0.cross_attn.fn.to_q.weight\", \"unets.0.ups.1.0.cross_attn.fn.to_kv.weight\", \"unets.0.ups.1.0.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.1.0.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.1.0.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.1.1.fn.norm.g\", \"unets.0.ups.1.1.fn.to_qkv.weight\", \"unets.0.ups.1.1.fn.to_out.0.weight\", \"unets.0.ups.1.1.fn.to_out.1.g\", \"unets.0.ups.1.2.0.time_mlp.1.weight\", \"unets.0.ups.1.2.0.time_mlp.1.bias\", \"unets.0.ups.1.2.0.cross_attn.fn.null_kv\", \"unets.0.ups.1.2.0.cross_attn.fn.norm.gamma\", \"unets.0.ups.1.2.0.cross_attn.fn.norm.beta\", \"unets.0.ups.1.2.0.cross_attn.fn.to_q.weight\", \"unets.0.ups.1.2.0.cross_attn.fn.to_kv.weight\", \"unets.0.ups.1.2.0.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.1.2.0.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.1.2.0.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.1.2.0.block1.project.weight\", \"unets.0.ups.1.2.0.block1.project.bias\", \"unets.0.ups.1.2.0.block1.norm.weight\", \"unets.0.ups.1.2.0.block1.norm.bias\", \"unets.0.ups.1.2.0.block2.project.weight\", \"unets.0.ups.1.2.0.block2.project.bias\", \"unets.0.ups.1.2.0.block2.norm.weight\", \"unets.0.ups.1.2.0.block2.norm.bias\", \"unets.0.ups.1.2.1.time_mlp.1.weight\", \"unets.0.ups.1.2.1.time_mlp.1.bias\", \"unets.0.ups.1.2.1.cross_attn.fn.null_kv\", \"unets.0.ups.1.2.1.cross_attn.fn.norm.gamma\", \"unets.0.ups.1.2.1.cross_attn.fn.norm.beta\", \"unets.0.ups.1.2.1.cross_attn.fn.to_q.weight\", \"unets.0.ups.1.2.1.cross_attn.fn.to_kv.weight\", \"unets.0.ups.1.2.1.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.1.2.1.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.1.2.1.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.1.2.1.block1.project.weight\", \"unets.0.ups.1.2.1.block1.project.bias\", \"unets.0.ups.1.2.1.block1.norm.weight\", \"unets.0.ups.1.2.1.block1.norm.bias\", \"unets.0.ups.1.2.1.block2.project.weight\", \"unets.0.ups.1.2.1.block2.project.bias\", \"unets.0.ups.1.2.1.block2.norm.weight\", \"unets.0.ups.1.2.1.block2.norm.bias\", \"unets.0.ups.1.2.2.time_mlp.1.weight\", \"unets.0.ups.1.2.2.time_mlp.1.bias\", \"unets.0.ups.1.2.2.cross_attn.fn.null_kv\", \"unets.0.ups.1.2.2.cross_attn.fn.norm.gamma\", \"unets.0.ups.1.2.2.cross_attn.fn.norm.beta\", \"unets.0.ups.1.2.2.cross_attn.fn.to_q.weight\", \"unets.0.ups.1.2.2.cross_attn.fn.to_kv.weight\", \"unets.0.ups.1.2.2.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.1.2.2.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.1.2.2.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.1.2.2.block1.project.weight\", \"unets.0.ups.1.2.2.block1.project.bias\", \"unets.0.ups.1.2.2.block1.norm.weight\", \"unets.0.ups.1.2.2.block1.norm.bias\", \"unets.0.ups.1.2.2.block2.project.weight\", \"unets.0.ups.1.2.2.block2.project.bias\", \"unets.0.ups.1.2.2.block2.norm.weight\", \"unets.0.ups.1.2.2.block2.norm.bias\", \"unets.0.ups.1.2.3.time_mlp.1.weight\", \"unets.0.ups.1.2.3.time_mlp.1.bias\", \"unets.0.ups.1.2.3.cross_attn.fn.null_kv\", \"unets.0.ups.1.2.3.cross_attn.fn.norm.gamma\", \"unets.0.ups.1.2.3.cross_attn.fn.norm.beta\", \"unets.0.ups.1.2.3.cross_attn.fn.to_q.weight\", \"unets.0.ups.1.2.3.cross_attn.fn.to_kv.weight\", \"unets.0.ups.1.2.3.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.1.2.3.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.1.2.3.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.1.2.3.block1.project.weight\", \"unets.0.ups.1.2.3.block1.project.bias\", \"unets.0.ups.1.2.3.block1.norm.weight\", \"unets.0.ups.1.2.3.block1.norm.bias\", \"unets.0.ups.1.2.3.block2.project.weight\", \"unets.0.ups.1.2.3.block2.project.bias\", \"unets.0.ups.1.2.3.block2.norm.weight\", \"unets.0.ups.1.2.3.block2.norm.bias\", \"unets.0.ups.1.3.weight\", \"unets.0.ups.1.3.bias\", \"unets.0.ups.2.0.cross_attn.fn.null_kv\", \"unets.0.ups.2.0.cross_attn.fn.norm.gamma\", \"unets.0.ups.2.0.cross_attn.fn.norm.beta\", \"unets.0.ups.2.0.cross_attn.fn.to_q.weight\", \"unets.0.ups.2.0.cross_attn.fn.to_kv.weight\", \"unets.0.ups.2.0.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.2.0.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.2.0.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.2.1.fn.norm.g\", \"unets.0.ups.2.1.fn.to_qkv.weight\", \"unets.0.ups.2.1.fn.to_out.0.weight\", \"unets.0.ups.2.1.fn.to_out.1.g\", \"unets.0.ups.2.2.0.time_mlp.1.weight\", \"unets.0.ups.2.2.0.time_mlp.1.bias\", \"unets.0.ups.2.2.0.cross_attn.fn.null_kv\", \"unets.0.ups.2.2.0.cross_attn.fn.norm.gamma\", \"unets.0.ups.2.2.0.cross_attn.fn.norm.beta\", \"unets.0.ups.2.2.0.cross_attn.fn.to_q.weight\", \"unets.0.ups.2.2.0.cross_attn.fn.to_kv.weight\", \"unets.0.ups.2.2.0.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.2.2.0.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.2.2.0.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.2.2.0.block1.project.weight\", \"unets.0.ups.2.2.0.block1.project.bias\", \"unets.0.ups.2.2.0.block1.norm.weight\", \"unets.0.ups.2.2.0.block1.norm.bias\", \"unets.0.ups.2.2.0.block2.project.weight\", \"unets.0.ups.2.2.0.block2.project.bias\", \"unets.0.ups.2.2.0.block2.norm.weight\", \"unets.0.ups.2.2.0.block2.norm.bias\", \"unets.0.ups.2.2.1.time_mlp.1.weight\", \"unets.0.ups.2.2.1.time_mlp.1.bias\", \"unets.0.ups.2.2.1.cross_attn.fn.null_kv\", \"unets.0.ups.2.2.1.cross_attn.fn.norm.gamma\", \"unets.0.ups.2.2.1.cross_attn.fn.norm.beta\", \"unets.0.ups.2.2.1.cross_attn.fn.to_q.weight\", \"unets.0.ups.2.2.1.cross_attn.fn.to_kv.weight\", \"unets.0.ups.2.2.1.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.2.2.1.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.2.2.1.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.2.2.1.block1.project.weight\", \"unets.0.ups.2.2.1.block1.project.bias\", \"unets.0.ups.2.2.1.block1.norm.weight\", \"unets.0.ups.2.2.1.block1.norm.bias\", \"unets.0.ups.2.2.1.block2.project.weight\", \"unets.0.ups.2.2.1.block2.project.bias\", \"unets.0.ups.2.2.1.block2.norm.weight\", \"unets.0.ups.2.2.1.block2.norm.bias\", \"unets.0.ups.2.2.2.time_mlp.1.weight\", \"unets.0.ups.2.2.2.time_mlp.1.bias\", \"unets.0.ups.2.2.2.cross_attn.fn.null_kv\", \"unets.0.ups.2.2.2.cross_attn.fn.norm.gamma\", \"unets.0.ups.2.2.2.cross_attn.fn.norm.beta\", \"unets.0.ups.2.2.2.cross_attn.fn.to_q.weight\", \"unets.0.ups.2.2.2.cross_attn.fn.to_kv.weight\", \"unets.0.ups.2.2.2.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.2.2.2.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.2.2.2.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.2.2.2.block1.project.weight\", \"unets.0.ups.2.2.2.block1.project.bias\", \"unets.0.ups.2.2.2.block1.norm.weight\", \"unets.0.ups.2.2.2.block1.norm.bias\", \"unets.0.ups.2.2.2.block2.project.weight\", \"unets.0.ups.2.2.2.block2.project.bias\", \"unets.0.ups.2.2.2.block2.norm.weight\", \"unets.0.ups.2.2.2.block2.norm.bias\", \"unets.0.ups.2.2.3.time_mlp.1.weight\", \"unets.0.ups.2.2.3.time_mlp.1.bias\", \"unets.0.ups.2.2.3.cross_attn.fn.null_kv\", \"unets.0.ups.2.2.3.cross_attn.fn.norm.gamma\", \"unets.0.ups.2.2.3.cross_attn.fn.norm.beta\", \"unets.0.ups.2.2.3.cross_attn.fn.to_q.weight\", \"unets.0.ups.2.2.3.cross_attn.fn.to_kv.weight\", \"unets.0.ups.2.2.3.cross_attn.fn.to_out.0.weight\", \"unets.0.ups.2.2.3.cross_attn.fn.to_out.1.gamma\", \"unets.0.ups.2.2.3.cross_attn.fn.to_out.1.beta\", \"unets.0.ups.2.2.3.block1.project.weight\", \"unets.0.ups.2.2.3.block1.project.bias\", \"unets.0.ups.2.2.3.block1.norm.weight\", \"unets.0.ups.2.2.3.block1.norm.bias\", \"unets.0.ups.2.2.3.block2.project.weight\", \"unets.0.ups.2.2.3.block2.project.bias\", \"unets.0.ups.2.2.3.block2.norm.weight\", \"unets.0.ups.2.2.3.block2.norm.bias\", \"unets.0.ups.2.3.weight\", \"unets.0.ups.2.3.bias\", \"unets.0.ups.3.1.fn.norm.g\", \"unets.0.ups.3.1.fn.to_qkv.weight\", \"unets.0.ups.3.1.fn.to_out.0.weight\", \"unets.0.ups.3.1.fn.to_out.1.g\", \"unets.0.ups.3.2.0.time_mlp.1.weight\", \"unets.0.ups.3.2.0.time_mlp.1.bias\", \"unets.0.ups.3.2.0.block1.project.weight\", \"unets.0.ups.3.2.0.block1.project.bias\", \"unets.0.ups.3.2.0.block1.norm.weight\", \"unets.0.ups.3.2.0.block1.norm.bias\", \"unets.0.ups.3.2.0.block2.project.weight\", \"unets.0.ups.3.2.0.block2.project.bias\", \"unets.0.ups.3.2.0.block2.norm.weight\", \"unets.0.ups.3.2.0.block2.norm.bias\", \"unets.0.ups.3.2.1.time_mlp.1.weight\", \"unets.0.ups.3.2.1.time_mlp.1.bias\", \"unets.0.ups.3.2.1.block1.project.weight\", \"unets.0.ups.3.2.1.block1.project.bias\", \"unets.0.ups.3.2.1.block1.norm.weight\", \"unets.0.ups.3.2.1.block1.norm.bias\", \"unets.0.ups.3.2.1.block2.project.weight\", \"unets.0.ups.3.2.1.block2.project.bias\", \"unets.0.ups.3.2.1.block2.norm.weight\", \"unets.0.ups.3.2.1.block2.norm.bias\", \"unets.0.ups.3.2.2.time_mlp.1.weight\", \"unets.0.ups.3.2.2.time_mlp.1.bias\", \"unets.0.ups.3.2.2.block1.project.weight\", \"unets.0.ups.3.2.2.block1.project.bias\", \"unets.0.ups.3.2.2.block1.norm.weight\", \"unets.0.ups.3.2.2.block1.norm.bias\", \"unets.0.ups.3.2.2.block2.project.weight\", \"unets.0.ups.3.2.2.block2.project.bias\", \"unets.0.ups.3.2.2.block2.norm.weight\", \"unets.0.ups.3.2.2.block2.norm.bias\", \"unets.0.ups.3.2.3.time_mlp.1.weight\", \"unets.0.ups.3.2.3.time_mlp.1.bias\", \"unets.0.ups.3.2.3.block1.project.weight\", \"unets.0.ups.3.2.3.block1.project.bias\", \"unets.0.ups.3.2.3.block1.norm.weight\", \"unets.0.ups.3.2.3.block1.norm.bias\", \"unets.0.ups.3.2.3.block2.project.weight\", \"unets.0.ups.3.2.3.block2.project.bias\", \"unets.0.ups.3.2.3.block2.norm.weight\", \"unets.0.ups.3.2.3.block2.norm.bias\", \"unets.0.mid_block1.cross_attn.fn.null_kv\", \"unets.0.mid_block1.cross_attn.fn.norm.gamma\", \"unets.0.mid_block1.cross_attn.fn.norm.beta\", \"unets.0.mid_block1.cross_attn.fn.to_q.weight\", \"unets.0.mid_block1.cross_attn.fn.to_kv.weight\", \"unets.0.mid_block1.cross_attn.fn.to_out.0.weight\", \"unets.0.mid_block1.cross_attn.fn.to_out.1.gamma\", \"unets.0.mid_block1.cross_attn.fn.to_out.1.beta\", \"unets.0.mid_attn.fn.fn.norm.gamma\", \"unets.0.mid_attn.fn.fn.norm.beta\", \"unets.0.mid_attn.fn.fn.to_out.1.gamma\", \"unets.0.mid_attn.fn.fn.to_out.1.beta\", \"unets.0.mid_block2.cross_attn.fn.null_kv\", \"unets.0.mid_block2.cross_attn.fn.norm.gamma\", \"unets.0.mid_block2.cross_attn.fn.norm.beta\", \"unets.0.mid_block2.cross_attn.fn.to_q.weight\", \"unets.0.mid_block2.cross_attn.fn.to_kv.weight\", \"unets.0.mid_block2.cross_attn.fn.to_out.0.weight\", \"unets.0.mid_block2.cross_attn.fn.to_out.1.gamma\", \"unets.0.mid_block2.cross_attn.fn.to_out.1.beta\". \n\tsize mismatch for unets.0.downs.0.4.weight: copying a param with shape torch.Size([416, 416, 4, 4]) from checkpoint, the shape in current model is torch.Size([416, 416, 1, 1]).\n\tsize mismatch for unets.0.downs.1.1.block1.project.weight: copying a param with shape torch.Size([832, 416, 3, 3]) from checkpoint, the shape in current model is torch.Size([832, 832, 3, 3]).\n\tsize mismatch for unets.0.downs.1.4.weight: copying a param with shape torch.Size([832, 832, 4, 4]) from checkpoint, the shape in current model is torch.Size([832, 832, 1, 1]).\n\tsize mismatch for unets.0.downs.2.1.block1.project.weight: copying a param with shape torch.Size([1248, 832, 3, 3]) from checkpoint, the shape in current model is torch.Size([1248, 1248, 3, 3]).\n\tsize mismatch for unets.0.downs.2.4.weight: copying a param with shape torch.Size([1248, 1248, 4, 4]) from checkpoint, the shape in current model is torch.Size([1248, 1248, 1, 1]).\n\tsize mismatch for unets.0.downs.3.1.block1.project.weight: copying a param with shape torch.Size([1664, 1248, 3, 3]) from checkpoint, the shape in current model is torch.Size([1664, 1664, 3, 3]).\n\tsize mismatch for unets.0.ups.0.0.time_mlp.1.weight: copying a param with shape torch.Size([2496, 1664]) from checkpoint, the shape in current model is torch.Size([3328, 1664]).\n\tsize mismatch for unets.0.ups.0.0.time_mlp.1.bias: copying a param with shape torch.Size([2496]) from checkpoint, the shape in current model is torch.Size([3328]).\n\tsize mismatch for unets.0.ups.0.0.block1.project.weight: copying a param with shape torch.Size([1248, 3328, 3, 3]) from checkpoint, the shape in current model is torch.Size([1664, 3328, 3, 3]).\n\tsize mismatch for unets.0.ups.0.0.block1.project.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1664]).\n\tsize mismatch for unets.0.ups.0.0.block1.norm.weight: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1664]).\n\tsize mismatch for unets.0.ups.0.0.block1.norm.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1664]).\n\tsize mismatch for unets.0.ups.0.0.block2.project.weight: copying a param with shape torch.Size([1248, 1248, 3, 3]) from checkpoint, the shape in current model is torch.Size([1664, 1664, 3, 3]).\n\tsize mismatch for unets.0.ups.0.0.block2.project.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1664]).\n\tsize mismatch for unets.0.ups.0.0.block2.norm.weight: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1664]).\n\tsize mismatch for unets.0.ups.0.0.block2.norm.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1664]).\n\tsize mismatch for unets.0.ups.0.0.res_conv.weight: copying a param with shape torch.Size([1248, 3328, 1, 1]) from checkpoint, the shape in current model is torch.Size([1664, 3328, 1, 1]).\n\tsize mismatch for unets.0.ups.0.0.res_conv.bias: copying a param with shape torch.Size([1248]) from checkpoint, the shape in current model is torch.Size([1664]).\n\tsize mismatch for unets.0.ups.1.0.time_mlp.1.weight: copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape in current model is torch.Size([2496, 1664]).\n\tsize mismatch for unets.0.ups.1.0.time_mlp.1.bias: copying a param with shape torch.Size([1664]) from checkpoint, the shape in current model is torch.Size([2496]).\n\tsize mismatch for unets.0.ups.1.0.block1.project.weight: copying a param with shape torch.Size([832, 2496, 3, 3]) from checkpoint, the shape in current model is torch.Size([1248, 2496, 3, 3]).\n\tsize mismatch for unets.0.ups.1.0.block1.project.bias: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([1248]).\n\tsize mismatch for unets.0.ups.1.0.block1.norm.weight: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([1248]).\n\tsize mismatch for unets.0.ups.1.0.block1.norm.bias: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([1248]).\n\tsize mismatch for unets.0.ups.1.0.block2.project.weight: copying a param with shape torch.Size([832, 832, 3, 3]) from checkpoint, the shape in current model is torch.Size([1248, 1248, 3, 3]).\n\tsize mismatch for unets.0.ups.1.0.block2.project.bias: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([1248]).\n\tsize mismatch for unets.0.ups.1.0.block2.norm.weight: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([1248]).\n\tsize mismatch for unets.0.ups.1.0.block2.norm.bias: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([1248]).\n\tsize mismatch for unets.0.ups.1.0.res_conv.weight: copying a param with shape torch.Size([832, 2496, 1, 1]) from checkpoint, the shape in current model is torch.Size([1248, 2496, 1, 1]).\n\tsize mismatch for unets.0.ups.1.0.res_conv.bias: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([1248]).\n\tsize mismatch for unets.0.ups.2.0.time_mlp.1.weight: copying a param with shape torch.Size([832, 1664]) from checkpoint, the shape in current model is torch.Size([1664, 1664]).\n\tsize mismatch for unets.0.ups.2.0.time_mlp.1.bias: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([1664]).\n\tsize mismatch for unets.0.ups.2.0.block1.project.weight: copying a param with shape torch.Size([416, 1664, 3, 3]) from checkpoint, the shape in current model is torch.Size([832, 1664, 3, 3]).\n\tsize mismatch for unets.0.ups.2.0.block1.project.bias: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([832]).\n\tsize mismatch for unets.0.ups.2.0.block1.norm.weight: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([832]).\n\tsize mismatch for unets.0.ups.2.0.block1.norm.bias: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([832]).\n\tsize mismatch for unets.0.ups.2.0.block2.project.weight: copying a param with shape torch.Size([416, 416, 3, 3]) from checkpoint, the shape in current model is torch.Size([832, 832, 3, 3]).\n\tsize mismatch for unets.0.ups.2.0.block2.project.bias: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([832]).\n\tsize mismatch for unets.0.ups.2.0.block2.norm.weight: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([832]).\n\tsize mismatch for unets.0.ups.2.0.block2.norm.bias: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([832]).\n\tsize mismatch for unets.0.ups.2.0.res_conv.weight: copying a param with shape torch.Size([416, 1664, 1, 1]) from checkpoint, the shape in current model is torch.Size([832, 1664, 1, 1]).\n\tsize mismatch for unets.0.ups.2.0.res_conv.bias: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([832])."
     ]
    }
   ],
   "source": [
    "\n",
    "# for k in decoder.clip.state_dict().keys():\n",
    "#     decoder_model_state[\"clip.\" + k] = decoder.clip.state_dict()[k]\n",
    "\n",
    "decoder.load_state_dict(decoder_model_state, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, t in enumerate(timesteps):\n",
    "    latent_model_input = torch.cat([latents] * 2) if do_classifier_free_guidance else latents\n",
    "    latent_model_input = noise_scheduler.scale_model_input(latent_model_input, t)\n",
    "    if verbose: print(\"timesteps: {}, latent_model_input: {}, input_embedding: {}\".format(i, latent_model_input.shape, input_embedding.shape))\n",
    "    noise_pred = unet(latent_model_input, t, encoder_hidden_states=input_embedding).sample\n",
    "\n",
    "    # perform guidance\n",
    "    if do_classifier_free_guidance:\n",
    "        noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
    "        noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
    "\n",
    "    # compute the previous noisy sample x_t -> x_t-1\n",
    "    latents = noise_scheduler.step(noise_pred, t, latents).prev_sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
