{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import clip\n",
    "import torch\n",
    "import redis\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['eeg', 'session', 'img', 'text', 'repeat_id', 'class_label', 'ch_names', 'times'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'things-eeg-small'\n",
    "subject = 'sub-08'\n",
    "path = f'/root/workspace/wht/multimodal_brain/datasets/things-eeg-small/Preprocessed_data_250Hz/{subject}/train.pt'\n",
    "data = torch.load(path)\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "int64\n",
      "<U74\n",
      "<U18\n",
      "int64\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "for key in ['eeg','session','img','text','repeat_id','class_label']:\n",
    "    print(data[key].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "r = redis.Redis(host='localhost', port=6379, db=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "for i in range(len(data['eeg'])):\n",
    "    _data = {\n",
    "        \"eeg\": pickle.dumps(data['eeg'][i].astype(np.float32)),          \n",
    "        \"session\":int(data['session'][i]),         \n",
    "        \"img\": data['img'][i],         \n",
    "        \"text\": data['text'][i],         \n",
    "        \"repeat_id\": int(data['repeat_id'][i]),         \n",
    "        \"class_label\": int(data['class_label'][i]),         \n",
    "    }\n",
    "    r.hset(f\"eeg_{dataset}_{subject}_{i}\", mapping=_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.flushall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keys in the database: 66160\n",
      "时间: 76.6370165348053 秒\n"
     ]
    }
   ],
   "source": [
    "import time,random\n",
    "db_size = r.dbsize()\n",
    "print(\"Number of keys in the database:\", db_size)\n",
    "# print(r.keys())\n",
    "\n",
    "start_time = time.time()\n",
    "keys = r.keys()\n",
    "\n",
    "random.shuffle(keys)\n",
    "\n",
    "for key in r.keys():\n",
    "    key = key.decode('utf-8')\n",
    "    value = r.hgetall(key)\n",
    "    # for k,v in value.items():\n",
    "    #     k =k.decode('utf-8')\n",
    "    #     if k == 'eeg':\n",
    "    #         v = pickle.loads(v)\n",
    "    #         pass\n",
    "    #     else:\n",
    "    #         v =v.decode('utf-8')\n",
    "    #     if k in ['session','repeat_id','class_label']:\n",
    "    #         v = int(v)\n",
    "end_time = time.time()\n",
    "print(f\"时间: {end_time - start_time} 秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "cursor, keys = r.scan(cursor=0)\n",
    "print(len(keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "\n",
    "# 重复次数\n",
    "repeats = 60000\n",
    "\n",
    "# 序列化和反序列化时间列表\n",
    "serialization_times = []\n",
    "deserialization_times = []\n",
    "\n",
    "for _ in range(repeats):\n",
    "    # 创建一个随机的63x250的NumPy矩阵\n",
    "    matrix = np.random.rand(63, 250)\n",
    "\n",
    "    # 序列化时间\n",
    "    start_time = time.time()\n",
    "    serialized_matrix = pickle.dumps(matrix)\n",
    "    serialization_time = time.time() - start_time\n",
    "    serialization_times.append(serialization_time)\n",
    "    \n",
    "    # 反序列化时间\n",
    "    start_time = time.time()\n",
    "    deserialized_matrix = pickle.loads(serialized_matrix)\n",
    "    deserialization_time = time.time() - start_time\n",
    "    deserialization_times.append(deserialization_time)\n",
    "\n",
    "# 计算平均时间\n",
    "avg_serialization_time = sum(serialization_times) \n",
    "avg_deserialization_time = sum(deserialization_times) \n",
    "\n",
    "print(\"Average Serialization Time:\", avg_serialization_time, \"seconds\")\n",
    "print(\"Average Deserialization Time:\", avg_deserialization_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
