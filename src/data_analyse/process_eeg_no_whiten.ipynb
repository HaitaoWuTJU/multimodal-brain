{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os,mne,pickle,torch\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "from sklearn.discriminant_analysis import _cov\n",
    "import scipy\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "\n",
    "def get_args_parser():\n",
    "    \n",
    "    parser = argparse.ArgumentParser('train', add_help=False)\n",
    "    parser.add_argument('--subject', type=int)\n",
    "    return parser.parse_args()\n",
    "\n",
    "sys.argv = ['train', '--subject', '8']\n",
    "args = get_args_parser()\n",
    "\n",
    "sub = args.subject\n",
    "\n",
    "\n",
    "n_ses = 4\n",
    "\n",
    "seed = 20200220\n",
    "re_sfreq= 250\n",
    "tmin = -0.2\n",
    "tmax = 1.0\n",
    "whiten = True\n",
    "\n",
    "project_dir = '/root/workspace/wht/multimodal_brain/datasets/things-eeg-small'\n",
    "\n",
    "if whiten:\n",
    "    save_dir = os.path.join(project_dir,\n",
    "        f'Preprocessed_data_{re_sfreq}Hz_whiten', 'sub-'+format(sub,'02'))\n",
    "else:\n",
    "    save_dir = os.path.join(project_dir,\n",
    "        f'Preprocessed_data_{re_sfreq}Hz_no_whiten', 'sub-'+format(sub,'02'))\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "chan_order = ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F7', 'F5', 'F3',\n",
    "\t\t\t\t  'F1', 'F2', 'F4', 'F6', 'F8', 'FT9', 'FT7', 'FC5', 'FC3', 'FC1', \n",
    "\t\t\t\t  'FCz', 'FC2', 'FC4', 'FC6', 'FT8', 'FT10', 'T7', 'C5', 'C3', 'C1',\n",
    "\t\t\t\t  'Cz', 'C2', 'C4', 'C6', 'T8', 'TP9', 'TP7', 'CP5', 'CP3', 'CP1', \n",
    "\t\t\t\t  'CPz', 'CP2', 'CP4', 'CP6', 'TP8', 'TP10', 'P7', 'P5', 'P3', 'P1',\n",
    "\t\t\t\t  'Pz', 'P2', 'P4', 'P6', 'P8', 'PO7', 'PO3', 'POz', 'PO4', 'PO8',\n",
    "\t\t\t\t  'O1', 'Oz', 'O2']\n",
    "mvnn_dim = 'epochs'\n",
    "\n",
    "def mvnn(epoched_test, epoched_train):\n",
    "\t\n",
    "\t### Loop across data collection sessions ###\n",
    "\twhitened_test = []\n",
    "\twhitened_train = []\n",
    "\tfor s in range(n_ses):\n",
    "\t\tsession_data = [epoched_test[s], epoched_train[s]]\n",
    "\n",
    "\t\t### Compute the covariance matrices ###\n",
    "\t\t# Data partitions covariance matrix of shape:\n",
    "\t\t# Data partitions × EEG channels × EEG channels\n",
    "\t\tsigma_part = np.empty((len(session_data),session_data[0].shape[2],\n",
    "\t\t\tsession_data[0].shape[2]))\n",
    "\t\tfor p in range(sigma_part.shape[0]):\n",
    "\t\t\t# Image conditions covariance matrix of shape:\n",
    "\t\t\t# Image conditions × EEG channels × EEG channels\n",
    "\t\t\tsigma_cond = np.empty((session_data[p].shape[0],\n",
    "\t\t\t\tsession_data[0].shape[2],session_data[0].shape[2]))\n",
    "\t\t\tfor i in tqdm(range(session_data[p].shape[0])):\n",
    "\t\t\t\tcond_data = session_data[p][i]\n",
    "\t\t\t\t# Compute covariace matrices at each time point, and then\n",
    "\t\t\t\t# average across time points\n",
    "\t\t\t\tif mvnn_dim == \"time\":\n",
    "\t\t\t\t\tsigma_cond[i] = np.mean([_cov(cond_data[:,:,t],\n",
    "\t\t\t\t\t\tshrinkage='auto') for t in range(cond_data.shape[2])],\n",
    "\t\t\t\t\t\taxis=0)\n",
    "\t\t\t\t# Compute covariace matrices at each epoch (EEG repetition),\n",
    "\t\t\t\t# and then average across epochs/repetitions\n",
    "\t\t\t\telif mvnn_dim == \"epochs\":\n",
    "\t\t\t\t\tsigma_cond[i] = np.mean([_cov(np.transpose(cond_data[e]),\n",
    "\t\t\t\t\t\tshrinkage='auto') for e in range(cond_data.shape[0])],\n",
    "\t\t\t\t\t\taxis=0)\n",
    "\t\t\t# Average the covariance matrices across image conditions\n",
    "\t\t\tsigma_part[p] = sigma_cond.mean(axis=0)\n",
    "\t\t# # Average the covariance matrices across image partitions\n",
    "\t\t# sigma_tot = sigma_part.mean(axis=0)\n",
    "\t\t# ? It seems not fair to use test data for mvnn, so we change to just use training data\n",
    "\t\tsigma_tot = sigma_part[1]\n",
    "\t\t# Compute the inverse of the covariance matrix\n",
    "\t\tsigma_inv = scipy.linalg.fractional_matrix_power(sigma_tot, -0.5)\n",
    "\n",
    "\t\t### Whiten the data ###\n",
    "\t\twhitened_test.append(np.reshape((np.reshape(session_data[0], (-1,\n",
    "\t\t\tsession_data[0].shape[2],session_data[0].shape[3])).swapaxes(1, 2)\n",
    "\t\t\t@ sigma_inv).swapaxes(1, 2), session_data[0].shape))\n",
    "\t\twhitened_train.append(np.reshape((np.reshape(session_data[1], (-1,\n",
    "\t\t\tsession_data[1].shape[2],session_data[1].shape[3])).swapaxes(1, 2)\n",
    "\t\t\t\t@ sigma_inv).swapaxes(1, 2), session_data[1].shape))\n",
    "\n",
    "\t### Output ###\n",
    "\treturn whitened_test, whitened_train\n",
    "\n",
    "\n",
    "def epoch_data(mode,sub):\n",
    "    epoched_data = []\n",
    "    img_conditions = []\n",
    "    for s in range(n_ses):\n",
    "        ### Load the EEG data and convert it to MNE raw format ###\n",
    "        eeg_dir = os.path.join('Raw_data', 'sub-'+\n",
    "            format(sub,'02'), 'ses-'+format(s+1,'02'), f\"raw_eeg_{mode}.npy\")\n",
    "        eeg_data = np.load(os.path.join(project_dir, eeg_dir),\n",
    "            allow_pickle=True).item()\n",
    "        ch_names = eeg_data['ch_names']\n",
    "        sfreq = eeg_data['sfreq']\n",
    "        ch_types = eeg_data['ch_types']\n",
    "        eeg_data = eeg_data['raw_eeg_data']\n",
    "        # Convert to MNE raw format\n",
    "        info = mne.create_info(ch_names, sfreq, ch_types)\n",
    "        raw = mne.io.RawArray(eeg_data, info)\n",
    "\n",
    "        ### Get events, drop unused channels and reject target trials ###\n",
    "        events = mne.find_events(raw, stim_channel='stim')\n",
    "        # # Select only occipital (O) and posterior (P) channels\n",
    "        # chan_idx = np.asarray(mne.pick_channels_regexp(raw.info['ch_names'],\n",
    "        # \t'^O *|^P *'))\n",
    "        # new_chans = [raw.info['ch_names'][c] for c in chan_idx]\n",
    "        # raw.pick_channels(new_chans)\n",
    "        # * chose all channels\n",
    "        raw.pick_channels(chan_order, ordered=True)\n",
    "        # Reject the target trials (event 99999)\n",
    "        idx_target = np.where(events[:,2] == 99999)[0]\n",
    "        events = np.delete(events, idx_target, 0)\n",
    "        ### Epoching, baseline correction and resampling ###\n",
    "        # * [0, 1.0]\n",
    "        epochs = mne.Epochs(raw, events, tmin=tmin, tmax=tmax, baseline=(None,0),\n",
    "            preload=True)\n",
    "        # Resampling\n",
    "        if re_sfreq < 1000:\n",
    "            epochs.resample(re_sfreq)\n",
    "        ch_names = epochs.info['ch_names']\n",
    "        times = epochs.times\n",
    "\n",
    "        ### Sort the data ###\n",
    "        data = epochs.get_data()\n",
    "        events = epochs.events[:,2]\n",
    "        img_cond = np.unique(events)\n",
    "        # Select only a maximum number of EEG repetitions\n",
    "        if mode == 'test':\n",
    "            max_rep = 20\n",
    "        else:\n",
    "            max_rep = 2\n",
    "        # Sorted data matrix of shape:\n",
    "        # Image conditions × EEG repetitions × EEG channels × EEG time points\n",
    "        sorted_data = np.zeros((len(img_cond),max_rep,data.shape[1],\n",
    "            data.shape[2]))\n",
    "        for i in range(len(img_cond)):\n",
    "            # Find the indices of the selected image condition\n",
    "            idx = np.where(events == img_cond[i])[0]\n",
    "            # Randomly select only the max number of EEG repetitions\n",
    "            idx = shuffle(idx, random_state=seed, n_samples=max_rep)\n",
    "            sorted_data[i] = data[idx]\n",
    "        print(sorted_data[:, :, :, int(abs(tmin)*re_sfreq)+1:].shape)\n",
    "        epoched_data.append(sorted_data[:, :, :, -int(re_sfreq*tmax):])\n",
    "        img_conditions.append(img_cond) \n",
    "    return epoched_data,img_conditions,ch_names,times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=64, n_times=1651180\n",
      "    Range : 0 ... 1651179 =      0.000 ...  1651.179 secs\n",
      "Ready.\n",
      "4080 events found on stim channel stim\n",
      "Event IDs: [    1     2     3     4     5     6     7     8     9    10    11    12\n",
      "    13    14    15    16    17    18    19    20    21    22    23    24\n",
      "    25    26    27    28    29    30    31    32    33    34    35    36\n",
      "    37    38    39    40    41    42    43    44    45    46    47    48\n",
      "    49    50    51    52    53    54    55    56    57    58    59    60\n",
      "    61    62    63    64    65    66    67    68    69    70    71    72\n",
      "    73    74    75    76    77    78    79    80    81    82    83    84\n",
      "    85    86    87    88    89    90    91    92    93    94    95    96\n",
      "    97    98    99   100   101   102   103   104   105   106   107   108\n",
      "   109   110   111   112   113   114   115   116   117   118   119   120\n",
      "   121   122   123   124   125   126   127   128   129   130   131   132\n",
      "   133   134   135   136   137   138   139   140   141   142   143   144\n",
      "   145   146   147   148   149   150   151   152   153   154   155   156\n",
      "   157   158   159   160   161   162   163   164   165   166   167   168\n",
      "   169   170   171   172   173   174   175   176   177   178   179   180\n",
      "   181   182   183   184   185   186   187   188   189   190   191   192\n",
      "   193   194   195   196   197   198   199   200 99999]\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Not setting metadata\n",
      "4056 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 4056 events and 1201 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_117077/1877751280.py:146: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  data = epochs.get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 20, 63, 249)\n",
      "Creating RawArray with float64 data, n_channels=64, n_times=1435420\n",
      "    Range : 0 ... 1435419 =      0.000 ...  1435.419 secs\n",
      "Ready.\n",
      "4080 events found on stim channel stim\n",
      "Event IDs: [    1     2     3     4     5     6     7     8     9    10    11    12\n",
      "    13    14    15    16    17    18    19    20    21    22    23    24\n",
      "    25    26    27    28    29    30    31    32    33    34    35    36\n",
      "    37    38    39    40    41    42    43    44    45    46    47    48\n",
      "    49    50    51    52    53    54    55    56    57    58    59    60\n",
      "    61    62    63    64    65    66    67    68    69    70    71    72\n",
      "    73    74    75    76    77    78    79    80    81    82    83    84\n",
      "    85    86    87    88    89    90    91    92    93    94    95    96\n",
      "    97    98    99   100   101   102   103   104   105   106   107   108\n",
      "   109   110   111   112   113   114   115   116   117   118   119   120\n",
      "   121   122   123   124   125   126   127   128   129   130   131   132\n",
      "   133   134   135   136   137   138   139   140   141   142   143   144\n",
      "   145   146   147   148   149   150   151   152   153   154   155   156\n",
      "   157   158   159   160   161   162   163   164   165   166   167   168\n",
      "   169   170   171   172   173   174   175   176   177   178   179   180\n",
      "   181   182   183   184   185   186   187   188   189   190   191   192\n",
      "   193   194   195   196   197   198   199   200 99999]\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Not setting metadata\n",
      "4056 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 4056 events and 1201 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_117077/1877751280.py:146: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  data = epochs.get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 20, 63, 249)\n",
      "Creating RawArray with float64 data, n_channels=64, n_times=1457940\n",
      "    Range : 0 ... 1457939 =      0.000 ...  1457.939 secs\n",
      "Ready.\n",
      "4080 events found on stim channel stim\n",
      "Event IDs: [    1     2     3     4     5     6     7     8     9    10    11    12\n",
      "    13    14    15    16    17    18    19    20    21    22    23    24\n",
      "    25    26    27    28    29    30    31    32    33    34    35    36\n",
      "    37    38    39    40    41    42    43    44    45    46    47    48\n",
      "    49    50    51    52    53    54    55    56    57    58    59    60\n",
      "    61    62    63    64    65    66    67    68    69    70    71    72\n",
      "    73    74    75    76    77    78    79    80    81    82    83    84\n",
      "    85    86    87    88    89    90    91    92    93    94    95    96\n",
      "    97    98    99   100   101   102   103   104   105   106   107   108\n",
      "   109   110   111   112   113   114   115   116   117   118   119   120\n",
      "   121   122   123   124   125   126   127   128   129   130   131   132\n",
      "   133   134   135   136   137   138   139   140   141   142   143   144\n",
      "   145   146   147   148   149   150   151   152   153   154   155   156\n",
      "   157   158   159   160   161   162   163   164   165   166   167   168\n",
      "   169   170   171   172   173   174   175   176   177   178   179   180\n",
      "   181   182   183   184   185   186   187   188   189   190   191   192\n",
      "   193   194   195   196   197   198   199   200 99999]\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Not setting metadata\n",
      "4056 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 4056 events and 1201 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_117077/1877751280.py:146: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  data = epochs.get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 20, 63, 249)\n",
      "Creating RawArray with float64 data, n_channels=64, n_times=1523380\n",
      "    Range : 0 ... 1523379 =      0.000 ...  1523.379 secs\n",
      "Ready.\n",
      "4080 events found on stim channel stim\n",
      "Event IDs: [    1     2     3     4     5     6     7     8     9    10    11    12\n",
      "    13    14    15    16    17    18    19    20    21    22    23    24\n",
      "    25    26    27    28    29    30    31    32    33    34    35    36\n",
      "    37    38    39    40    41    42    43    44    45    46    47    48\n",
      "    49    50    51    52    53    54    55    56    57    58    59    60\n",
      "    61    62    63    64    65    66    67    68    69    70    71    72\n",
      "    73    74    75    76    77    78    79    80    81    82    83    84\n",
      "    85    86    87    88    89    90    91    92    93    94    95    96\n",
      "    97    98    99   100   101   102   103   104   105   106   107   108\n",
      "   109   110   111   112   113   114   115   116   117   118   119   120\n",
      "   121   122   123   124   125   126   127   128   129   130   131   132\n",
      "   133   134   135   136   137   138   139   140   141   142   143   144\n",
      "   145   146   147   148   149   150   151   152   153   154   155   156\n",
      "   157   158   159   160   161   162   163   164   165   166   167   168\n",
      "   169   170   171   172   173   174   175   176   177   178   179   180\n",
      "   181   182   183   184   185   186   187   188   189   190   191   192\n",
      "   193   194   195   196   197   198   199   200 99999]\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Not setting metadata\n",
      "4056 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 4056 events and 1201 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_117077/1877751280.py:146: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  data = epochs.get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 20, 63, 249)\n",
      "Creating RawArray with float64 data, n_channels=64, n_times=6557560\n",
      "    Range : 0 ... 6557559 =      0.000 ...  6557.559 secs\n",
      "Ready.\n",
      "16800 events found on stim channel stim\n",
      "Event IDs: [    1     2     3 ... 16519 16520 99999]\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Not setting metadata\n",
      "16710 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 16710 events and 1201 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_117077/1877751280.py:146: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  data = epochs.get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8270, 2, 63, 249)\n",
      "Creating RawArray with float64 data, n_channels=64, n_times=6084640\n",
      "    Range : 0 ... 6084639 =      0.000 ...  6084.639 secs\n",
      "Ready.\n",
      "16800 events found on stim channel stim\n",
      "Event IDs: [   31    32    33 ... 16539 16540 99999]\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Not setting metadata\n",
      "16710 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 16710 events and 1201 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_117077/1877751280.py:146: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  data = epochs.get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8270, 2, 63, 249)\n",
      "Creating RawArray with float64 data, n_channels=64, n_times=6128440\n",
      "    Range : 0 ... 6128439 =      0.000 ...  6128.439 secs\n",
      "Ready.\n",
      "16800 events found on stim channel stim\n",
      "Event IDs: [   31    32    33 ... 16529 16530 99999]\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Not setting metadata\n",
      "16710 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 16710 events and 1201 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eeg_test,_,ch_names,times = epoch_data('test',sub)\n",
    "eeg_train,img_conditions_train,_,_ = epoch_data('train',sub)\n",
    "\n",
    "if whiten:\n",
    "    whitened_test, whitened_train =  mvnn(eeg_test, eeg_train)\n",
    "    del eeg_test,eeg_train\n",
    "else:\n",
    "    whitened_test = eeg_test\n",
    "    whitened_train = eeg_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "session_list=np.zeros((200, 80))\n",
    "for s in range(n_ses):\n",
    "    if s == 0:\n",
    "        merged_test = whitened_test[s]\n",
    "    else:\n",
    "        merged_test = np.append(merged_test, whitened_test[s], 1)\n",
    "    start_index = merged_test.shape[1]-whitened_test[s].shape[1]\n",
    "    end_index = merged_test.shape[1]\n",
    "    session_list[:,start_index:end_index]=s\n",
    "\n",
    "del whitened_test\n",
    "\n",
    "# 'img': duplicated_images,\n",
    "# 'label': label,\n",
    "img_directory = f'/dev/shm/wht/datasets/things-eeg-small/Image_set/test_images'\n",
    "all_folders = [d for d in os.listdir(img_directory) if os.path.isdir(os.path.join(img_directory, d))]\n",
    "all_folders.sort()\n",
    "images = []\n",
    "labels = []\n",
    "texts = []\n",
    "for i,folder in enumerate(all_folders):\n",
    "    folder_path = os.path.join(img_directory, folder)\n",
    "    all_images = [img for img in os.listdir(folder_path) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    all_images.sort()\n",
    "    images.extend(os.path.join(folder_path, img).rsplit(\"Image_set/\")[-1] for img in all_images)\n",
    "    labels.extend([i for img in all_images])\n",
    "    texts.extend([img.rsplit('_',1)[0] for img in all_images])\n",
    "img_list = np.tile(np.array(images)[:, np.newaxis], (1, 80))\n",
    "labels_list = np.tile(np.array(labels)[:, np.newaxis], (1, 80))\n",
    "text_list = np.tile(np.array(texts)[:, np.newaxis], (1, 80))\n",
    "print(merged_test.shape,merged_test.dtype)\n",
    "print(img_list.shape)\n",
    "print(labels_list.shape,labels_list.dtype)\n",
    "print(img_list[0,0].split('/')[-1].rsplit('_',1)[0])\n",
    "print(text_list.shape)\n",
    "\n",
    "test_dict = {\n",
    "    'eeg': merged_test.astype(np.float16),\n",
    "    'label':labels_list,\n",
    "    'img':img_list,\n",
    "    'text':text_list,\n",
    "    'session': session_list,\n",
    "    'ch_names': ch_names,\n",
    "    'times': times,\n",
    "}\n",
    "\n",
    "torch.save(test_dict, os.path.join(save_dir,'test.pt'),pickle_protocol=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge and save the training data ###\n",
    "ses_list=np.zeros((33080, 2))\n",
    "for s in range(n_ses):\n",
    "    if s == 0:\n",
    "        white_data = whitened_train[s]\n",
    "        img_cond = img_conditions_train[s]\n",
    "    else:\n",
    "        white_data = np.append(white_data, whitened_train[s], 0)\n",
    "        img_cond = np.append(img_cond, img_conditions_train[s], 0)\n",
    "    start_index = white_data.shape[0] - whitened_train[s].shape[0]\n",
    "    end_index = white_data.shape[0]\n",
    "    ses_list[start_index:end_index] = s\n",
    "\n",
    "del whitened_train\n",
    "print('ses_list',len(ses_list))\n",
    "\n",
    "# Data matrix of shape:\n",
    "# Image conditions × EGG repetitions × EEG channels × EEG time points\n",
    "merged_train = np.zeros((len(np.unique(img_cond)), white_data.shape[1]*2,\n",
    "    white_data.shape[2],white_data.shape[3]))\n",
    "\n",
    "sorted_session_list = np.zeros((16540, 4))\n",
    "for i in range(len(np.unique(img_cond))):\n",
    "    # Find the indices of the selected category\n",
    "    idx = np.where(img_cond == i+1)[0]\n",
    "    \n",
    "    for r in range(len(idx)):\n",
    "        sorted_session_list[i][r*2:r*2+2]=ses_list[idx[r]]\n",
    "        if r == 0:\n",
    "            ordered_data = white_data[idx[r]]\n",
    "        else:\n",
    "            ordered_data = np.append(ordered_data, white_data[idx[r]], 0)\n",
    "    merged_train[i] = ordered_data\n",
    "    \n",
    "del ordered_data\n",
    "\n",
    "img_directory = f'/dev/shm/wht/datasets/things-eeg-small/Image_set/train_images'\n",
    "all_folders = [d for d in os.listdir(img_directory) if os.path.isdir(os.path.join(img_directory, d))]\n",
    "all_folders.sort()\n",
    "images = []  \n",
    "labels = []\n",
    "texts = []\n",
    "for i,folder in enumerate(all_folders):\n",
    "    folder_path = os.path.join(img_directory, folder)\n",
    "    all_images = [img for img in os.listdir(folder_path) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    all_images.sort()\n",
    "    images.extend(os.path.join(folder_path, img).rsplit(\"Image_set/\")[-1] for img in all_images)\n",
    "    labels.extend([i for img in all_images])\n",
    "    texts.extend([img.rsplit('_',1)[0] for img in all_images])\n",
    "    \n",
    "\n",
    "labels_list = np.tile(np.array(labels)[:, np.newaxis], (1, 4))\n",
    "img_list = np.tile(np.array(images)[:, np.newaxis], (1, 4))\n",
    "text_list = np.tile(np.array(texts)[:, np.newaxis], (1, 4))\n",
    "\n",
    "print(merged_train.shape,merged_train.dtype)\n",
    "print(labels_list.shape,labels_list.dtype)\n",
    "print(img_list.shape)\n",
    "print(text_list.shape)\n",
    "print(sorted_session_list.shape)\n",
    "\n",
    "\n",
    "train_dict = {\n",
    "    'eeg': merged_train.astype(np.float16),\n",
    "    'label':labels_list,\n",
    "    'img':img_list,\n",
    "    'text':text_list,\n",
    "    'session':sorted_session_list,\n",
    "    'ch_names': ch_names,\n",
    "    'times': times,\n",
    "}\n",
    "# Create the directory if not existing and save the data\n",
    "if os.path.isdir(save_dir) == False:\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "file_name_train = 'train.pt'\n",
    "torch.save(train_dict, os.path.join(save_dir,file_name_train),pickle_protocol=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
