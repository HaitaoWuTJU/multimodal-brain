{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 14:03:57.342886: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from diffusers import DiffusionPipeline, StableDiffusionPipeline,StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline\n",
    "import torch\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7890'\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7890'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7890'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't connect to the Hub: (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/runwayml/stable-diffusion-v1-5 (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f1b958ec280>: Failed to establish a new connection: [Errno 111] Connection refused')))\"), '(Request ID: efc4df79-b6b6-4a96-94d0-9061e384dabd)').\n",
      "Will try to load from local cache.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c035bb7679a4d4bb593d2c570ef2140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc965e9b960d417b80b695028a592fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make sure you're logged in with `huggingface-cli login`\n",
    "from diffusers import StableDiffusionPipeline, LMSDiscreteScheduler\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "image = pipe(prompt).images[0]\n",
    "\n",
    "image.save(\"results/astronaut_rides_horse.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't connect to the Hub: (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/stabilityai/stable-diffusion-xl-base-1.0 (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f1b9d07a2e0>: Failed to establish a new connection: [Errno 111] Connection refused')))\"), '(Request ID: 53732b46-7627-4f96-a1a6-0c142e886310)').\n",
      "Will try to load from local cache.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9ba158185f41f6890d9e723c0e77dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StableDiffusionXLPipeline {\n",
       "  \"_class_name\": \"StableDiffusionXLPipeline\",\n",
       "  \"_diffusers_version\": \"0.29.2\",\n",
       "  \"_name_or_path\": \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
       "  \"feature_extractor\": [\n",
       "    null,\n",
       "    null\n",
       "  ],\n",
       "  \"force_zeros_for_empty_prompt\": true,\n",
       "  \"image_encoder\": [\n",
       "    null,\n",
       "    null\n",
       "  ],\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"EulerDiscreteScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModel\"\n",
       "  ],\n",
       "  \"text_encoder_2\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModelWithProjection\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"tokenizer_2\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"unet\": [\n",
       "    \"diffusers\",\n",
       "    \"UNet2DConditionModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKL\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = DiffusionPipeline.from_pretrained(pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\")\n",
    "# pipe = StableDiffusionPipeline(\"stabilityai/stable-diffusion-xl-base-1.0\").to(\"cuda\")\n",
    "pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Create an image of a tall cactus in a desert. The cactus has multiple arms, is green, and covered in small spines. The desert features sandy terrain, a few rocks, sparse vegetation, and a bright blue sky with a few clouds.\"\n",
    "for step in [1,5,10,20,30,50,80,100,200,300,500,1000]:\n",
    "    img = pipe(prompt=prompt,num_inference_steps=step).images[0]\n",
    "    img.save(f\"results/cactus_base_s{step}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image_folder = \"results\"\n",
    "image_paths = [f\"{image_folder}/sunflower_base_s{step}.png\" for step in [1,5,10,20,30,50,80,100,200,300,500,1000]]\n",
    "grid_size = (3, 4)\n",
    "\n",
    "assert len(image_paths) == grid_size[0] * grid_size[1], \"Number of images does not match grid size\"\n",
    "\n",
    "# Open the first image to get the size\n",
    "first_img = Image.open(image_paths[0])\n",
    "img_width, img_height = first_img.size\n",
    "\n",
    "# Create a new image with the appropriate size\n",
    "grid_img = Image.new('RGB', (img_width * grid_size[1], img_height * grid_size[0]))\n",
    "\n",
    "# Paste each image into the grid\n",
    "for idx, img_path in enumerate(image_paths):\n",
    "    img = Image.open(img_path)\n",
    "    x = (idx % grid_size[1]) * img_width\n",
    "    y = (idx // grid_size[1]) * img_height\n",
    "    grid_img.paste(img, (x, y))\n",
    "\n",
    "# Save the final grid image\n",
    "grid_img.save(f\"{image_folder}/cactus_grid.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load both base & refiner\n",
    "base = DiffusionPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n",
    ")\n",
    "base.to(\"cuda\")\n",
    "refiner = DiffusionPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
    "    text_encoder_2=base.text_encoder_2,\n",
    "    vae=base.vae,\n",
    "    torch_dtype=torch.float16,\n",
    "    use_safetensors=True,\n",
    "    variant=\"fp16\",\n",
    ")\n",
    "refiner.to(\"cuda\")\n",
    "\n",
    "# Define how many steps and what % of steps to be run on each experts (80/20) here\n",
    "n_steps = 200\n",
    "high_noise_frac = 0.8\n",
    "\n",
    "prompt = \"real sunflower\"\n",
    "\n",
    "# run both experts\n",
    "image = base(\n",
    "    prompt=prompt,\n",
    "    num_inference_steps=n_steps,\n",
    "    denoising_end=high_noise_frac,\n",
    "    output_type=\"latent\",\n",
    ").images\n",
    "\n",
    "image = refiner(\n",
    "    prompt=prompt,\n",
    "    num_inference_steps=n_steps,\n",
    "    denoising_start=high_noise_frac,\n",
    "    image=image,\n",
    ").images[0]\n",
    "\n",
    "image.save(\"results/sunflower_refiner.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
