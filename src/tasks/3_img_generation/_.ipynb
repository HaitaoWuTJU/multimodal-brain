{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-19 03:51:28.185420: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Seed set to 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# from diffusers import DiffusionPipeline, StableDiffusionPipeline,StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline\n",
    "import torch\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "\n",
    "from _pipeline import StableDiffusionXLPipeline, retrieve_timesteps\n",
    "from models import Autoencoder\n",
    "seed_everything(0)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7890'\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7890'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7890'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't connect to the Hub: (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/stabilityai/stable-diffusion-xl-base-1.0 (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fac4c9283a0>: Failed to establish a new connection: [Errno 111] Connection refused')))\"), '(Request ID: 95fc66c4-b80d-444f-a0ea-43427ff8d5ca)').\n",
      "Will try to load from local cache.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09bf23feacb54811bcb4f6e72d6a0ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "config = OmegaConf.load(\"/root/workspace/wht/multimodal_brain/src/tasks/img_generation/configs/base.yaml\")\n",
    "\n",
    "model = {}\n",
    "for k,v in config['models'].items():\n",
    "    if k == 'generation':\n",
    "        model[k] = StableDiffusionXLPipeline.from_pretrained(pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\").to(\"cuda\")\n",
    "    else:\n",
    "        model[k] = globals()[v['name']](**v['args'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet2DConditionModel(\n",
      "  (conv_in): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (time_proj): Timesteps()\n",
      "  (time_embedding): TimestepEmbedding(\n",
      "    (linear_1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "    (act): SiLU()\n",
      "    (linear_2): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  )\n",
      "  (add_time_proj): Timesteps()\n",
      "  (add_embedding): TimestepEmbedding(\n",
      "    (linear_1): Linear(in_features=2816, out_features=1280, bias=True)\n",
      "    (act): SiLU()\n",
      "    (linear_2): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  )\n",
      "  (down_blocks): ModuleList(\n",
      "    (0): DownBlock2D(\n",
      "      (resnets): ModuleList(\n",
      "        (0-1): 2 x ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "        )\n",
      "      )\n",
      "      (downsamplers): ModuleList(\n",
      "        (0): Downsample2D(\n",
      "          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): CrossAttnDownBlock2D(\n",
      "      (attentions): ModuleList(\n",
      "        (0-1): 2 x Transformer2DModel(\n",
      "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "          (proj_in): Linear(in_features=640, out_features=640, bias=True)\n",
      "          (transformer_blocks): ModuleList(\n",
      "            (0-1): 2 x BasicTransformerBlock(\n",
      "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn1): Attention(\n",
      "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn2): Attention(\n",
      "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "                (to_k): Linear(in_features=2048, out_features=640, bias=False)\n",
      "                (to_v): Linear(in_features=2048, out_features=640, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "              (ff): FeedForward(\n",
      "                (net): ModuleList(\n",
      "                  (0): GEGLU(\n",
      "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "                  )\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (proj_out): Linear(in_features=640, out_features=640, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (resnets): ModuleList(\n",
      "        (0): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
      "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
      "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "        )\n",
      "      )\n",
      "      (downsamplers): ModuleList(\n",
      "        (0): Downsample2D(\n",
      "          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): CrossAttnDownBlock2D(\n",
      "      (attentions): ModuleList(\n",
      "        (0-1): 2 x Transformer2DModel(\n",
      "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "          (proj_in): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (transformer_blocks): ModuleList(\n",
      "            (0-9): 10 x BasicTransformerBlock(\n",
      "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn1): Attention(\n",
      "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn2): Attention(\n",
      "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                (to_k): Linear(in_features=2048, out_features=1280, bias=False)\n",
      "                (to_v): Linear(in_features=2048, out_features=1280, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "              (ff): FeedForward(\n",
      "                (net): ModuleList(\n",
      "                  (0): GEGLU(\n",
      "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "                  )\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (proj_out): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (resnets): ModuleList(\n",
      "        (0): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up_blocks): ModuleList(\n",
      "    (0): CrossAttnUpBlock2D(\n",
      "      (attentions): ModuleList(\n",
      "        (0-2): 3 x Transformer2DModel(\n",
      "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "          (proj_in): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (transformer_blocks): ModuleList(\n",
      "            (0-9): 10 x BasicTransformerBlock(\n",
      "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn1): Attention(\n",
      "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn2): Attention(\n",
      "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                (to_k): Linear(in_features=2048, out_features=1280, bias=False)\n",
      "                (to_v): Linear(in_features=2048, out_features=1280, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "              (ff): FeedForward(\n",
      "                (net): ModuleList(\n",
      "                  (0): GEGLU(\n",
      "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "                  )\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (proj_out): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (resnets): ModuleList(\n",
      "        (0-1): 2 x ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (upsamplers): ModuleList(\n",
      "        (0): Upsample2D(\n",
      "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): CrossAttnUpBlock2D(\n",
      "      (attentions): ModuleList(\n",
      "        (0-2): 3 x Transformer2DModel(\n",
      "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "          (proj_in): Linear(in_features=640, out_features=640, bias=True)\n",
      "          (transformer_blocks): ModuleList(\n",
      "            (0-1): 2 x BasicTransformerBlock(\n",
      "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn1): Attention(\n",
      "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn2): Attention(\n",
      "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "                (to_k): Linear(in_features=2048, out_features=640, bias=False)\n",
      "                (to_v): Linear(in_features=2048, out_features=640, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "              (ff): FeedForward(\n",
      "                (net): ModuleList(\n",
      "                  (0): GEGLU(\n",
      "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "                  )\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (proj_out): Linear(in_features=640, out_features=640, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (resnets): ModuleList(\n",
      "        (0): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
      "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
      "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
      "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (upsamplers): ModuleList(\n",
      "        (0): Upsample2D(\n",
      "          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): UpBlock2D(\n",
      "      (resnets): ModuleList(\n",
      "        (0): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1-2): 2 x ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mid_block): UNetMidBlock2DCrossAttn(\n",
      "    (attentions): ModuleList(\n",
      "      (0): Transformer2DModel(\n",
      "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "        (proj_in): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (transformer_blocks): ModuleList(\n",
      "          (0-9): 10 x BasicTransformerBlock(\n",
      "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn1): Attention(\n",
      "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_out): ModuleList(\n",
      "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn2): Attention(\n",
      "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_k): Linear(in_features=2048, out_features=1280, bias=False)\n",
      "              (to_v): Linear(in_features=2048, out_features=1280, bias=False)\n",
      "              (to_out): ModuleList(\n",
      "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "            (ff): FeedForward(\n",
      "              (net): ModuleList(\n",
      "                (0): GEGLU(\n",
      "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "                )\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (proj_out): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (resnets): ModuleList(\n",
      "      (0-1): 2 x ResnetBlock2D(\n",
      "        (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "        (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (nonlinearity): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_norm_out): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
      "  (conv_act): SiLU()\n",
      "  (conv_out): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "AutoencoderKL(\n",
      "  (encoder): Encoder(\n",
      "    (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (down_blocks): ModuleList(\n",
      "      (0): DownEncoderBlock2D(\n",
      "        (resnets): ModuleList(\n",
      "          (0-1): 2 x ResnetBlock2D(\n",
      "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (nonlinearity): SiLU()\n",
      "          )\n",
      "        )\n",
      "        (downsamplers): ModuleList(\n",
      "          (0): Downsample2D(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): DownEncoderBlock2D(\n",
      "        (resnets): ModuleList(\n",
      "          (0): ResnetBlock2D(\n",
      "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (nonlinearity): SiLU()\n",
      "            (conv_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1): ResnetBlock2D(\n",
      "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (nonlinearity): SiLU()\n",
      "          )\n",
      "        )\n",
      "        (downsamplers): ModuleList(\n",
      "          (0): Downsample2D(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): DownEncoderBlock2D(\n",
      "        (resnets): ModuleList(\n",
      "          (0): ResnetBlock2D(\n",
      "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (nonlinearity): SiLU()\n",
      "            (conv_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1): ResnetBlock2D(\n",
      "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (nonlinearity): SiLU()\n",
      "          )\n",
      "        )\n",
      "        (downsamplers): ModuleList(\n",
      "          (0): Downsample2D(\n",
      "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): DownEncoderBlock2D(\n",
      "        (resnets): ModuleList(\n",
      "          (0-1): 2 x ResnetBlock2D(\n",
      "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (nonlinearity): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (mid_block): UNetMidBlock2D(\n",
      "      (attentions): ModuleList(\n",
      "        (0): Attention(\n",
      "          (group_norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (to_out): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (resnets): ModuleList(\n",
      "        (0-1): 2 x ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv_norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "    (conv_act): SiLU()\n",
      "    (conv_out): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (conv_in): Conv2d(4, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (up_blocks): ModuleList(\n",
      "      (0-1): 2 x UpDecoderBlock2D(\n",
      "        (resnets): ModuleList(\n",
      "          (0-2): 3 x ResnetBlock2D(\n",
      "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (nonlinearity): SiLU()\n",
      "          )\n",
      "        )\n",
      "        (upsamplers): ModuleList(\n",
      "          (0): Upsample2D(\n",
      "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): UpDecoderBlock2D(\n",
      "        (resnets): ModuleList(\n",
      "          (0): ResnetBlock2D(\n",
      "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "            (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (nonlinearity): SiLU()\n",
      "            (conv_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1-2): 2 x ResnetBlock2D(\n",
      "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (nonlinearity): SiLU()\n",
      "          )\n",
      "        )\n",
      "        (upsamplers): ModuleList(\n",
      "          (0): Upsample2D(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): UpDecoderBlock2D(\n",
      "        (resnets): ModuleList(\n",
      "          (0): ResnetBlock2D(\n",
      "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "            (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (nonlinearity): SiLU()\n",
      "            (conv_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1-2): 2 x ResnetBlock2D(\n",
      "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (nonlinearity): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (mid_block): UNetMidBlock2D(\n",
      "      (attentions): ModuleList(\n",
      "        (0): Attention(\n",
      "          (group_norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (to_out): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (resnets): ModuleList(\n",
      "        (0-1): 2 x ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv_norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "    (conv_act): SiLU()\n",
      "    (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (quant_conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (post_quant_conv): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model['generation'].unet)\n",
    "print(model['generation'].vae)\n",
    "sd_model = model['generation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([981., 961., 941., 921., 901., 881., 861., 841., 821., 801., 781., 761.,\n",
      "        741., 721., 701., 681., 661., 641., 621., 601., 581., 561., 541., 521.,\n",
      "        501., 481., 461., 441., 421., 401., 381., 361., 341., 321., 301., 281.,\n",
      "        261., 241., 221., 201., 181., 161., 141., 121., 101.,  81.,  61.,  41.,\n",
      "         21.,   1.], device='cuda:0') 50\n"
     ]
    }
   ],
   "source": [
    "num_inference_steps = 50\n",
    "device = sd_model._execution_device\n",
    "timesteps = None\n",
    "sigmas = None\n",
    "\n",
    "prompt = \"a photo of a cat on mars\"\n",
    "\n",
    "timesteps, num_inference_steps = retrieve_timesteps(\n",
    "            sd_model.scheduler, num_inference_steps, device, timesteps, sigmas\n",
    "        )\n",
    "print(timesteps,num_inference_steps)\n",
    "\n",
    "batch_size = 1\n",
    "num_images_per_prompt = 1\n",
    "height = 1024\n",
    "width = 1024\n",
    "generator = None\n",
    "latents =None\n",
    "torch.float16\n",
    "num_channels_latents = sd_model.unet.config.in_channels\n",
    "prompt_2 = None\n",
    "do_classifier_free_guidance = True\n",
    "negative_prompt = None\n",
    "negative_prompt_2 = None\n",
    "prompt_embeds = None\n",
    "negative_prompt_embeds = None\n",
    "pooled_prompt_embeds = None\n",
    "negative_pooled_prompt_embeds = None\n",
    "lora_scale = None\n",
    "clip_skip = None\n",
    "do_classifier_free_guidance = True\n",
    "eta = 0.0\n",
    "output_type = 'pil'\n",
    "return_dict = False\n",
    "guidance_scale = 5.0\n",
    "guidance_rescale = 0.0\n",
    "clip_skip = None\n",
    "cross_attention_kwargs = None\n",
    "denoising_end = 1.0\n",
    "\n",
    "sd_model._guidance_scale = guidance_scale\n",
    "sd_model._guidance_rescale = guidance_rescale\n",
    "sd_model._clip_skip = clip_skip\n",
    "sd_model._cross_attention_kwargs = cross_attention_kwargs\n",
    "sd_model._denoising_end = denoising_end\n",
    "sd_model._interrupt = False\n",
    "\n",
    "(\n",
    "    prompt_embeds,\n",
    "    negative_prompt_embeds,\n",
    "    pooled_prompt_embeds,\n",
    "    negative_pooled_prompt_embeds,\n",
    ") = sd_model.encode_prompt(\n",
    "        prompt=prompt,\n",
    "        prompt_2=prompt_2,\n",
    "        device=device,\n",
    "        num_images_per_prompt=num_images_per_prompt,\n",
    "        do_classifier_free_guidance=do_classifier_free_guidance,\n",
    "        negative_prompt=negative_prompt,\n",
    "        negative_prompt_2=negative_prompt_2,\n",
    "        prompt_embeds=prompt_embeds,\n",
    "        negative_prompt_embeds=negative_prompt_embeds,\n",
    "        pooled_prompt_embeds=pooled_prompt_embeds,\n",
    "        negative_pooled_prompt_embeds=negative_pooled_prompt_embeds,\n",
    "        lora_scale=lora_scale,\n",
    "        clip_skip=clip_skip,\n",
    "    )\n",
    "latents = sd_model.prepare_latents(\n",
    "    batch_size * num_images_per_prompt,\n",
    "    num_channels_latents,\n",
    "    height,\n",
    "    width,\n",
    "    torch.float16,\n",
    "    device,\n",
    "    generator,\n",
    "    latents,\n",
    ")\n",
    "extra_step_kwargs = sd_model.prepare_extra_step_kwargs(generator, eta)\n",
    "add_text_embeds = pooled_prompt_embeds\n",
    "text_encoder_projection_dim = sd_model.text_encoder_2.config.projection_dim\n",
    "original_size =  (height, width)\n",
    "crops_coords_top_left = (0, 0)\n",
    "target_size =  (height, width)\n",
    "add_time_ids = sd_model._get_add_time_ids(\n",
    "            original_size,\n",
    "            crops_coords_top_left,\n",
    "            target_size,\n",
    "            dtype=prompt_embeds.dtype,\n",
    "            text_encoder_projection_dim=text_encoder_projection_dim,\n",
    "        )\n",
    "negative_add_time_ids = add_time_ids\n",
    "\n",
    "\n",
    "if do_classifier_free_guidance:\n",
    "    prompt_embeds = torch.cat([negative_prompt_embeds, prompt_embeds], dim=0)\n",
    "    add_text_embeds = torch.cat([negative_pooled_prompt_embeds, add_text_embeds], dim=0)\n",
    "    add_time_ids = torch.cat([negative_add_time_ids, add_time_ids], dim=0)\n",
    "\n",
    "prompt_embeds = prompt_embeds.to(device)\n",
    "add_text_embeds = add_text_embeds.to(device)\n",
    "add_time_ids = add_time_ids.to(device).repeat(batch_size * num_images_per_prompt, 1)\n",
    "num_warmup_steps = max(len(timesteps) - num_inference_steps * sd_model.scheduler.order, 0)\n",
    "\n",
    "timestep_cond = None\n",
    "sd_model._num_timesteps = len(timesteps)\n",
    "# print(prompt_embeds.shape)\n",
    "# print(negative_prompt_embeds.shape)\n",
    "# print(pooled_prompt_embeds.shape)\n",
    "# print(negative_pooled_prompt_embeds.shape)\n",
    "# print(latents.shape)\n",
    "# print(add_time_ids.shape)\n",
    "\n",
    "# print(negative_prompt_embeds)\n",
    "# print(prompt_embeds)\n",
    "# print(sd_model.scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_embeds': tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.8608, -0.2827,  1.0537,  ..., -0.5127, -1.5000,  0.3979]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<CatBackward0>),\n",
       " 'time_ids': tensor([[1024., 1024.,    0.,    0., 1024., 1024.],\n",
       "         [1024., 1024.,    0.,    0., 1024., 1024.]], device='cuda:0',\n",
       "        dtype=torch.float16)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_embeds.shape\n",
    "added_cond_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e0b71bab294679893d10b3cf3a36e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "        with sd_model.progress_bar(total=num_inference_steps) as progress_bar:\n",
    "                for i, t in enumerate(timesteps):\n",
    "                        latent_model_input = torch.cat([latents] * 2) if do_classifier_free_guidance else latents\n",
    "                        latent_model_input = sd_model.scheduler.scale_model_input(latent_model_input, t)\n",
    "                        added_cond_kwargs = {\"text_embeds\": add_text_embeds, \"time_ids\": add_time_ids}\n",
    "\n",
    "                        noise_pred = sd_model.unet(\n",
    "                                latent_model_input,\n",
    "                                t,\n",
    "                                encoder_hidden_states=prompt_embeds,\n",
    "                                timestep_cond=timestep_cond,\n",
    "                                cross_attention_kwargs=sd_model.cross_attention_kwargs,\n",
    "                                added_cond_kwargs=added_cond_kwargs,\n",
    "                                return_dict=False,\n",
    "                        )[0]\n",
    "\n",
    "\n",
    "                        if do_classifier_free_guidance:\n",
    "                                noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
    "                                noise_pred = noise_pred_uncond + sd_model.guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
    "\n",
    "                        latents_dtype = latents.dtype\n",
    "                        latents = sd_model.scheduler.step(noise_pred, t, latents, **extra_step_kwargs, return_dict=False)[0]\n",
    "\n",
    "                        if i == len(timesteps) - 1 or ((i + 1) > num_warmup_steps and (i + 1) % sd_model.scheduler.order == 0):\n",
    "                                progress_bar.update()\n",
    "\n",
    "        needs_upcasting = sd_model.vae.dtype == torch.float16 and sd_model.vae.config.force_upcast\n",
    "        if needs_upcasting:\n",
    "                sd_model.upcast_vae()\n",
    "                latents = latents.to(next(iter(sd_model.vae.post_quant_conv.parameters())).dtype)\n",
    "        # elif latents.dtype != sd_model.vae.dtype:\n",
    "        #         if torch.backends.mps.is_available():\n",
    "        #                 # some platforms (eg. apple mps) misbehave due to a pytorch bug: https://github.com/pytorch/pytorch/pull/99272\n",
    "        #                 sd_model.vae = sd_model.vae.to(latents.dtype)\n",
    "        latents = latents / sd_model.vae.config.scaling_factor\n",
    "        image = sd_model.vae.decode(latents, return_dict=False)[0]\n",
    "\n",
    "        if needs_upcasting:\n",
    "                sd_model.vae.to(dtype=torch.float16)\n",
    "\n",
    "        image = sd_model.image_processor.postprocess(image, output_type=output_type)\n",
    "\n",
    "        # Offload all models\n",
    "        sd_model.maybe_free_model_hooks()\n",
    "\n",
    "        if not return_dict:\n",
    "                output = (image,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([<PIL.Image.Image image mode=RGB size=1024x1024 at 0x7FAC439BDE80>],)\n"
     ]
    }
   ],
   "source": [
    "print(output)\n",
    "output[0][0].save('results/mar_cat.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "pipeline = StableDiffusionXLPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\",torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n",
    ")\n",
    "pipeline.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# print(pipeline.cross_attention_kwargs)\n",
    "# print(pipeline.encode_prompt)\n",
    "# print(pipeline.do_classifier_free_guidance)\n",
    "# print(pipeline.negative_prompt)\n",
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "# prompt = \"\"\n",
    "n_steps = 30\n",
    "high_noise_frac = 1.0\n",
    "output = pipeline(\n",
    "    prompt=prompt,\n",
    "    num_inference_steps=n_steps,\n",
    "    denoising_end=high_noise_frac,\n",
    "    # output_type=\"latent\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['images'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "output['images'][0].save('results/mar_horse_2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# output['images'].shape #latent 1, 4, 128, 128\n",
    "output['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode input prompt\n",
    "\n",
    "cross_attention_kwargs = None\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_images_per_prompt = 1\n",
    "do_classifier_free_guidance = True\n",
    "\n",
    "lora_scale = (\n",
    "    cross_attention_kwargs.get(\"scale\", None) if cross_attention_kwargs is not None else None\n",
    ")\n",
    "\n",
    "prompt_embeds, negative_prompt_embeds = pipeline.encode_prompt(\n",
    "    prompt,\n",
    "    device,\n",
    "    num_images_per_prompt,\n",
    "    do_classifier_free_guidance,\n",
    "    negative_prompt,\n",
    "    prompt_embeds=prompt_embeds,\n",
    "    negative_prompt_embeds=negative_prompt_embeds,\n",
    "    lora_scale=lora_scale,\n",
    "    clip_skip=self.clip_skip,\n",
    ")\n",
    "\n",
    "# For classifier free guidance, we need to do two forward passes.\n",
    "# Here we concatenate the unconditional and text embeddings into a single batch\n",
    "# to avoid doing two forward passes\n",
    "if self.do_classifier_free_guidance:\n",
    "    prompt_embeds = torch.cat([negative_prompt_embeds, prompt_embeds])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
